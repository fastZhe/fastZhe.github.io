[{"title":"docker-shadowsocks多用户镜像","url":"%2F2018%2F11%2F20%2Fshadowsocks-2019-3-3%2F","content":"\n## 简介\n\n搭建一个使用docker镜像实现的shadowsocks server端，支持多用户\n\n\n## 使用\n\n可以使用作者已有的仓库镜像\n\n* 默认开启五个端口，密码都为hhhzz，加密方法为：aes-256-cfb\n\n```\n# 使用默认的配置文件\ndocker run -d -p 9991:9991 -p 9992:9992 -p 9993:9993 -p 9994:9994 -p 9995:9995  hzdan/shadowsocks_manyusers:1.0\n# 使用自定义文件\n# /mnt/shadowsocks.json 为具体配置项，自己可定义，并挂载覆盖\ndocker run -d -p 9991:9991 -p 9992:9992 -p 9993:9993 -p 9994:9994 -p 9995:9995  -v `pwd`:/mnt hzdan/shadowsocks_manyusers:1.0\n\n```\n\n## 自定义镜像\n\n### 创建dockerfile && shadowsocks.json && start.sh\n\n* dockerfile\n\n> 本镜像借鉴与oddrationale@gmail.com 作者的镜像\n\n```\n# shadowsocks\n#\n# VERSION 0.0.3\n\nFROM ubuntu:16.04\nMAINTAINER hzz\n\nRUN apt-get update && \\\n    apt-get install -y python-pip libsodium18\nRUN pip install shadowsocks==2.8.2\nCOPY shadowsocks.json /mnt\nCOPY start.sh /usr/local\n\n# Configure container to run as an executable\nCMD /usr/local/start.sh\n```\n\n* shadowsocks.json\n\n> 用户密码，端口都可以更改\n\n\n```\n{\n    \"server\":\"0.0.0.0\",\n    \"local_address\":\"127.0.0.1\",\n    \"local_port\":1080,\n    \"port_password\":{\n        \"9991\":\"hhhzz\",\n        \"9992\":\"hhhzz\",\n        \"9993\":\"hhhzz\",\n        \"9994\":\"hhhzz\",\n        \"9995\":\"hhhzz\"\n},\n    \"timeout\":300,\n    \"method\":\"aes-256-cfb\",\n    \"fast_open\":false\n}\n```\n\n* start.sh\n\n```\n#!/bin/sh\n/usr/local/bin/ssserver -c /mnt/shadowsocks.json\n```\n\n\n## 打包、使用\n\n\n```\n# 打包\ndocker build -t <tag> .\n\n# 运行，-p使用的端口与配置文件中需要一致\ndocker run -d -p 9991:9991 -p 9992:9992 -p 9993:9993 -p 9994:9994 -p 9995:9995 <tag>\n\n```\n\n","tags":["shadowsocks"],"categories":["shadowsocks"]},{"title":"mongodb 整合kerberos以及java连接","url":"%2F2018%2F09%2F26%2Fmongodb-kerberos-2018-09-26%2F","content":"\n### 简介\n\n* Kerberos（KDC） 几个重要的概念：\n\n```\nPrincipal：任何服务器所提供的用户、计算机、服务都将被定义成Principal。本例使用客户端使用：mongodb@HZ.COM  mongodb服务端使用：mongodb/hz.com@HZ.COM\nInstances：用于服务principals和特殊管理Principal。\nRealms：Kerberos安装提供的独特的域的控制，把它想象成你的主机和用户所属的主机或者组。官方约定这域需要大写。默认的，Ubuntu将把DNS域名转换为大写当成这里的域。 本例使用HZ.COM\nKey Distribution Center: （KDC）由三部分组成，一是principal数据库，认证服务器，和票据授予服务器。每个Realm至少要有一个。\nTicket Granting Ticket：由认证服务器（AS）签发，Ticket Granting Ticket (TGT)使用用户的密码加密，这个密码只有用户和KDC知道。\nTicket Granting Server: (TGS) 根据请求签发服务的票据。\nTickets：确认两个Principal的身份。一个主体是用户，另一个是由用户请求的服务。门票会建立一个加密密钥，用于在身份验证会话中的安全通信。\nKeytab Files：从KDC主数据库中提取的文件，并且包含的服务或主机的加密密钥。\n```\n\n* mongodb 启用kerberos\n使用kerberos授权登录可以更大的增加安全性\n\n\n### 安装带有kerberos认证的mongodb\n#### 安装kerberos\n    请参照网上相关的教程，作者后续会发布相关的安装教程\n\n\n#### 安装mongodb enterprice\n\n这是企业版下载链接 [mongodb enterprice](https://downloads.mongodb.com/linux/mongodb-linux-x86_64-enterprise-rhel70-4.0.2.tgz?_ga=2.98831574.996585356.1537869301-553143157.1537869299 \"mongodb\") \n\n本次安装基于centos7.2\n\n* 安装依赖的一些库\n```\nyum install cyrus-sasl cyrus-sasl-gssapi cyrus-sasl-plain krb5-libs libcurl libpcap lm_sensors-libs net-snmp net-snmp-agent-libs openldap openssl rpm-libs tcp_wrappers-libs -y\n```\n\n* 解压下载的mongodb\n\n```\n# 解压\n$ tar -xvf mongodb-linux-x86_64-enterprise-rhel70-4.0.2.tgz\n$ cd mongodb-linux-x86_64-enterprise-rhel70-4.0.2/\n$ mkdir data\n$ mkdir conf\n```\n\n$ vi conf/mongod.conf  #更改以下路径为自己的路径,ip为服务器的ip\n```\ndbpath=/root/mongodb/mongodb-linux-x86_64-enterprise-rhel70-4.0.2/data\n\n#where to log\nlogpath=/root/mongodb/mongodb-linux-x86_64-enterprise-rhel70-4.0.2/mongodb.log\n\nlogappend=true\n\nbind_ip = 10.211.55.5\nport = 27017\n\n# Enable journaling, http://www.mongodb.org/display/DOCS/Journaling\njournal=true\n\n```\n\n* 创建对应的kerberos用户以及keytab文件（hz.com为我自己的主机名）\n\n>客户端用户：mongodb@HZ.COM  mongodb服务端用户：mongodb/hz.com@HZ.COM\n>keytab文件：mongodb.keytab                  mongodb_hz.keytab\n\n\n* 将mongodb目录下的bin文件夹加入到PATH\n\n以下两句可以追加到文件末尾：/etc/profile   具体路径请根据自己的进行修改\n\n```\nexport MONGODB_HOME=/root/mongodb/mongodb-linux-x86_64-enterprise-rhel70-4.0.2\nexport PATH=$MONGODB_HOME/bin:$PATH\nexport KRB5_KTNAME=/root/mongodb_hz.keytab\n```\n执行source，使上面的追加起作用\nsource /etc/profile\n\n* 添加kerberos登录用户到mongodb\n\n```\ncd $MONGODB_HOME\n./bin/mongod -f conf/mongod.conf\n\n另起一个窗口，使用shell登录进去mongodb，并添加kerberos用户,请替换以下的kerberos客户端用户为你的用户\n\n$ mongo --host hz.com\n\nuse $external\n db.getSiblingDB(\"$external\").createUser(\n   {\n     user: \"mongodb@HZ.COM\",\n     roles: [ { role: \"root\", db: \"admin\" } ]\n   }\n)\nexit\n```\n* 使用kerberos认证启动mongodb\n\n```\n首先关闭上一个mongod服务,然后使用下面命令启动mongodb\n$ kdestory\n$ kinit -kt /root/mongodb_hz.keytab mongodb/hz.com\n$ mongod-auth --setParameter authenticationMechanisms=GSSAPI -f /root/mongodb/mongodb-linux-x86_64-enterprise-rhel70-4.0.2/conf/mongod.conf\n\n```\n启动后如下图\n![mongodb](/images/mongodb/2018-09-26-01.png)\n\n* 使用kerberos，登录mongodb\n\n```\n$ kdestory\n$ kinit -kt mongodb.keytab mongodb\n$ mongo --host hz.com --authenticationMechanism=GSSAPI --authenticationDatabase='$external' --username mongodb@HZ.COM\n$ show dbs\n```\n如下图，表示成功\n![mongodb](/images/mongodb/2018-09-26-02.png)\n\n\n\n### 使用java连接带有kerberos的mongodb\n\n使用maven工程构建，依赖如下\n```\n    <dependency>\n        <groupId>org.apache.hadoop</groupId>\n        <artifactId>hadoop-common</artifactId>\n        <version>2.6.0-cdh5.13.0</version>\n    </dependency>\n    <dependency>\n        <groupId>org.mongodb</groupId>\n        <artifactId>mongo-java-driver</artifactId>\n        <version>3.8.2</version>\n    </dependency>\n```\n\n\b创建连接类MyMongo,请替换相关的用户名、host、krb5.conf、keytab文件位置等\n```\npackage com.hz.mongodb;\n\nimport com.mongodb.MongoClient;\nimport com.mongodb.MongoCredential;\nimport com.mongodb.ServerAddress;\nimport com.mongodb.client.*;\nimport org.apache.hadoop.conf.Configuration;\nimport org.apache.hadoop.security.UserGroupInformation;\nimport org.bson.Document;\nimport java.io.IOException;\nimport java.security.PrivilegedAction;\nimport java.security.PrivilegedExceptionAction;\nimport java.util.Arrays;\n\n/**\n * Created with hzz\n * Description:\n *\n * @author: huangzhe\n * @date: 2018-01-25\n * @time: 下午20:14\n */\npublic class MyMongo {\n    public static void main(String[] args) {\n        Configuration conf = new Configuration();\n        conf.set(\"hadoop.security.authentication\", \"Kerberos\");\n        System.setProperty(\"java.security.krb5.conf\", \"/Users/huangzhe/Downloads/krb5.conf\");\n        UserGroupInformation.setConfiguration(conf);\n         MongoClient client = null;\n        try {\n            UserGroupInformation ugi = UserGroupInformation.loginUserFromKeytabAndReturnUGI(\"mongodb@HZ.COM\", \"/Users/huangzhe/Downloads/mongodb.keytab\");\n\n            try {\n                client=ugi.doAs((PrivilegedExceptionAction<MongoClient>) () -> {\n                    MongoCredential credential = MongoCredential.createGSSAPICredential(\"mongodb@HZ.COM\");\n                    MongoClient result = new MongoClient(new ServerAddress(\"hz.com\", 27017),\n                            Arrays.asList(credential));\n                    MongoDatabase db = result.getDatabase(\"ceshi\");\n                    MongoIterable<String> tbs = db.listCollectionNames();\n                    MongoCursor<String> tbCursor = tbs.iterator();\n                    System.out.println(\"连接mongodb 成功\");\n                    return result;\n                });\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        } catch (IOException e) {\n            e.printStackTrace();\n            System.out.println(\"连接mongodb 失败\");\n        }\n\n        //获取对应的表\n        MongoDatabase db = client.getDatabase(\"mybase\");\n        MongoIterable<String> tbs = db.listCollectionNames();\n\n        MongoCursor<String> tbCursor = tbs.iterator();\n        while (tbCursor.hasNext()) {\n            System.out.println(tbCursor.next());\n        }\n\n        MongoCollection<Document> t = db.getCollection(\"test\");\n        FindIterable<Document> ds = t.find();\n        MongoCursor<Document> ss = ds.iterator();\n        while (ss.hasNext()){\n            System.out.println(ss.next());\n        }\n        System.out.println(t.count());\n    }\n}\n```\n\n","tags":["mongodb"],"categories":["java"]},{"title":"netty Unit testing","url":"%2F2018%2F08%2F04%2Fchapter9-2018-8-4%2F","content":"\n### 简介\n\n本章主要覆盖以下几方面，单元测试，EmbeddedChannel的简介，使用EmbeddedChannel测试ChannelHandlers\n\nChannelHandlers是netty应用模块中最重要的一部分，因此彻底的测试在开发过程中也是标准的一部分，很多最好的事件表名你的测试并不能证明你的实现是正确的，但是使用Unit Testing 总是很容易隔离问题。\n\n\n### EmbeddedChannel 概述\nNetty中提供了一个叫做embedded transport 为了测试ChannelHandlers，这个具有传输特性的channel实现，EmbeddedChannel，提供一种简单的方式让事件通过整个Pipeline\n\n这种注意是很直接的，你可以用EmbeddedChannel写入站与出站的数据，然后检测通过ChannelPipeline的数据是否符合预期\n\n![netty-9](/images/netty_part1/2018-8-4-1.png)\n\n以下为具体的流程图\n\n![netty-9](/images/netty_part1/2018-8-4-2.png)\n\n入站数据由ChannelInboundHandlers 处理并且表达数据是从远端处理，出站数据是由ChannelOutboundHandlers 并且表示数据是由远端写的，取决于你所需要测试的channleHandler\n\n### 使用EmbeddedChannel测试ChannelHandlers\n\n#### 测试入站数据\n以下为表示了一个简单的ByteToMessageDecoder的实现，给与充足的数据，它将提供一个固定的大小，如果没有足够的数据去读，它将会等待下个数据块并且再次检查是否有一个固定大小的对象生成\n\n![netty-9](/images/netty_part1/2018-8-4-3.png)\n\n你可以看到上面这张图右边的部分，特别是解码生产一个固定大小的对象，因此它可能需要超过一个时间提供足够的字节生产对象。最终每一个对象都将通过下一个ChannelHandler直至通过整个链条\n\n```\npublic class FixedLengthFrameDecoder extends ByteToMessageDecoder {\n    private final int frameLength;\n\n    public FixedLengthFrameDecoder(int frameLength) {\n        if (frameLength <= 0) {\n            throw new IllegalArgumentException(\n                \"frameLength must be a positive integer: \" + frameLength);\n        }\n        this.frameLength = frameLength;\n    }\n\n    @Override\n    protected void decode(ChannelHandlerContext ctx, ByteBuf in,\n        List<Object> out) throws Exception {\n        while (in.readableBytes() >= frameLength) {\n            ByteBuf buf = in.readBytes(frameLength);\n            out.add(buf);\n        }\n    }\n}\n```\n以下为测试代码\n\n```\npublic class FixedLengthFrameDecoderTest {\n    @Test\n    public void testFramesDecoded() {\n        ByteBuf buf = Unpooled.buffer();\n        for (int i = 0; i < 9; i++) {\n            buf.writeByte(i);\n        }\n        ByteBuf input = buf.duplicate();\n        EmbeddedChannel channel = new EmbeddedChannel(\n            new FixedLengthFrameDecoder(3));\n        // write bytes\n        assertTrue(channel.writeInbound(input.retain()));\n        assertTrue(channel.finish());\n\n        // read messages\n        ByteBuf read = (ByteBuf) channel.readInbound();\n        assertEquals(buf.readSlice(3), read);\n        read.release();\n\n        read = (ByteBuf) channel.readInbound();\n        assertEquals(buf.readSlice(3), read);\n        read.release();\n\n        read = (ByteBuf) channel.readInbound();\n        assertEquals(buf.readSlice(3), read);\n        read.release();\n\n        assertNull(channel.readInbound());\n        buf.release();\n    }\n\n    @Test\n    public void testFramesDecoded2() {\n        ByteBuf buf = Unpooled.buffer();\n        for (int i = 0; i < 9; i++) {\n            buf.writeByte(i);\n        }\n        ByteBuf input = buf.duplicate();\n\n        EmbeddedChannel channel = new EmbeddedChannel(\n            new FixedLengthFrameDecoder(3));\n        assertFalse(channel.writeInbound(input.readBytes(2)));\n        assertTrue(channel.writeInbound(input.readBytes(7)));\n\n        assertTrue(channel.finish());\n        ByteBuf read = (ByteBuf) channel.readInbound();\n        assertEquals(buf.readSlice(3), read);\n        read.release();\n\n        read = (ByteBuf) channel.readInbound();\n        assertEquals(buf.readSlice(3), read);\n        read.release();\n\n        read = (ByteBuf) channel.readInbound();\n        assertEquals(buf.readSlice(3), read);\n        read.release();\n\n        assertNull(channel.readInbound());\n        buf.release();\n    }\n}\n```\n\n\n#### 测试出站数据\n以下主要以一个MessageToMessage的编码器为例,将负整数转换为整整数\n![netty-9](/images/netty_part1/2018-8-4-4.png)\n\n```\npublic class AbsIntegerEncoder extends\n    MessageToMessageEncoder<ByteBuf> {\n    @Override\n    protected void encode(ChannelHandlerContext channelHandlerContext,\n        ByteBuf in, List<Object> out) throws Exception {\n        while (in.readableBytes() >= 4) {\n            int value = Math.abs(in.readInt());\n            out.add(value);\n        }\n    }\n}\n```\n\n1.写负整数（四个字节的数据到ByteBuf）\n2.创建一个EmbeddedChannel并且分配了一个Encoder\n3.调用writeOutbound 写入数据ByteBuf\n4.标记channel已经写入完成\n5.读取所有的出站数据并且确认是否已经转换为正整数\n\n```\npublic class AbsIntegerEncoderTest {\n    @Test\n    public void testEncoded() {\n        ByteBuf buf = Unpooled.buffer();\n        for (int i = 1; i < 10; i++) {\n            buf.writeInt(i * -1);\n        }\n\n        EmbeddedChannel channel = new EmbeddedChannel(\n            new AbsIntegerEncoder());\n        assertTrue(channel.writeOutbound(buf));\n        assertTrue(channel.finish());\n//\n//        // read bytes\n//        for (int i = 1; i < 10; i++) {\n//            assertEquals(i, channel.readOutbound());\n//        }\n        assertNull(channel.readOutbound());\n    }\n}\n```\n\n### 测试异常处理\n\n主要测试当入站数据的大小超过指定长度，会抛出异常\n\n```\npublic class FrameChunkDecoder extends ByteToMessageDecoder {\n    private final int maxFrameSize;\n\n    public FrameChunkDecoder(int maxFrameSize) {\n        this.maxFrameSize = maxFrameSize;\n    }\n\n    @Override\n    protected void decode(ChannelHandlerContext ctx, ByteBuf in,\n        List<Object> out)\n        throws Exception {\n        int readableBytes = in.readableBytes();\n        if (readableBytes > maxFrameSize) {\n            // discard the bytes\n            in.clear();\n            throw new TooLongFrameException();\n        }\n        ByteBuf buf = in.readBytes(readableBytes);\n        out.add(buf);\n    }\n}\n```\n\n测试\n\n```\npublic class FrameChunkDecoderTest {\n    @Test\n    public void testFramesDecoded() {\n        ByteBuf buf = Unpooled.buffer();\n        for (int i = 0; i < 9; i++) {\n            buf.writeByte(i);\n        }\n        ByteBuf input = buf.duplicate();\n\n        EmbeddedChannel channel = new EmbeddedChannel(\n            new FrameChunkDecoder(3));\n\n        assertTrue(channel.writeInbound(input.readBytes(2)));\n        try {\n            channel.writeInbound(input.readBytes(4));\n            Assert.fail();\n        } catch (TooLongFrameException e) {\n            // expected exception\n        }\n        assertTrue(channel.writeInbound(input.readBytes(3)));\n        assertTrue(channel.finish());\n\n        // Read frames\n        ByteBuf read = (ByteBuf) channel.readInbound();\n        assertEquals(buf.readSlice(2), read);\n        read.release();\n\n        read = (ByteBuf) channel.readInbound();\n        assertEquals(buf.skipBytes(4).readSlice(3), read);\n        read.release();\n        buf.release();\n    }\n}\n```\n\n这部分主要使用try...catch来测试是否有异常被抛出，因为这个是运行时异常，这个很容易测试是否一个异常在处理数据的过程中被捕捉并且处理的。\n\n### 总结\n以一个侵入少的例如JUnit单元测试是一个极度有效的方式保证代码的正确性并且增强可维护性。在这章，你可以学到netty提供的工具怎么测试您自己的ChannelHandler\n\n在下一章您将聚焦于怎么用netty写一个真实的应用。我们将不会表示更多的测试用例，希望你自己保持思考我们想表达的测试方法的重要性。\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":["netty"],"categories":["Unit testing"]},{"title":"netty Bootstrap","url":"%2F2018%2F08%2F03%2Fchapter8-2018-8-3%2F","content":"\n本章主要覆盖以下方面\n* Bootstraping 客户端与服务端\n* 在一个channle中的Bootstraping 客户端\n* 添加channelHandlers\n* 使用ChannelOptions以及属性\n\n![netty-8](/images/netty_part1/2018-8-3-1.png)\n\n\n### Bootstrap 类\n一个server端的Bootstrap，如上图所示，主要用于接收连接，并且创建一个子Channels与客户端服务，然而客户端只需要一个，因此不需要父级的channel。对于udp的服务端也一样如此\n\n```\npublic abstract class AbstractBootstrap\n            <B extends AbstractBootstrap<B,C>,C extends Channel>\n\n\n public class Bootstrap\n            extends AbstractBootstrap<Bootstrap,Channel>\n\n public class ServerBootstrap\n            extends AbstractBootstrap<ServerBootstrap,ServerChannel>\n\n```\n\n### Bootstraping 客户端以及无连接协议\n以下是Bootstraping的API\n\n![netty-8](/images/netty_part1/2018-8-3-2.png)\n![netty-8](/images/netty_part1/2018-8-3-3.png)\n\n\n#### 引导客户端\nBootstrap 类主要负责为客户端创建channels以及为应用指定连接协议\n\n![netty-8](/images/netty_part1/2018-8-3-4.png)\n\n\n例如以下为使用NIO TCP连接\n\n```\nEventLoopGroup group = new NioEventLoopGroup();\nBootstrap bootstrap = new Bootstrap();\n//Sets the EventLoopGroup that provides EventLoops for processing Channel events\nbootstrap.group(group)\n         .channel(NioSocketChannel.class)\n    .handler(new SimpleChannelInboundHandler<ByteBuf>() {\n        @Override\n        protected void channeRead0(\n            ChannelHandlerContext channelHandlerContext,\n            ByteBuf byteBuf) throws Exception {\n            System.out.println(\"Received data\");\n} } );\nChannelFuture future = bootstrap.connect(\n    new InetSocketAddress(\"www.manning.com\", 80));\n    //Specifies the Channel implementation to be used\n    //Sets the handler for Channel events and data\n    //Connects to the remote host\n         \nfuture.addListener(new ChannelFutureListener() {\n    @Override\n    public void operationComplete(ChannelFuture channelFuture)\n        throws Exception {\n        if (channelFuture.isSuccess()) {\n            System.out.println(\"Connection established\");\n        } else {\n            System.err.println(\"Connection attempt failed\");\n            channelFuture.cause().printStackTrace();\n        }\n} } );\n\n\n```\n\n#### Channel 与 EventLoopGroup 组合\nchannel与EventLoopGroup要对应起来，是NIO的channel就要对应NIo的EventLoopGroup\n\n当Bootstrap bind() 或者 connect() 的时候，一定要先设置以下三项\n\n* group()\n* channel() 或者 channelFactory()\n* handler\n\n\n### Bootstrapping 服务端 \n这一节主要讲述Bootstrapping 服务端的相关APi以及使用用例\n\n![netty-8](/images/netty_part1/2018-8-3-5.png)\n\n#### \n你可以发现服务端的Bootstrapping与客户端存在差别，例如childHandler，childAttr以及childOption，以上这些操作传统的server应用都有，特别是ServerChannel要实现创建相关的子channel，主要用于已经接入的连接。所以ServerChannel管理一些数量的子channel\n\n下图为例：\n\n![netty-8](/images/netty_part1/2018-8-3-6.png)\n\n\n```\nNioEventLoopGroup group = new NioEventLoopGroup();\nServerBootstrap bootstrap = new ServerBootstrap();\n//Sets the EventLoopGroup that provides EventLoops for processing Channel events\nbootstrap.group(group)\n     .channel(NioServerSocketChannel.class)\n.childHandler(new SimpleChannelInboundHandler<ByteBuf>() {\n    @Override\n    protected void channelRead0(ChannelHandlerContext ctx,\n              ByteBuf byteBuf) throws Exception {\n        System.out.println(\"Received data\");\n    }\n} );\n//Sets a ChannelInboundHandler for I/O and data for the accepted channels\n\nChannelFuture future = bootstrap.bind(new InetSocketAddress(8080));\nfuture.addListener(new ChannelFutureListener() throws Exception {\n    @Override\n    public void operationComplete(ChannelFuture channelFuture){\n//Binds the channel with the configured bootstrap\n   } } );\n\nif (channelFuture.isSuccess()) {\n    System.out.println(\"Server bound\");\n} else {\n    System.err.println(\"Bound attempt failed\");\n    channelFuture.cause().printStackTrace();\n}\n```\n\n### 从channle中引导客户端\n如果你的程序既有服务，又有客户端场景，因此我们可能需要创建Bootstrap的客户端，由此连接到远程peer，但是这个是最没有效率的解决方法，这种方法可能需要你定义另一个EventLoop，这样就会产生额外的线程，以及上下文切换。\n一个更好的方法是共享已经介入的channel的EventLoop，通过Bootstrap的group方法，因为所有的channles斗湖被分配到一个EventLoop使用同样的线程，这避免了额外的线程创建。\n\n如下图所示：\n![netty-8](/images/netty_part1/2018-8-3-7.png) \n\n```\npublic class BootstrapSharingEventLoopGroup {\n\n    /**\n     * Listing 8.5 Bootstrapping a server\n     * */\n    public void bootstrap() {\n        ServerBootstrap bootstrap = new ServerBootstrap();\n        bootstrap.group(new NioEventLoopGroup(), new NioEventLoopGroup())\n            .channel(NioServerSocketChannel.class)\n            .childHandler(\n                new SimpleChannelInboundHandler<ByteBuf>() {\n                    ChannelFuture connectFuture;\n                    @Override\n                    public void channelActive(ChannelHandlerContext ctx)\n                        throws Exception {\n                        Bootstrap bootstrap = new Bootstrap();\n                        bootstrap.channel(NioSocketChannel.class).handler(\n                            new SimpleChannelInboundHandler<ByteBuf>() {\n                                @Override\n                                protected void channelRead0(\n                                    ChannelHandlerContext ctx, ByteBuf in)\n                                    throws Exception {\n                                    System.out.println(\"Received data\");\n                                }\n                            });\n                        bootstrap.group(ctx.channel().eventLoop());\n                        connectFuture = bootstrap.connect(\n                            new InetSocketAddress(\"www.manning.com\", 80));\n                    }\n\n                    @Override\n                    protected void channelRead0(\n                        ChannelHandlerContext channelHandlerContext,\n                            ByteBuf byteBuf) throws Exception {\n                        if (connectFuture.isDone()) {\n                            // do something with the data\n                        }\n                    }\n                });\n        ChannelFuture future = bootstrap.bind(new InetSocketAddress(8080));\n        future.addListener(new ChannelFutureListener() {\n            @Override\n            public void operationComplete(ChannelFuture channelFuture)\n                throws Exception {\n                if (channelFuture.isSuccess()) {\n                    System.out.println(\"Server bound\");\n                } else {\n                    System.err.println(\"Bind attempt failed\");\n                    channelFuture.cause().printStackTrace();\n                }\n            }\n        });\n    }\n}\n\n```\n\n**主要是无论什么时候都要考虑重用EventLoop**\n\n### 在一个bootstrap中添加多个ChannelHandler\n上文所示主要是使用handler与childHandler中只能绑定一个ChannelHandler，如何绑定多个呢？\n\n答案是使用netty提供的一个ChannelInboundHandlerAdapter 的子类ChannelInitializer这个类\n```\npublic abstract class ChannelInitializer<C extends Channel>\n            extends ChannelInboundHandlerAdapter\n\n\n        //使用这个方法\n        protected abstract void initChannel(C ch) throws Exception;\n```\n\n当有channle绑定到EvnetLoop的时候，这个initChannel方法就会调用，然后在方法完成后，会将自己从ChannelPipeline中去除\n\n```\npublic class BootstrapWithInitializer {\n\n    /**\n     * Listing 8.6 Bootstrapping and using ChannelInitializer\n     * */\n    public void bootstrap() throws InterruptedException {\n        ServerBootstrap bootstrap = new ServerBootstrap();\n        bootstrap.group(new NioEventLoopGroup(), new NioEventLoopGroup())\n            .channel(NioServerSocketChannel.class)\n            .childHandler(new ChannelInitializerImpl());\n        ChannelFuture future = bootstrap.bind(new InetSocketAddress(8080));\n        future.sync();\n    }\n\n    final class ChannelInitializerImpl extends ChannelInitializer<Channel> {\n        @Override\n        protected void initChannel(Channel ch) throws Exception {\n            ChannelPipeline pipeline = ch.pipeline();\n            pipeline.addLast(new HttpClientCodec());\n            pipeline.addLast(new HttpObjectAggregator(Integer.MAX_VALUE));\n\n        }\n    }\n}\n\n```\n### 使用netty 的ChannelOptions以及attributes\n手动配置每个channel是单调乏味的。我们可以使用option()方法对Bootstrap配置ChannelOptions，ChannelOptions提供了相关keep-alive、timeout以及buffer的设置等。\n\n\n```\npublic class BootstrapClientWithOptionsAndAttrs {\n\n    /**\n     * Listing 8.7 Using attributes\n     * */\n    public void bootstrap() {\n        final AttributeKey<Integer> id = AttributeKey.newInstance(\"ID\");\n        Bootstrap bootstrap = new Bootstrap();\n        bootstrap.group(new NioEventLoopGroup())\n            .channel(NioSocketChannel.class)\n            .handler(\n                new SimpleChannelInboundHandler<ByteBuf>() {\n                    @Override\n                    public void channelRegistered(ChannelHandlerContext ctx)\n                        throws Exception {\n                        Integer idValue = ctx.channel().attr(id).get();\n                        // do something with the idValue\n                    }\n\n                    @Override\n                    protected void channelRead0(\n                        ChannelHandlerContext channelHandlerContext,\n                        ByteBuf byteBuf) throws Exception {\n                        System.out.println(\"Received data\");\n                    }\n                }\n            );\n        bootstrap.option(ChannelOption.SO_KEEPALIVE, true)\n            .option(ChannelOption.CONNECT_TIMEOUT_MILLIS, 5000);\n        bootstrap.attr(id, 123456);\n        ChannelFuture future = bootstrap.connect(\n            new InetSocketAddress(\"www.manning.com\", 80));\n        future.syncUninterruptibly();\n    }\n}\n```\n\n### 引导一个UDP的channels  DatagramChannels\n前面的channel例子都是基于Tcp的，但是netty也提供了UDP的实现，区别主要在于connnect以及bind\n\n···\n public void bootstrap() {\n        Bootstrap bootstrap = new Bootstrap();\n        bootstrap.group(new OioEventLoopGroup()).channel(\n            OioDatagramChannel.class).handler(\n            new SimpleChannelInboundHandler<DatagramPacket>() {\n                @Override\n                public void channelRead0(ChannelHandlerContext ctx,\n                    DatagramPacket msg) throws Exception {\n                    // Do something with the packet\n                }\n            }\n        );\n        ChannelFuture future = bootstrap.bind(new InetSocketAddress(0));\n        future.addListener(new ChannelFutureListener() {\n            @Override\n            public void operationComplete(ChannelFuture channelFuture)\n               throws Exception {\n               if (channelFuture.isSuccess()) {\n                   System.out.println(\"Channel bound\");\n               } else {\n                   System.err.println(\"Bind attempt failed\");\n                   channelFuture.cause().printStackTrace();\n               }\n            }\n        });\n    }\n}\n···\n\n\n### 关闭\n如何优雅的关闭\n\n```\nEventLoopGroup group = new NioEventLoopGroup();\nBootstrap bootstrap = new Bootstrap();\nbootstrap.group(group)\n      .channel(NioSocketChannel.class);\n...\nFuture<?> future = group.shutdownGracefully();\n// block until the group has shutdown\nfuture.syncUninterruptibly()\n```\n\n不建议：可选的，你可以使用channel.close() 确定关闭所有活跃的channel，然后再关闭EventLoop。\n\n但是在所有的例子中，记住先关闭EventLoop\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n","tags":["netty"],"categories":["Bootstrap"]},{"title":"netty EventLoop与Thread","url":"%2F2018%2F08%2F02%2Fchapter7-2018-8-2%2F","content":"\n### 线程模型\n传统的线程池模型：jDK1.5之后的Executor的API，表现入下：\n\n![netty-7](/images/netty_part1/2018-8-2-1.png)\n\n* 一个线程从池子中的free列表选中，并且指派一个提交的任务（实现了Runnable接口的任务）\n* 当任务完成的时候，这个线程将返回到list中，并且变得可用\n\n\n#### 总结\n传统的这种池化以及可重用提升了线程的创建于销毁，但是并没有排除线程上下文的切换\n\n\n\n### EventLoop 接口\n当连接发生的整个生命周期，运行一个任务处理事件，是一个基础的网络框架的功能。相应的架构通常是作为一个事件循环，netty是使用EventLoop这个接口实现的，如下图：\n![netty-7](/images/netty_part1/2018-8-2-2.png)\n\n一个EventLoop确定绑定在一个Thread上并且不会改变，一个EventLoop会被分配多个Channels\n![netty-7](/images/netty_part1/2018-8-2-3.png)\n\n通常Events以及任务是执行在一个FIFO序列中，这个排除数据出错的可能性，并且保证任务处理的正确顺序\n\n\n#### I/O 以及事件处理在netty4中\n所有的I/O操作以及事件处理都通过线程被指派在EventLoop上\n\n\n#### I/O 以及事件处理在netty3中\n所有的入站都由EventLoop执行，但是出站的操作是由调用它的线程处理，这个导致了一个问题，可能会导致异步操作，例如同时发生了两个出站的写操作，在不同的线程\n\n另一个消极的方面是当一个入站事件产生了出站事件，但是出站的时候发生了异常，在netty3中，你需要调用线程来处理，增加了线程切换\n\n在netty4中，解决了这个问题，提供了简单的执行架构，并且排除了在ChannelHandler上进行同步操作\n\n\n### 任务调度\n偶尔你需要延迟（推迟）执行一个任务，或者周期性的执行，你可能需要注册一个任务例如5分钟连接一次。一个通用的用例是心跳消息对远端执行。如果没有响应，你知道将要关闭这个channel\n\n#### JDK的任务调度\n在JDk1.5之前，通常使用java.util.Timer，随后JDk1.5之后使用java.util.concurrent，定义了一个ScheduledExecutorService，\n![netty-7](/images/netty_part1/2018-8-2-4.png)\n\n```\n ScheduledExecutorService executor =\n    Executors.newScheduledThreadPool(10);\nScheduledFuture<?> future = executor.schedule(\n    new Runnable() {\n    @Override\n    public void run() {\n        System.out.println(\"60 seconds later\");\n\n      }\n}, 60, TimeUnit.SECONDS);\n......\nexecutor.shutdown();\n```\n\n#### netty的任务调度使用的是EventLoop\n```\nChannel ch = ...\nScheduledFuture<?> future = ch.eventLoop().schedule(\n    new Runnable() {\n    @Override\n    public void run() {\n        System.out.println(\"60 seconds later\");\n    }\n}, 60, TimeUnit.SECONDS);\n```\n\n```\nChannel ch = ...\nScheduledFuture<?> future = ch.eventLoop().scheduleAtFixedRate(\n   new Runnable() {\n@Override\npublic void run() {\n    System.out.println(\"Run every 60 seconds\");\n}\n\n }, 60, 60, TimeUnit.Seconds);\n```\n\n\n### 实现细节\n这一节主要讲解重要元素线程模型以及调度实现的细节\n\n#### 线程管理\n\n![netty-7](/images/netty_part1/2018-8-2-5.png)\n\n\n#### 事件循环与线程的分配\n异步实现仅使用一点EventLoops，在单签的线程模型中，可能持有多个Channels，这个允许多个Channels可以用一个很小数量的线程，而不是每个线程都有一个channel\n\n如下：\n\n![netty-7](/images/netty_part1/2018-8-2-6.png)\n\n\n一旦一个Channel已经被分配到了一个EventLoop，它将会在整个生命周期中使用EventLooop响应的线程\n\n一个EventLoop需要使用ThreadLocal来保证线程安全，因为一个EvnetLoop通常持有多各Channel\n\nOIO\n![netty-7](/images/netty_part1/2018-8-2-7.png)\n\n\n","tags":["netty"],"categories":["EventLoop"]},{"title":"netty ChannelHandler and ChannelPipeline","url":"%2F2018%2F08%2F01%2Fchapter6-2018-8-1%2F","content":"\n\n### channelHandler 家族\n\n#### Channel的生命周期\nChannel接口定义了一个简单但是有力的状态模型，与相关的ChannelInboundHandler API,下面四种状态：\n\n* ChannelUnregistered   当channel创建的时候，但是还没有注册到eventLoop\n* ChannelRegistered     Channel注册到EventLoop\n* ChannelActive         当Channel是活跃的时候（连接到远程），当前状态就是可以接受以及发送数据\n* ChannelInactive       当Channel不在连接到远程\n\n> 正常的Channel的生命周期，当这些响应的状态发生后，会产生响应的事件（event），而这些事件将会在ChannlePipeline中从头至尾经过各个ChannelHandler\n\n```\nChannelRegistered->ChannelActive->ChannelInactive->ChannelUnregistered\n```\n\n### ChannleHandler的生命周期\nChannelHandler的生命周期发生在add、remove、发生异常的时候\n\n* handlerAdded      当ChannelHandler添加到ChannelPipeline \n* handlerRemoved    当ChannelHandler从 ChannelPipeline 移除\n* exceptionCaught   在处理的过程中发生异常\n\n\nChannelInboundHandler—处理所有的入站数据以及所有类型的状态改变\n\nChannelOutboundHandler—处理所有出站的数据以及对所有的操作进行拦截\n\n#### ChannelInboundHandler接口\n![netty-6](/images/netty_part1/2018-8-1-5.png)\n\n当使用ChannelInboundHandler覆盖channelRead()方法时，记得要主动释放池化的 ByteBuf实例，使用ReferenceCountUtil.release()这个方法来释放\n\n```\n@Sharable\npublic class DiscardHandler extends ChannelInboundHandlerAdapter {\n    @Override\n    public void channelRead(ChannelHandlerContext ctx, Object msg) {\n\n        ReferenceCountUtil.release(msg);\n    }\n}\nDiscards received message\n```\n\n当然你也可以使用SimpleChannelInboundHandler，这个不需要你主动释放，它会自动释放\n\n```\n@Sharable\npublic class SimpleDiscardHandler\nExtends SimpleChannel- InboundHandler\n     extends SimpleChannelInboundHandler<Object> {\n    @Override\n    public void channelRead0(ChannelHandlerContext ctx,\nObject msg) {\n        // No need to do anything special\n    }\n}\n```\n\n#### ChannelOutboundHandler接口\n出站操作以及数据处理，通常入参包括Channel, ChannelPipeline, and ChannelHandlerContext\n![netty-6](/images/netty_part1/2018-8-1-6.png)\n\n![netty-6](/images/netty_part1/2018-8-1-7.png)\n\n\nCHANNELPROMISE VS. CHANNELFUTURE \n大多数的出站Channel方法使用ChannelPromise作为参数，当操作完成时候被通知，ChannelPromise是ChannelFuture的子类，他定义了一系列方法，像setSuccess() 或者setFailure()，这样可以使得ChannelFuture不可变\n\n#### ChannelHandler adapters\n\n![netty-6](/images/netty_part1/2018-8-1-8.png)\n\n由图可知，adapters实现了ChannelHandler了以及进站、出站的默认实现\n\n#### 资源管理\nnetty默认提供了资源管理类class Resource- LeakDetector，使用这个类可以诊断程序中是否有内存泄漏（主要是ByteBuf）\n\n如果有泄漏检测到，可以看到如下日志\n```\nLEAK: ByteBuf.release() was not called before it's garbage-collected. Enable\nadvanced leak reporting to find out where the leak occurred. To enable\nadvanced leak reporting, specify the JVM option\n'-Dio.netty.leakDetectionLevel=ADVANCED' or call\nResourceLeakDetector.setLevel().\n```\n\n泄漏等级\n![netty-6](/images/netty_part1/2018-8-1-9.png)\n\n### ChannelPipeline 接口\n每一个新的channel都有一个ChannelPipeline\n\n一个event会出现在入站ChannelInboundHandler或者出站ChannelOutboundHandler中，随后它将向下一个hnadler转发，通过ChannelHandlerContext实现\n\nchannelPipeline总是从头到尾的，如果时间类型不符合某个handler，那么会自动跳过该handler\n\n#### 修改ChannelPipeline\n这是相关的方法\n![netty-6](/images/netty_part1/2018-8-1-10.png)\n\n![netty-6](/images/netty_part1/2018-8-1-11.png)\n\n\n```\nChannelPipeline pipeline = ..;\nFirstHandler firstHandler = new FirstHandler();\npipeline.addLast(\"handler1\", firstHandler);\npipeline.addFirst(\"handler2\", new SecondHandler());\npipeline.addLast(\"handler3\", new ThirdHandler());\n...\npipeline.remove(\"handler3\");\npipeline.remove(firstHandler);\npipeline.replace(\"handler2\", \"handler4\", new FourthHandler());\n```\n\nChannelPipeline执行是不能阻塞的，如果因为以前的旧代码兼容，我们可以使用自定义的EventExecutorGroup来添加到ChannelPipeline链上\n\n\n#### 发出时间 firing events\n当ChannelPipeline 发出的有关ChannelInboundHandlers事件的相关API\n![netty-6](/images/netty_part1/2018-8-1-12.png)\n\n\n当ChannelPipeline 发出的有关ChannelOutboundHandlers事件的相关API\n![netty-6](/images/netty_part1/2018-8-1-13.png)\n\n\n#### ChannelPipeline本章总结\n* 一个ChannelPipeline 持有ChannelHandlers 与Channel协调\n* 一个ChannelPipeline 可以动态删减ChannelHandlers \n* ChannelPipeline拥有富足的API，用于入站、出站的所有事件响应\n\n\n### ChannelHandlerContext 接口\nChannelHandlerContext是管理ChannelHandler与它的ChannelPipeline\n\nChannelHandlerContext有很多的方法、主要用于操作Channel、ChannelPipeline，但是不同的是，他的方法将用于整个pipe链，同样的方法被ChannelHandlerContext调用，它将开始在当前的ChannelHandler，并将调动pipe链中下一个ChannelHandler处理该事件\n\n#### 使用ChannelHandlerContext\n\nChannelHandlerContext API\n![netty-6](/images/netty_part1/2018-8-1-14.png)\n![netty-6](/images/netty_part1/2018-8-1-15.png)\n\nChannelHandlerContext、ChannelPipeline、Channel的关系\n![netty-6](/images/netty_part1/2018-8-1-16.png)\n\n只在感兴趣的事件后执行，在channelHandler中获取ChannelHandlerContext，然后执行读写，即可\n![netty-6](/images/netty_part1/2018-8-1-17.png)\n\n\n#### ChannelHandler与ChannelHandlerContext的高级使用\n使用@Sharable注解我们的handler，可以使得handler在多个Pipeline中使用\n\nChannelHandler要保证线程安全，因此不该带有状态\n\nChannelHandlerContext是线程安全的\n\n\n```\n//保存ChannelHandlerContext的引用\npublic class WriteHandler extends ChannelHandlerAdapter {\n    private ChannelHandlerContext ctx;\n    @Override\n    public void handlerAdded(ChannelHandlerContext ctx) {\n        this.ctx = ctx;\n    }\n    public void send(String msg) {\n        ctx.writeAndFlush(msg);\n} }\n```\n\n### 异常处理\n\n#### 处理入站异常\n您要覆盖ChannelInboundHandler以下方法\n\n```\npublic void exceptionCaught(\n    ChannelHandlerContext ctx, Throwable cause) throws Exception\n\n\n\n//例如\npublic class InboundExceptionHandler extends ChannelInboundHandlerAdapter {\n            @Override\n            public void exceptionCaught(ChannelHandlerContext ctx,\n                Throwable cause) {\n                cause.printStackTrace();\n                ctx.close();\n} }\n\n```\n\n通常我们实现的ChannelInboundHandler总是处于链条的最后，因此我们总是要确保处理异常！，如果没有处理，netty会打印相关日志\n\n#### 处理出站异常\n通常出站操作会返回ChannelFuture、或者ChannelPromise\n\n以下为两种处理方法\n\n```\nChannelPromise setSuccess();\nChannelPromise setFailure(Throwable cause);\n```\n\n```\nChannelFuture future = channel.write(someMessage);\nfuture.addListener(new ChannelFutureListener() {\n    @Override\n    public void operationComplete(ChannelFuture f) {\n        if (!f.isSuccess()) {\n            f.cause().printStackTrace();\n            f.channel().close();\n} }\n});\n```\n\n```\npublic class OutboundExceptionHandler extends ChannelOutboundHandlerAdapter {\n    @Override\n    public void write(ChannelHandlerContext ctx, Object msg,\n        ChannelPromise promise) {\n        promise.addListener(new ChannelFutureListener() {\n            @Override\n            public void operationComplete(ChannelFuture f) {\n                if (!f.isSuccess()) {\n                    f.cause().printStackTrace();\n                    f.channel().close();\n} }\n}); }\n}\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":["netty"],"categories":["channel"]},{"title":"tcp-socket-http区别","url":"%2F2018%2F08%2F01%2Ftcp-socket-http%E5%8C%BA%E5%88%AB-2018-8-1%2F","content":"\n\n### 简介\n这三个概念是很容易混淆的，我们将通过以下来阐述具体的区别\n\n### HTTP与socket、tcp的关系\n这是OSI（开放系统连接--open system interconnection）模型\n![osi](/images/internet/2018-8-1-3.png)\n\n\n这是三者的关系\n![tcp/http/socket](/images/internet/2018-8-1-4.png)\n\n\n\n### http 与tcp\nhttp是基于tcp的，客户端往服务端发送一个HTTP请求时第一步就是要建立与服务端的TCP连接，也就是先三次握手，“你好，你好，你好”。从HTTP 1.1开始支持持久连接，也就是一次TCP连接可以发送多次的HTTP请求。\n\n**总结**\nHTTP是基于tcp的，属于应用层协议\n\n### http 与socket\n\n由于通常情况下Socket(基于tcp)连接就是TCP连接，因此Socket连接一旦建立，通信双方即可开始相互发送数据内容，直到双方连接断开。但在实际网络应用中，客户端到服务器之间的通信往往需要穿越多个中间节点，例如路由器、网关、防火墙等，大部分防火墙默认会关闭长时间处于非活跃状态的连接而导致 Socket 连接断连，因此需要通过轮询告诉网络，该连接处于活跃状态。\n\n而HTTP连接使用的是“请求—响应”的方式，不仅在请求时需要先建立连接，而且需要客户端向服务器发出请求后，服务器端才能回复数据。\n\n很多情况下，需要服务器端主动向客户端推送数据，保持客户端与服务器数据的实时与同步。此时若双方建立的是Socket连接，服务器就可以直接将数据传送给客户端；若双方建立的是HTTP连接，则服务器需要等到客户端发送一次请求后才能将数据传回给客户端，因此，客户端定时向服务器端发送连接请求，不仅可以保持在线，同时也是在“询问”服务器是否有新的数据，如果有就将数据传给客户端。\n\n**总结**\nhttp协议是应用层的协义，有个比较形象的描述：HTTP是轿车，提供了封装或者显示数据的具体形式；Socket是发动机，提供了网络通信的能力。 \n\n### socket 与tcp/ip\n\n**总结**\nsocket本就是传输层tcp与udp的封装，不是协议，是编程接口，因此可以说tcp与udp的具体实现编程接口是由socket实现的\n\n\n\n\n### 总结\n\n用HTTP的情况：双方不需要时刻保持连接在线，比如客户端资源的获取、文件上传等。\n用Socket的情况：大部分即时通讯应用(QQ、微信)、聊天室等\n\n\n\n\n","tags":["tcp"],"categories":["internet"]},{"title":"socket","url":"%2F2018%2F08%2F01%2Fsocket%E7%9F%A5%E8%AF%86-2018-8-1%2F","content":"\n\n\n\n### socket的概念\n\n套接字（socket）是通信的基石，是支持TCP/IP协议的网络通信的基本操作单元。它是网络通信过程中端点的抽象表示，包含进行网络通信必须的五种信息：连接使用的协议，本地主机的IP地址，本地进程的协议端口，远地主机的IP地址，远地进程的协议端口。\n\n应用层通过传输层进行数据通信时，TCP会遇到同时为多个应用程序进程提供并发服务的问题。多个TCP连接或多个应用程序进程可能需要通过同一个TCP协议端口传输数据。为了区别不同的应用程序进程和连接，许多计算机操作系统为应用程序与TCP／IP协议交互提供了套接字(Socket)接口。应用层可以和传输层通过Socket接口，区分来自不同应用程序进程或网络连接的通信，实现数据传输的并发服务。\n\n\n创建Socket连接时，可以指定使用的传输层协议，Socket可以支持不同的传输层协议（TCP或UDP），当使用TCP协议进行连接时，该Socket连接就是一个TCP连接。\n\nsocket则是对TCP/IP协议的封装和应用（程序员层面上）。也可以说，TPC/IP协议是传输层协议，主要解决数据 如何在网络中传输，而HTTP是应用层协议，主要解决如何包装数据。关于TCP/IP和HTTP协议的关系，网络有一段比较容易理解的介绍：\n```\n我们在传输数据时，可以只使用（传输层）TCP/IP协议，但是那样的话，如 果没有应用层，便无法识别数据内容，如果想要使传输的数据有意义，则必须使用到应用层协议，应用层协议有很多，比如HTTP、FTP、TELNET等，也可以自己定义应用层协议。WEB使用HTTP协议作应用层协议，以封装HTTP文本信息，然后使用TCP/IP做传输层协议将它发到网络上。\n```\n\n\n我们平时说的最多的socket是什么呢，实际上socket是对TCP/IP协议的封装，Socket本身并不是协议，而是一个调用接口\n（API），通过Socket，我们才能使用TCP/IP协议。 实际上，Socket跟TCP/IP协议没有必然的联系。Socket编程接\n口在设计的时候，就希望也能适应其他的网络协议。所以说，Socket的出现 只是使得程序员更方便地使用TCP/IP协议栈而已，是对TCP/IP协议的抽象，从而形成了我们知道的一些最基本的函数接口，比如create、 listen、connect、accept、send、read和write等等\n\n\n**总结**\nsocket是基于tcp、udp协议的抽象，是编程的接口,socket不是协议，socket既可以基于tcp（有状态、连接），也可以基于UDP（无状态连接）\n","tags":["socket"],"categories":["socket"]},{"title":"HTTP协议","url":"%2F2018%2F08%2F01%2Fhttp%E5%8D%8F%E8%AE%AE%E5%AD%A6%E4%B9%A0-2018-8-1%2F","content":"\n\n### 简介\nHTTP 本质是位于OSI应用层的一种协议，全拼： hypertext transfer protocol 超文本传输协议（就是说什么数据格式都能传输）\n\n本质是 请求---响应\n\n### 请求\n由三部分组成：请求行、请求头、请求体\n\n如图：\n![osi](/images/internet/2018-8-1-1.png)\n\n\n\n#### 请求行\n第一行是请求行：\n请求方法（METHOD） 统一资源标识符（URI） HTTP版本号\n\n```\n请求方法： POST /GET /HEAD /PUT /DELETE\nURI：URI就是URL中排除掉HOST剩下的部分，也就是资源在服务器上的地址\nHTTP版本号目前主流是1.1\n```\n**区别**\n>HTTP 1.0需要使用keep-alive参数来告知服务器端要建立一个长连接，而HTTP1.1默认支持长连接。\n>HTTP2.0使用了多路复用的技术，做到同一个连接并发处理多个请求，而且并发请求的数量比HTTP1.1大了好几个数量级。\n>当然HTTP1.1也可以多建立几个TCP连接，来支持处理更多并发的请求，但是创建TCP连接本身也是有开销的\n>HTTP1.1不支持header数据的压缩，HTTP2.0使用HPACK算法对header的数据进行压缩，这样数据体积小了，在网络上传输就会更快。\n\n#### 请求头header\n```\nHost: 目标服务器的网络地址\n\nAccept: 让服务端知道客户端所能接收的数据类型，如text/html */*\n\nContent-Type: body中的数据类型，如application/json; charset=UTF-8\n\nAccept-Language: 客户端的语言环境，如zh-cn\n\nAccept-Encoding: 客户端支持的数据压缩格式，如gzip\n\nUser-Agent: 客户端的软件环境，我们可以更改该字段为自己客户端的名字，比如QQ music v1.11，比如浏览器Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) AppleWebKit/600.8.9 (KHTML, like Gecko) Maxthon/4.5.2\n\nConnection: keep-alive，该字段是从HTTP 1.1才开始有的，用来告诉服务端这是一个持久连接，“请服务端不要在发出响应后立即断开TCP连接”。关于该字段的更多解释将在后面的HTTP版本简介中展开。\n\nContent-Length: body的长度，如果body为空则该字段值为0。该字段一般在POST请求中才会有。\nCookie: 记录者用户信息的保存在本地的用户数据，如果有会被自动附上\n```\n\n#### 请求体\n真正需要发给服务端的数据，在使用POST-multipart上传请求中请求体就是上传文件的二进制NSData类型数据；在GET请求中请求体为空；在普通的POST请求中请求体就是一些表单数据。\n\n\n### 响应\n![osi](/images/internet/2018-8-1-2.png)\n\n\n\n#### 响应行\n包含HTTP版本号、状态码、状态码对应的英文名称\n\n**状态码对应的信息**\n```\n1XX：信息提示。不代表成功或者失败，表示临时响应，比如100表示继续，101表示切换协议\n\n2XX: 成功\n\n3XX: 重定向\n\n4XX:客户端错误，很有可能是客户端发生问题，如亲切可爱的404表示未找到文件，说明你的URI是有问题的，服务器机子上该目录是没有该文件的；414URI太长\n\n5XX: 服务器错误，比如504网关超时\n```\n\n#### 响应头与响应体\n与请求头与请求体基本一致，除却一些字段\n\n### HTTP版本差异\n\nHTTP 1.1之前\n```\n不支持持久连接。一旦服务器对客户端发出响应就立即断开TCP连接(频繁创建会话费资源、影响性能)\n\n无请求头跟响应头\n\n客户端的前后请求是同步的。下一个请求必须等上一个请求从服务端拿到响应后才能发出，有点类似多线程的同步机制。（异步会走多线程，快捷）\n```\nHTTP 1.1(主流版本)\n```\n与1.1之前的版本相比，做了以下性能上的提升\n\n增加请求头跟响应头\n\n支持持久连接。客户端通过请求头中指定Connection为keep-alive告知服务端不要在完成响应后立即释放连接。HTTP是基于TCP的，在HTTP 1.1中一次TCP连接可以处理多次HTTP请求\n\n客户端不同请求之间是异步的。下一个请求不必等到上一个请求回来后再发出，而可以连续发出请求，有点类似多线程的异步处理。\n```\n\nHTTP 2.0\n```\n本着向下兼容的原则，1.1版本有的特性2.0都具备，也使用相同的API。但是2.0将只用于https网址。\n```\n\n\n\n\n\n\n\n\n","tags":["http"],"categories":["http"]},{"title":"netty ByteBuf","url":"%2F2018%2F07%2F31%2Fchapter5-2018-7-31%2F","content":"\n### 简介\n这章主要讲解数据的容器-ByteBuf ,以及相关的Api细节、使用用例和内存分配\n\n网络数据的基础单元总是byte（字节），jva nio 提供ByteBuffer作为字节的容器，但是这个类使用比较负责，而且用起来很笨重\n\nnetty提供了ByteBuf来承担这一个责任，更加好的API使用\n\n###ByteBuf API\nnetty API暴露了两部分 abstract class ByteBuf和 interface BYteBufHolder\n\n* 可扩展用户自定义的buffer类型\n* 透明的零复制通过内置的组成buffer 类型\n* 可以根据要求扩展容量\n* 读写切换不需要调用类似于ByteBuffer's flip()方法\n* 读写使用不同的索引\n* 可以链式调用方法\n* 相关计数支持\n* 支持池\n\n#### ByteBuf 怎么工作\n* ByteBuf有两个索引，一个读索引，一个写索引，当超出正常的索引范围，会触发IndexOutOfBoundsException\n* ByteBuf最大的容量是Integer.MAX_VALUE\n\n#### ByteBuf使用模式\n##### HEAP BUFFERS\n顾名思义：使用堆内存进行存储的buffer，在内存中作为一个backing array\n\n优点：\n    分配，以及回收很快\n    使用java GC\n\n##### DIRECT BUFFERS\n使用直接内存分配的buffer，就是使用本地的Api\n\n优点：\n    避免在本地I/O操作前后，拷贝buffer内容到中间状态\n    通过引用计数来进行释放\n\n缺点：\n    获取、回收比较昂贵\n\n##### Composite Buffers\n这个模式聚合了多个ByteBufs,你可以添加或删除你需要的ByteBuf,对外表示一个single\n\n例如一个响应分为header 与body 就可以构建一个Composite Buffers，轻松实现\n\n#### Byte 级别的操作\n##### 随机根据索引获取\n```\nByteBuf buffer = ...;\n        for (int i = 0; i < buffer.capacity(); i++) {\n            byte b = buffer.getByte(i);\n           System.out.println((char) b);\n       }\n\n```\n##### 序列存取数据\nByteBuf有两个读、写索引\n![ByteBuf构造](/images/netty_part1/2018-7-31-1.png)\n\n##### discardable bytes\n表示已经读取过的数据，通过执行read操作，可以通过调用discardReadBytes()来丢弃。\n\n一般不建议经常使用，可能导致内存拷贝，这时候内容部分已经移到开头了，通常，只有当内存很稀缺\n\n##### Readable bytes\n通常这部分存储真正的内容，readerIndex通常从0开始，你可以读取或者跳过等。\n\n读取全部数据\n```\nByteBuf buffer = ...;\nwhile (buffer.isReadable()) {\n    System.out.println(buffer.readByte());\n}\n\n```\n\n##### Writable bytes\n表示的是准备写入的区域，任意写入的操作都将会使writeIndex增加，\n\n写入\n```\nByteBuf buffer = ...;\nwhile (buffer.writableBytes() >= 4) {\n    buffer.writeInt(random.nextInt());\n}\n```\n\n##### Index Management\n ByteBuf readerIndex and writerIndex 通过调用 markReaderIndex(), markWriterIndex(), resetReaderIndex(), and reset- WriterIndex()重置读或者写索引 ，   readerIndex(int) 或者 writerIndex(int)都会将索引设置，因此请小心设置，可以通过调用clear()将读、写索引设置为0\n\n\n##### 搜索操作\n通常可以用IndexOf()判断在哪个位置，复杂搜索可以使用ByteBufProcessor，这个借口定义了很多有用的方法，例如：\n```\nforEachByte(ByteBufProcessor.FIND_NUL)\n```\n\n##### 获取 buffers\n以下操作都会返回新的buffer，但是底层依然是源ButeBuf，所以修改新Buffer会导致源变化\n```\nduplicate()\nslice()\nslice(int, int)\nUnpooled.unmodifiableBuffer(...)\norder(ByteOrder)\nreadSlice(int)\n```\n\n如果想深度拷贝，可以使用copy() 方法\n\n```\nCharset utf8 = Charset.forName(\"UTF-8\");\nByteBuf buf = Unpooled.copiedBuffer(\"Netty in Action rocks!\", utf8);\nByteBuf copy = buf.copy(0, 14);\nSystem.out.println(copy.toString(utf8));\nbuf.setByte(0, (byte)'J');\nassert buf.getByte(0) != copy.getByte(0);\n```\n\n##### 读写操作\nget() set() 不会改变索引\nread() write() 会改变索引\n![ByteBuf get/set](/images/netty_part1/2018-7-31-2.png)\n\n![ByteBuf read](/images/netty_part1/2018-7-31-3.png)\n\n![ByteBuf write](/images/netty_part1/2018-7-31-4.png)\n\n\n\n##### 更多的操作\n![ByteBuf 其他操作](/images/netty_part1/2018-7-31-5.png)\n\n\n### 接口ByteBufHolder\n定义了一个可以实现自己的属性的接口，例如一个http请求中，多个属性，就可以使用ByteBufHolder来实现\n\n### ByteBuf allocation\n本节主要讲述怎么管理ByteBuf的实例\n\n#### ByteBufAllocator\n为了减少分配、以及回收的成本，netty使用了池化的ByteBufAllocator接口\n\n提供了两种实现：ByteBufAllocator: PooledByteBufAllocator and UnpooledByteBufAllocator.\n顾名思义，前者每次使用已有的对象，后者每次返回一个新的对象\n![ByteBufAllocator](/images/netty_part1/2018-7-31-6.png)\n\n\n#### 非池化的 buffers(Unpooled)\n许多情况下我们并没有ByteBufAllocator的相关引用，netty提供了一个工具类，使用静态方法提供ByteBuf的实例\n![Unpooled](/images/netty_part1/2018-7-31-7.png)\n\n\n\n#### 工具类 ByteBufUtil\n用于操作ByteBuf，例如比较equal()  ,打印 hexdup()成16进制的信息\n\n\n### 引用计数 Reference counting\n引用计数是一个用于优化内存使用的技术，通过一个对象当其他对象不在拥有它的引用时，从而释放资源，netty是在版本4的时候实现的，使用ByteBuf、ByteBufHolder\n\nnetty通过实现接口，interface ReferenceCounted，引用计数主要用于池化对象的释放，避免过大的内存消耗\n\n```\nChannel channel = ...;\nByteBufAllocator allocator = channel.alloc();\n....\nByteBuf buffer = allocator.directBuffer();\nassert buffer.refCnt() == 1;\n\n\nByteBuf buffer = ...;\nboolean released = buffer.release();\n\n```\n\n当对象被释放了，再使用，会导致IllegalReferenceCountException.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":["netty"],"categories":["ByteBuf"]},{"title":"netty 传输","url":"%2F2018%2F07%2F30%2Fchapter4-2018-7-30%2F","content":"\n### 简介\n传统的oio（old I/O）编程，与nio异步编程在Api级别差别比较大，但是netty在公共API做了很好的封装，这比在传统的使用JDK编程要更简单。\n\n\n#### 使用传统的jdk来实现blocking与non-blocking\n##### 实现blocking\n\n```\npublic class PlainOioServer {\n    public void serve(int port) throws IOException {\n        final ServerSocket socket = new ServerSocket(port);\n        try {\n            for(;;) {\n                final Socket clientSocket = socket.accept();\n                System.out.println(\n                        \"Accepted connection from \" + clientSocket);\n                new Thread(new Runnable() {\n                    @Override\n                    public void run() {\n                        OutputStream out;\n                        try {\n                            out = clientSocket.getOutputStream();\n                            out.write(\"Hi!\\r\\n\".getBytes(\n                                    Charset.forName(\"UTF-8\")));\n                            out.flush();\n                            clientSocket.close();\n                        } catch (IOException e) {\n                            e.printStackTrace();\n                        } finally {\n                            try {\n                                clientSocket.close();\n                            } catch (IOException ex) {\n                                // ignore on close\n                            }\n                        }\n                    }\n                }).start();\n            }\n        } catch (IOException e) {\n            e.printStackTrace();\n        }\n    }\n}\n```\n* 使用OIO只能支持中等级别的并发，并不能支持上万的连接\n\n##### 实现NIO\n\n```\npublic class PlainNioServer {\n    public void serve(int port) throws IOException {\n        ServerSocketChannel serverChannel = ServerSocketChannel.open();\n        serverChannel.configureBlocking(false);\n        ServerSocket ss = serverChannel.socket();\n        InetSocketAddress address = new InetSocketAddress(port);\n        ss.bind(address);\n        Selector selector = Selector.open();\n        serverChannel.register(selector, SelectionKey.OP_ACCEPT);\n        final ByteBuffer msg = ByteBuffer.wrap(\"Hi!\\r\\n\".getBytes());\n        for (;;){\n            try {\n                selector.select();\n            } catch (IOException ex) {\n                ex.printStackTrace();\n                //handle exception\n                break;\n            }\n            Set<SelectionKey> readyKeys = selector.selectedKeys();\n            Iterator<SelectionKey> iterator = readyKeys.iterator();\n            while (iterator.hasNext()) {\n                SelectionKey key = iterator.next();\n                iterator.remove();\n                try {\n                    if (key.isAcceptable()) {\n                        ServerSocketChannel server =\n                                (ServerSocketChannel) key.channel();\n                        SocketChannel client = server.accept();\n                        client.configureBlocking(false);\n                        client.register(selector, SelectionKey.OP_WRITE |\n                                SelectionKey.OP_READ, msg.duplicate());\n                        System.out.println(\n                                \"Accepted connection from \" + client);\n                    }\n                    if (key.isWritable()) {\n                        SocketChannel client =\n                                (SocketChannel) key.channel();\n                        ByteBuffer buffer =\n                                (ByteBuffer) key.attachment();\n                        while (buffer.hasRemaining()) {\n                            if (client.write(buffer) == 0) {\n                                break;\n                            }\n                        }\n                        client.close();\n                    }\n                } catch (IOException ex) {\n                    key.cancel();\n                    try {\n                        key.channel().close();\n                    } catch (IOException cex) {\n                        // ignore on close\n                    }\n                }\n            }\n        }\n    }\n}\n\n```\n##### 比较\n可以看出传统的OIO与NIO相比来说差距很大，所以对于编程来说，是需要重写的。\n\n#### 使用netty来实现\n##### 同步\n\n```\npublic class NettyOioServer {\n    public void server(int port)\n            throws Exception {\n        final ByteBuf buf =\n                Unpooled.unreleasableBuffer(Unpooled.copiedBuffer(\"Hi!\\r\\n\", Charset.forName(\"UTF-8\")));\n        EventLoopGroup group = new OioEventLoopGroup();\n        try {\n            ServerBootstrap b = new ServerBootstrap();\n            b.group(group)\n                    .channel(OioServerSocketChannel.class)\n                    .localAddress(new InetSocketAddress(port))\n                    .childHandler(new ChannelInitializer<SocketChannel>() {\n                        @Override\n                        public void initChannel(SocketChannel ch)\n                                throws Exception {\n                                ch.pipeline().addLast(\n                                    new ChannelInboundHandlerAdapter() {\n                                        @Override\n                                        public void channelActive(\n                                                ChannelHandlerContext ctx)\n                                                throws Exception {\n                                            ctx.writeAndFlush(buf.duplicate())\n                                                    .addListener(\n                                                            ChannelFutureListener.CLOSE);\n                                        }\n                                    });\n                        }\n                    });\n            ChannelFuture f = b.bind().sync();\n            f.channel().closeFuture().sync();\n        } finally {\n            group.shutdownGracefully().sync();\n        }\n    }\n}\n\n```\n\n##### 异步\n\n```\npublic class NettyNioServer {\n    public void server(int port) throws Exception {\n        final ByteBuf buf =\n                Unpooled.unreleasableBuffer(Unpooled.copiedBuffer(\"Hi!\\r\\n\",\n                        Charset.forName(\"UTF-8\")));\n        NioEventLoopGroup group = new NioEventLoopGroup();\n        try {\n            ServerBootstrap b = new ServerBootstrap();\n            b.group(group).channel(NioServerSocketChannel.class)\n                    .localAddress(new InetSocketAddress(port))\n                    .childHandler(new ChannelInitializer<SocketChannel>() {\n                                      @Override\n                                      public void initChannel(SocketChannel ch)\n                                              throws Exception {\n                                              ch.pipeline().addLast(\n                                                  new ChannelInboundHandlerAdapter() {\n                                                      @Override\n                                                      public void channelActive(\n                                                              ChannelHandlerContext ctx) throws Exception {\n                                                                ctx.writeAndFlush(buf.duplicate())\n                                                                  .addListener(\n                                                                          ChannelFutureListener.CLOSE);\n                                                      }\n                                                  });\n                                      }\n                                  }\n                    );\n            ChannelFuture f = b.bind().sync();\n            f.channel().closeFuture().sync();\n        } finally {\n            group.shutdownGracefully().sync();\n        }\n    }\n}\n\n```\n\n### transport API\n\n\n\nChannleHandler包含以下传统使用：\n* channel是线程安全的\n* 将数据转换类型\n* 提供异常通知\n* 提供channle active与 inactive的通知\n* 提供当channle注册或者从eventLoop注销\n\nlinux使用epoll 本地非阻塞传输、可以通过本地传输通过JVM、内部传输可以测试应用逻辑\n\n\n![channel method](/images/netty_part1/2018-7-30-1.png)\n\n\n#### 包含的传输\n\n![channel include](/images/netty_part1/2018-7-30-2.png)\n\n#### 状态的改变\n![Selection Operation bit-set](/images/netty_part1/2018-7-30-3.png)\n\n\n#### netty支持的OIO实现\n通过使用很短时间间隔获取结果，如果未获取到则抛出异常，来继续进行事件循环来实现OIO\n\n\n### 总结 summary\n在这一张主要讨论了传，输并讨论了传输行为的各种最小需求，因为不是所有的传输在给定的java版本以及同样类型适用于特定的os\n\n\n\n","tags":["netty"],"categories":["transport"]},{"title":"netty asynchronous","url":"%2F2018%2F07%2F29%2Fchapter1-2018-7-27%2F","content":"\n## netty 异步(asynchronous)与事件驱动(event-driven)\n\n本章主要介绍java网络、介绍netty、netty核心模块\n\n### blocking i/o\n传统的java版阻塞i/o编程，使用java原生API，要编写很多代码，并且这些api并没有经过装饰，所以比较臃肿。\n示例：\n```\npublic class BlockingIoExample {\n\n    /**\n     * Listing 1.1 Blocking I/O example\n     * */\n    public void serve(int portNumber) throws IOException {\n        ServerSocket serverSocket = new ServerSocket(portNumber);\n        Socket clientSocket = serverSocket.accept();\n        BufferedReader in = new BufferedReader(\n                new InputStreamReader(clientSocket.getInputStream()));\n        PrintWriter out =\n                new PrintWriter(clientSocket.getOutputStream(), true);\n        String request, response;\n        while ((request = in.readLine()) != null) {\n            if (\"Done\".equals(request)) {\n                break;\n            }\n            response = processRequest(request);\n            out.println(response);\n        }\n    }\n\n    private String processRequest(String request){\n        return \"Processed\";\n    }\n\n    public static void main(String[] args) throws IOException {\n        new BlockingIoExample().serve(8090);\n    }\n}\n```\n试想一下，如果client数量有多少个，就有多少个线程，那么对于资源是极度浪费的，包括栈内存、堆内存、以及系统间线程的切换，以及内存的使用\n\n### non-blocking java NIO\njava是在2002年的JDK1.4支持NIO\n\n#### 简介\n* nio是使用setsockopt()，你自己可以配置sockets 读写请求，如果没数据这个将立即返回，如果有数据，则会堵塞。\n* 可以通过注册一系列的非阻塞sockets 使用系统的事件提示API去决定是否有准备读写的数据\n\nnio: new i/o   \nnio:non-blocking i/o \noio: old blocking i/o\n\n\n#### 选择器 selector\nselector 是一个实现nio的关键因素，它使用了事件通知的API来表示，在一系列sockets中，哪些准备好了可以进行i/o事件，这样一个线程就可以通过selector监控处理多个sockets，这个模型提供给了一个更好的资源管理。\n\n* 很多的连接可以通过一些线程去处理，因此可以减少堆内存溢出，减少多线程之间的切换\n* 在没有nio处理的时候，这些线程可以处理其他任务\n\n尽管nio的出现使得编写应用简单的多，但是想要正确并且安全的编写\n\n\n### introduce netty\n\n* design\n> 多种传输格式使用统一的Api，包括阻塞与非阻塞。简单有力的线程模型、真正的无连接socket支持、链式逻辑部分重用支持\n\n* ease of use\n> 大量的javadoc，以及很多例子、不要求支持jdk1.6以上\n\n* performance\n> 更大的吞吐量、更小的时延远比传统的java Api好的多，并且通过pooling以及reuse减少资源的占用，最小的内存拷贝\n\n* robustness（强劲、结实）\n> 不会由于慢、快以及超负载的连接导致outofMemoryError ，在传统nio高速网上排除不公平的读写速率\n\n* Security\n> 完整的SSL/TLS 以及StartTLS支持。可用于限制环境、例如Applet 或者OSGI\n\n* Community-driven\n> 非常快的迭代版本\n\n\n#### asynchronous and event-Driven\n* 异步\n> 顾名思义,当你调用一个方法时，可以立即给你回复、如果这个事件没有完成，也会给你立即回复，然后一会儿当事件完成时通知你\n\n* 事件驱动\n> 一个问题与一个答案总是挂钩的（事务的处理逻辑），无论何时何地（当事件发生的时候（问题触发、事务触发））他都可以响应（答案）\n\n\n\n#### netty 核心部分\n* channels\n> java NIO的基本构成，\n一个（实体，例如硬件设备、文件、网络socket）打开的连接，一个或多个不同的I/o操作，例如读和写\n可以认为channel 是一个进入、出去数据的载货车，当然，它可以关闭或打开，连接或断开\n\n* Callbacks\n> 回调方法，当事情发生了，会调用\n\n* Futures\n> future主要用于另外一种方式来通知应用，当操作完成的时候，相当于异步操作结果的占位对象，它可能在未来某个时间节点完成，并且提供完成的结果\n\nnetty 中的ChannelFuture提供额外的方法允许我们注册一个或者多个ChannelFutureListener 实例，当任务完成的时候，会进行这些监听器方法的调用，每一个outbound(往外发的数据)异步操作都会返回一个Future\n\n* Event and handlers\n> 基于时间触发后的处理可以包括：日志、数据转换、流控、应用逻辑\n> 时间的类型：连接的active、inactive、数据读、用户事件、错误事件\n> 出站的事件类型：打开或者关闭远程连接，写数据并且刷新到socket中\n\n","tags":["netty"],"categories":["asynchronous"]},{"title":"netty part1","url":"%2F2018%2F07%2F29%2Fpart1%2F","content":"\n\n## part1 netty concepts and architecture\n\nnetty 是一个先进的框架，主要是创建一个高性能网络应用。在这一部分，我们主要探索三个方面以深度证明netty的能力\n* 用netty创建一个网络应用不用你是网络专家\n* 使用netty将比你使用java API本身容易的多\n* netty是设计的最佳实践，使得你的应用本身与网络层解耦\n\n本章主要用于简介java 网络的演变，复习基本的异步通讯以及实践驱动的概念，我们将通过netty的核心模块，在第二章你讲创建自己第一个netty应，用第三章，你将会深入netty底部细节，第四章熟悉网络协议，5-6章将使数据处理层，第七章是并发模型。\n\n第八章，我们将把part1部分所有的细节放入其中，你可以看到怎么配置运行中的基于netty网络应用，最后第九章主要帮助你用netty测试你的应用\n","tags":["netty"],"categories":["netty"]},{"title":"netty 模块与设计","url":"%2F2018%2F07%2F29%2Fchapter3-2018-7-29%2F","content":"\n## 简介\n本章将介绍channel、eventloop、channleFuture\n\n* Channel --sockets\n实现最基础的操作，依赖于下层网络传输的支持\n\n```\nEmbeddedChannel\nLocalServerChannel \nNioDatagramChannel\nNioSctpChannel\nNioSocketChannel\n```\n\n* EventLoop   流控、多线程、并发\n这一章主要讨论高级的EventLoop与Channle、Threads，以及EventLoopGroup的关系，我们将在第七章深入讲述eventLoop\n\n```\n一个EventLoopGroup包含一个或多个EventLoop\n一个EventLoop绑定一个线程在他的生命周期中\n所有的I/O时间都由EventLoop中的线程处理\n一个Channel通常在它的生命周期中注册在一个EventLoop\n一个EventLoop可能被分配一个或者多个Channles\n```\n如图![事件循环](/images/netty_part1/2018-7-29-1.png)\n\n* ChannelFuture 异步通知\n在netty中的所有I/O线程都是异步的，因为所有的操作都不回立即返回结果，因此我们需要一种方式在未来的事件去决定它的结果\n\n\nChannelHandler and ChannelPipeline\n我们可以通过了解具体的细节去看这些组件怎么管理流式、以及执行业务逻辑。\n\n* ChannelHandler\n从用户的立场来讲，netty最重要的部分就是component就是ChannleHandler，通常netty提供一个应用逻辑的容器，去处理所有的出站与入站的数据。这是因为ChannelHadnler所有的方法都是由Event来触发。包括异常的处理，数据类型的转换等。\n\n* ChannelPipleline\n一个ChannelPipleline提供一个链式ChannelHandler的容器，并且处理入站与出站的流式数据，当一个Channel创建的时候，它会自动被分配给一个ChannelPipleline\n\n```\n一个 ChannelInitializer 实现通常将自己注册在ServerBootstrap\n当ChannelInitializer.initChannel() 调用的时候，这个ChannelInitializer通常将吧用户自己实现的handler注册在pipeline\nChannelInitializer 将自己从 ChannelPipeline中删除\n```\n如图![ChannelPipeline](/images/netty_part1/2018-7-29-2.png)\n\n* adapters\n代理的作用就是它对所有的方法都有自己的默认实现，因此你可以通过这些类很快的开发基于自定义的实现，只用覆盖你想要覆盖的方法\n```\nChannelHandlerAdapter\nChannelInboundHandlerAdapter\nChannelOutboundHandlerAdapter\nChannelDuplexHandlerAdapter\n```\n\n\n* SimpleChannelInboundHandler\n通常我们编写的应用都是接受一个解码的消息并且通过应用逻辑处理我们的消息。那么创建一个ChannelHandler，你可以通过继承一个基类 SImpleChannleInboundHandler\n<T> T是你要处理的java类型，最重要的一个方法是channelRead0(Channel- HandlerContext,T)，记住不要堵塞线程\n\n\n\n* Bootstrapping\nbootstrap 类提供了一个用于配置以及应用网络层的容器，用于连接一个给定特殊的端口与host\n\n| category | Bootstrap | Bootstraping | \n| ------ | ------ | ------ |\n| 网络功能 | 连接一个远程的host、port | 绑定本地端口 |\n|EventLoopGroup的数量|1|2|\n\n如图![ChannelPipeline](/images/netty_part1/2018-7-29-3.png)\n\n> 为什么server端需要两个channles、以及EventLoopGroup，因为一个channle接受\b创建新连接，一个负责接受正常的请求。\n\n\n### 编码与解码 Encoders and Decoders\n当数据入站的时候可能通过解码（即byte-> java Object），出站的时候就更好相反，这是编码\n\nnetty提供了类似于ByteToMessageDecoder MessageToByteEncoder这样的编解码，通常netty也提供了入站与出站的编解码代理类\n\n\n### 本章总结\n在这章我们讨论了理解了netty的一席而技术以及架构要点，我们重新回顾了前面的一些具体细节\n\n特殊的我们讨论了，ChannleHandler的一个层次结构，并且介绍了编解码组件，描述了数据在网络层byte格式转换的相辅相成只是。\n\n\n\n\n\n\n","tags":["netty"],"categories":["components"]},{"title":"netty-第一个netty应用","url":"%2F2018%2F07%2F28%2Fchapter2-2018-7-28%2F","content":"\n### 简介\n本章主要从三方面开始创建netty应用，主要覆盖 1.设置开发环境。2.写一个基于Echo client与server的程序。3.building并且测试你的程序\n\n#### 设置开发环境\n基于unix通常需要：\n\n* jdk7  jre不能compile，请设置JAVA_HOME等相关环境变量，并将$JAVA_HOME/bin添加入环境变量\n* maven  创建管理的工具  设置MAVEN_HOME环境变量，并将$MAVEN_HOME/bin添加入环境变量\n* plain text edit 或者 integrated development environment -> IDE\n\n\n#### netty client/server 简介\n如图所示：![echo server/client view](/images/netty_part1/2018-7-28-2-1.png)\n\n主要功能是实现 ，当echo client与server监理连接后，它将发送一个或多个信息给server，然后server将echo 每一条信息给client\n> 这幅图展示了多个client与server的交互，client的数量理论上是可以被限制的，仅仅受系统资源的限制（或者jdk本身强制限制）\n\n##### echo server\n* 要求\n\n> 至少一个channelHandler 这个主要实现server端的业务处理逻辑\n\n> bootstrapping,开始代码配置server,最低限度的配置，绑定端口并且监听请求连接\n\n###### channelHandlers 与 业务逻辑\n在netty中，ChannelHandler主要用于接收以及响应事件的通知。在netty中，所有的数据处理逻辑都包含在在里面。在EchoServer中，server将回复进来的数据，一次我们需要实现接口 **ChannleInboundHandler**,相关方法定义了入站事务，我们的例子比较简单，因此只需要一些方法，因此最有效的是使用子类 **ChannleINbouondHandlerAdapter** 这个子类是接口提供个默认实现，主要有以下几个方法与我们有关 \n\n```\n@Sharable\npublic class EchoServerHandler extends ChannelInboundHandlerAdapter {\n    @Override\n    public void channelRead(ChannelHandlerContext ctx, Object msg) {\n        ByteBuf in = (ByteBuf) msg;\n        System.out.println(\n                \"Server received: \" + in.toString(CharsetUtil.UTF_8));\n        ctx.write(in);\n    }\n\n    @Override\n    public void channelReadComplete(ChannelHandlerContext ctx)\n            throws Exception {\n        ctx.writeAndFlush(Unpooled.EMPTY_BUFFER)\n                .addListener(ChannelFutureListener.CLOSE);\n    }\n\n    @Override\n    public void exceptionCaught(ChannelHandlerContext ctx,\n        Throwable cause) {\n        cause.printStackTrace();\n        ctx.close();\n    }\n}\n```\n* channelRead 有入站数据的时候会被调用\n* channelReadComplete 通知handler 在当前批次最后一条消息被调用\n* exceptionCaught  发生异常的时候被调用 ，每个channle 都有一个chain（管道），因此最好有一个handler实现该方法，否则，一旦有异常发生，会直到链尾才会被打印出来\n\n**channlehandlers**\n支持不同的事件类型格式，应用实现了ChannlHandlers可以实现一个事件整个生命周期的钩子，并且提供自己的业务逻辑。业务代码与网络代码解耦\n\n\n###### bootstrapping 服务\nbootstrap是配置服务\n```\npublic class EchoServer {\n    private final int port;\n\n    public EchoServer(int port) {\n        this.port = port;\n    }\n\n    public static void main(String[] args)\n        throws Exception {\n        if (args.length != 1) {\n            System.err.println(\"Usage: \" + EchoServer.class.getSimpleName() +\n                \" <port>\"\n            );\n            return;\n        }\n        int port = Integer.parseInt(args[0]);\n        new EchoServer(port).start();\n    }\n\n    public void start() throws Exception {\n        final EchoServerHandler serverHandler = new EchoServerHandler();  //创建我们的处理handler\n        EventLoopGroup group = new NioEventLoopGroup();   //创建一个nio事件循环组\n        try {\n            ServerBootstrap b = new ServerBootstrap();   //创建一个bootstrap\n            b.group(group)    //绑定事件循环组\n                .channel(NioServerSocketChannel.class)   //指定处理的channle类型\n                .localAddress(new InetSocketAddress(port))    //绑定端口\n                .childHandler(new ChannelInitializer<SocketChannel>() {  //初始化一个channle\n                    @Override\n                    public void initChannel(SocketChannel ch) throws Exception {\n                        ch.pipeline().addLast(serverHandler);   //添加我们的业务逻辑到处理链条中\n                    }\n                });\n\n            ChannelFuture f = b.bind().sync();      //同步绑定\n            System.out.println(EchoServer.class.getName() +\n                \" started and listening for connections on \" + f.channel().localAddress());\n            f.channel().closeFuture().sync();   //阻塞到channle 同步关闭\n        } finally {\n            group.shutdownGracefully().sync();    //优雅的同步关闭\n        }\n    }\n}\n```\n\n##### echo client\n###### 简介\n1. 连接server\n2. 发送一个或多个消息\n3. 对每个消息，等待接收到同样的消息\n4. 关闭连接\n\nChannelInboundHandler-> SimpleChannelInboundHandler\n需要实现的方法\n* channelActive()—Called after the connection to the server is established，连接建立的时候\n* channelRead0()—Called when a message is received from the server    当接收到消息的时候\n* exceptionCaught()—Called if an exception is raised during processing 发生异常的时候\n\n\n###### Bootstrap client\n```\npublic class EchoClient {\n    private final String host;\n    private final int port;\n\n    public EchoClient(String host, int port) {\n        this.host = host;\n        this.port = port;\n    }\n\n    public void start()\n        throws Exception {\n        EventLoopGroup group = new NioEventLoopGroup();\n        try {\n            Bootstrap b = new Bootstrap();\n            b.group(group)\n                .channel(NioSocketChannel.class)   //与server端不同的\n                .remoteAddress(new InetSocketAddress(host, port))\n                .handler(new ChannelInitializer<SocketChannel>() {\n                    @Override\n                    public void initChannel(SocketChannel ch)\n                        throws Exception {\n                        ch.pipeline().addLast(\n                             new EchoClientHandler());  //实现自己的业务逻辑\n                    }\n                });\n            ChannelFuture f = b.connect().sync();\n            f.channel().closeFuture().sync();\n        } finally {\n            group.shutdownGracefully().sync();\n        }\n    }\n\n    public static void main(String[] args)\n            throws Exception {\n        if (args.length != 2) {\n            System.err.println(\"Usage: \" + EchoClient.class.getSimpleName() +\n                    \" <host> <port>\"\n            );\n            return;\n        }\n\n        final String host = args[0];\n        final int port = Integer.parseInt(args[1]);\n        new EchoClient(host, port).start();\n    }\n}\n```\n\n###### echo client handler\n```\npublic class EchoClientHandler\n    extends SimpleChannelInboundHandler<ByteBuf> {\n    @Override\n    public void channelActive(ChannelHandlerContext ctx) {\n        ctx.writeAndFlush(Unpooled.copiedBuffer(\"Netty rocks!\",\n                CharsetUtil.UTF_8));\n    }\n\n    @Override\n    public void channelRead0(ChannelHandlerContext ctx, ByteBuf in) {\n        System.out.println(\n                \"Client received: \" + in.toString(CharsetUtil.UTF_8));\n    }\n\n    @Override\n    public void exceptionCaught(ChannelHandlerContext ctx,\n        Throwable cause) {\n        cause.printStackTrace();\n        ctx.close();\n    }\n}\n```\n\n\n\n* SimpleChannelInboundHandler vs. ChannelInboundHandler\n\nSimpleChannelInboundHandler 调用完channelRead0() 完成后，将会释放ByteBuf的内存，而server端则不能释放，因为发送出去，是在调用readComplete的时候，才会发送。\n\n\n\n\n\n\n\n","tags":["netty"],"categories":["netty"]},{"title":"Tcp学习-下","url":"%2F2018%2F07%2F25%2Ftcp%E5%AD%A6%E4%B9%A0%E4%B8%8B-2018-07-26%2F","content":"\n\n### 简介\ntcp要解决一个很大的事情，就是要在一个网络根据不同的情况来动态调整自己的发包速度---小则让自己更稳定，大则让整个网络更稳定\n\n\n### tcp的rtt算法\ntimeout 太大->重发慢->丢了半天重发-> 没效率->性能差\n\ntimeout 太小->可能没有丢就重发->重发就快、增加网络拥堵，导致更多超时 (恶性循环导致更多重发)\n\n* RTT：round trip time 就是一个数据包从发出去到回来的时间。这样发送端就可以设置RTO\n* RTO：retransmission timeout 重传超时\n* SRTT：smoothed RTT 平滑RTT\n\n\n### tcp滑动窗口\ntcp必须解决的可靠传输以及包乱序问题，所以tcp必须知道网络实际的数据处理带宽或者数据处理的速度，这样才不会引起网络拥塞，导致丢包\n\n所以tcp，引入了一些技术做网络流控，sliding window是其中的一个技术，tcp里面有一个字段叫做window，又叫Advertised-window,这个字段是接收端告诉发送端自己还有多少缓冲区可以接收数据。于是发送端就可以根据这个接收端的处理能力发送数据，而不会导致接收端处理不过来。\n\n#### Zero Window\n接收端可能没有多余的窗口了，那么当恢复到足够的窗口大小时，怎么通知发送端呢？ \n\n解决这个问题使用了Zero Window Probe，缩写为zwp，也就是说，发送端在窗口的值变成0后，会发zwp的包给接收方，让接收方来ack他的window，一般这个值会设置3次，第三次大约30-60s，如果3次过后还是0的话，tcp就会发RST把连接断掉\n\n#### Silly Window Syndrome\n糊涂窗口综合征，接收方太忙了，来不及取走Receive window里的数据，那么，会导致发送方越来越小，到最后，如果接收方有几个字节并告诉发送方，那么发送方会义无反顾发送几个字节。\n\n* MTU：以太网 MTU是1500字节，出去TCP+IP头的40个字节，真正的数据传输为1460，这就是MSS，Maximum Transmission Unit，MTU\n* MSS：max segment size 最大tcp包大小\n\n\n\n### TCP的拥塞处理 – Congestion Handling\nTCP不是一个自私的协议，当拥塞发生的时候，要做自我牺牲。就像交通阻塞一样，每个车都应该把路让出来，而不要再去抢路了\n\n拥塞处理的四种算法：\n\n1）慢启动，2）拥塞避免，3）拥塞发生，4）快速恢复\n\n首先，我们来看一下TCP的慢热启动。慢启动的意思是，刚刚加入网络的连接，一点一点地提速，不要一上来就像那些特权车一样霸道地把路占满。新同学上高速还是要慢一点，不要把已经在高速上的秩序给搞乱了。\n\n#### 慢启动的算法如下(cwnd全称Congestion Window)：\n\n1）连接建好的开始先初始化cwnd = 1，表明可以传一个MSS大小的数据。\n\n2）每当收到一个ACK，cwnd++; 呈线性上升\n\n3）每当过了一个RTT，cwnd = cwnd*2; 呈指数让升\n\n4）还有一个ssthresh（slow start threshold），是一个上限，当cwnd >= ssthresh时，就会进入“拥塞避免算法”（后面会说这个算法）\n\n所以，我们可以看到，如果网速很快的话，ACK也会返回得快，RTT也会短，那么，这个慢启动就一点也不慢。下图说明了这个过程。\n\n\n\n#### 拥塞避免算法 – Congestion Avoidance\n前面说过，还有一个ssthresh（slow start threshold），是一个上限，当cwnd >= ssthresh时，就会进入“拥塞避免算法”。一般来说ssthresh的值是65535，单位是字节，当cwnd达到这个值时后，算法如下：\n\n1）收到一个ACK时，cwnd = cwnd + 1/cwnd\n\n2）当每过一个RTT时，cwnd = cwnd + 1\n\n这样就可以避免增长过快导致网络拥塞，慢慢的增加调整到网络的最佳值。很明显，是一个线性上升的算法。\n\n\n前面我们说过，当丢包的时候，会有两种情况：\n\n1）等到RTO超时，重传数据包。TCP认为这种情况太糟糕，反应也很强烈。\n```\nsshthresh =  cwnd /2\ncwnd 重置为 1\n进入慢启动过程\n2）Fast Retransmit算法，也就是在收到3个duplicate ACK时就开启重传，而不用等到RTO超时。\n\nTCP Tahoe的实现和RTO超时一样。\nTCP Reno的实现是：\ncwnd = cwnd /2\nsshthresh = cwnd\n进入快速恢复算法——Fast Recovery\n上面我们可以看到RTO超时后，sshthresh会变成cwnd的一半，这意味着，如果cwnd<=sshthresh时出现的丢包，那么TCP的sshthresh就会减了一半，然后等cwnd又很快地以指数级增涨爬到这个地方时，就会成慢慢的线性增涨。我们可以看到，TCP是怎么通过这种强烈地震荡快速而小心得找到网站流量的平衡点的。\n```\n\n#### 快速恢复算法 – Fast Recovery\nTCP Reno\n\n这个算法定义在RFC5681。快速重传和快速恢复算法一般同时使用。快速恢复算法是认为，你还有3个Duplicated Acks说明网络也不那么糟糕，所以没有必要像RTO超时那么强烈。 注意，正如前面所说，进入Fast Recovery之前，cwnd 和 sshthresh已被更新：\n```\ncwnd = cwnd /2\nsshthresh = cwnd\n然后，真正的Fast Recovery算法如下：\n\ncwnd = sshthresh  + 3 * MSS （3的意思是确认有3个数据包被收到了）\n重传Duplicated ACKs指定的数据包\n如果再收到 duplicated Acks，那么cwnd = cwnd +1\n如果收到了新的Ack，那么，cwnd = sshthresh ，然后就进入了拥塞避免的算法了。\n如果你仔细思考一下上面的这个算法，你就会知道，上面这个算法也有问题，那就是——它依赖于3个重复的Acks。注意，3个重复的Acks并不代表只丢了一个数据包，很有可能是丢了好多包。但这个算法只会重传一个，而剩下的那些包只能等到RTO超时，于是，进入了恶梦模式——超时一个窗口就减半一下，多个超时会超成TCP的传输速度呈级数下降，而且也不会触发Fast Recovery算法了。\n\n通常来说，正如我们前面所说的，SACK或D-SACK的方法可以让Fast Recovery或Sender在做决定时更聪明一些，但是并不是所有的TCP的实现都支持SACK（SACK需要两端都支持），所以，需要一个没有SACK的解决方案。而通过SACK进行拥塞控制的算法是FACK（后面会讲）\n```\n","tags":["tcp"],"categories":["tcp"]},{"title":"Tcp名词解析","url":"%2F2018%2F07%2F25%2Ftcp%E5%90%8D%E8%AF%8D%E8%A7%A3%E6%9E%90-2018-07-25%2F","content":"\n### 简介\n主要介绍一些tcp的专业名词以及相关的含义\n\n#### 在TCP层，有个FLAGS字段，这个字段有以下几个标识：SYN, FIN, ACK, PSH, RST, URG.\n\n\n* SYN表示建立连接\n\n* FIN表示关闭连接\n\n* ACK表示响应\n\n* PSH表示有 DATA数据传输\n\n* RST表示连接重置\n\n\n> 其中，ACK是可能与SYN，FIN等同时使用的，比如SYN和ACK可能同时为1，它表示的就是建立连接之后的响应，\n> 如果只是单个的一个SYN，它表示的只是建立连接。\n> TCP的几次握手就是通过这样的ACK表现出来的。\n> 但SYN与FIN是不会同时为1的，因为前者表示的是建立连接，而后者表示的是断开连接。\n> RST一般是在FIN之后才会出现为1的情况，表示的是连接重置。\n> 一般地，当出现FIN包或RST包时，我们便认为客户端与服务器端断开了连接；而当出现SYN和SYN＋ACK包时，我们认为客户端与服务器建立了一个连接。\n> PSH为1的情况，一般只出现在 DATA内容不为0的包中，也就是说PSH为1表示的是有真正的TCP数据包内容被传递。\n\n\n#### 重传的相关名词\n\n* 处理大负载连接的名词\n```\ntcp_synack_retries   ： 可以用他来减少重试次数\ntcp_max_syn_backlog  ： 可以增大SYN连接数\ntcp_abort_on_overflow： 处理不过来干脆就直接拒绝连接了\n```\n\n* 相关注意的\n\n```\nISN ：init sequence number 初始化序列码\n\nMSL ： max segment lifetime 最大tcp segment存活时间\n\nTIME_WAIT： 为主动关闭方的tcp状态机的状态\n主要有两个原因：1）TIME_WAIT确保有足够的时间让对端收到了ACK，如果被动关闭的那方没有收到Ack，就会触发被动端重发Fin，一来一去正好2个MSL，2）有足够的时间让这个连接不会跟后面的连接混在一起\n\ntcp_tw_reuse：官方文档上说tcp_tw_reuse 加上tcp_timestamps（又叫PAWS, for Protection Against Wrapped Sequence Numbers）可以保证协议的角度上的安全，但是你需要tcp_timestamps在两边都被打开\n\ntcp_tw_recycle：如果是tcp_tw_recycle被打开了话，会假设对端开启了tcp_timestamps，然后会去比较时间戳，如果时间戳变大了，就可以重用。但是，如果对端是一个NAT网络的话（如：一个公司只用一个IP出公网）或是对端的IP被另一台重用了，这个事就复杂了。建链接的SYN可能就被直接丢掉了\n\ntcp_max_tw_buckets：这个是控制并发的TIME_WAIT的数量，默认值是180000，如果超限，那么，系统会把多的给destory掉，然后在日志里打一个警告（如：time wait bucket table overflow），官网文档说这个参数是用来对抗DDoS攻击的。\n\nFast Retransmit ：快速重传机制，当对端没有收到对应的包时，对端会发送三次一样的ack，我们可以通过发送的这种机制，重传丢失的segment\n\nSACK ：Selective Acknowledgment (SACK)，主要是对端接收到的数据块，可以让己方发现哪些没有收到\n\nD-ACK:Duplicate SACK – 重复收到数据的问题,其主要使用了SACK来告诉发送方有哪些数据被重复接收了。\n如果SACK的第一个段的范围被ACK所覆盖，那么就是D-SACK\n如果SACK的第一个段的范围被SACK的第二个段覆盖，那么就是D-SACK\n\n```\n\n\n\nTCP的连接建立和连接关闭，都是通过请求－响应的模式完成的。\n\n### 概念补充-TCP三次握手：\n\nTCP(Transmission Control Protocol)传输控制协议\n\nTCP是主机对主机层的传输控制协议，提供可靠的连接服务，采用三次握手确认建立一个连接：\n\n位码即tcp标志位，有6种标示：SYN(synchronous建立联机) ACK(acknowledgement 确认) PSH(push传送) FIN(finish结束) RST(reset重置) URG(urgent紧急)Sequence number(顺序号码) Acknowledge number(确认号码)\n\n```\n第一次握手：主机A发送位码为syn＝1，随机产生seq number=1234567的数据包到服务器，主机B由SYN=1知道，A要求建立联机；\n第二次握手：主机B收到请求后要确认联机信息，向A发送ack number=(主机A的seq+1)，syn=1，ACK=1，随机产生seq=7654321的包；\n第三次握手：主机A收到后检查ack number是否正确，即第一次发送的seq number+1，以及位码ACK是否为1，若正确，主机A会再发送ack number=(主机B的seq+1)，ACK=1，主机B收到后确认seq值与ACK=1则连接建立成功。\n\n完成三次握手，主机A与主机B开始传送数据。\n\n\n在TCP/IP协议中，TCP协议提供可靠的连接服务，采用三次握手建立一个连接。\n第一次握手：建立连接时，客户端发送syn包(syn=j)到服务器，并进入SYN_SEND状态，等待服务器确认；\n第二次握手：服务器收到syn包，必须确认客户的SYN（ack=j+1），同时自己也发送一个SYN包（syn=k），即SYN+ACK包，此时服务器进入SYN_RECV状态；\n第三次握手：客户端收到服务器的SYN＋ACK包，向服务器发送确认包ACK(ack=k+1)，此包发送完毕，客户端和服务器进入ESTABLISHED状态，完成三次握手。完成三次握手，客户端与服务器开始传送数据.\n```\n\n### 概念补充-TCP四次挥手：\n* 以客户端主动挥手为例\n```\n第一次挥手：客户端发送fin=1 ,seq=x,ack=y，此时客户端状态为fin_wait1,等待服务器确认\n第二次挥手：服务端接收后，先发送ack=x+1，此时服务端状态进入close_wait,客户端接收后状态进入fin_wait2\n第三次挥手：服务端发送fin=1,seq=y+1,此时服务端状态进入last_ack，客户端接收后进入time_wait\n第四次挥手：客户端接收到上面两个后，发送ack=y+2,服务端收到后会关闭;\n\n客户端time_wait状态等待timeout时间后，才会释放关闭\n```\n\n* 客户端与服务端同时关闭\n```\n第一次与第二次挥手同时进行\n1.客户端与服务端同时发送fin,seq,ack,两者接收后，此时客户端与服务端同时进入fin_wait1,等待对方确认\n2.客户端与服务端同时发送ack,两者接收后同时进入time_wait\n\n两者都在time_wait状态等待timeout时间后，才会释放关闭\n```\n\n\n\n\n\n\n\n\n\n","tags":["tcp"],"categories":["tcp"]},{"title":"设计模式之空对象模式","url":"%2F2018%2F07%2F23%2F%E7%A9%BA%E5%AF%B9%E8%B1%A1%E6%A8%A1%E5%BC%8F-2018-07-23%2F","content":"\n## 设计模式之空对象模式\n* 23中模式之外的新模式\n\n### 简介\n通过实现一个默认的无意义对象类避免null值实现\n\n### 最佳实践\n* 就是指定默认的一个映射对象，方法不实现，默认为空，与实际对象实现同一个接口，这样在源头中解决null值\n* 使用类似于Option这样的对象，获取时判断有值没，再获取\n","tags":["空对象模式"],"categories":["power design"]},{"title":"设计模式之黑板模式","url":"%2F2018%2F07%2F22%2F%E9%BB%91%E6%9D%BF%E6%A8%A1%E5%BC%8F-2018-07-22%2F","content":"\n## 设计模式之黑板模式\n* 23中模式之外的新模式\n\n### 简介\n黑板模式是观察者模式的一个扩展，允许消息的读写同时进行，广泛地交互消息\n就像一个黑板，任何一个老师都可以写东西，同学都可以看东西，在时间上和空间上彻底解耦\n\n\n### 示意图\n![黑板模式示意图](/images/designPatterns/2018-07-22-1.png)\n<center>黑板模式示意图</center>\n\n### 最佳实践\n* 使用数据库作为黑板，大量消息访问下回影响性能。\n* 使用消息队列作为黑板，订阅发布式\n\n> 消息队列：使用推模式、拉模式实现，具体请参考一些消息队列，kafka\n\n","tags":["黑板模式"],"categories":["power design"]},{"title":"设计模式之雇工模式","url":"%2F2018%2F07%2F21%2F%E9%9B%87%E5%B7%A5%E6%A8%A1%E5%BC%8F-2018-07-21%2F","content":"\n## 设计模式之雇工模式\n* 23中模式之外的新模式\n\n### 简介\n雇工模式也叫做仆人模式：雇工模式是行为模式的一种，它为一组类提供通用的功能，而不需要类实现这些功能，他是命令模式的一种扩展。\n> 类似于厨师、裁缝、园丁等都是一组类，具有清洁的能力，但是我们并没有实现，使用雇工模式，就是简化版的命令模式。让被服务对象实现具体的方法，使用雇工来干活\n\n### 类图\n![雇工模式示意图](/images/designPatterns/2018-07-19-4.png)\n<center>雇工模式示意图</center>\n\n### 代码\n\n具有一组能力的对象，以及对应对象的实现\nIserviced\n```\npackage com.bj.hz.hire;\n\n/**\n * Created with hzz\n * Description:\n *\n * @author: huangzhe\n * @date: 2018-07-19\n * @time: 9:08 PM\n */\npublic interface Iserviced {\n    public void cleaned();\n}\n\n\npackage com.bj.hz.hire;\n\n/**\n * Created with hzz\n * Description:\n *\n * @author: huangzhe\n * @date: 2018-07-19\n * @time: 9:15 PM\n */\npublic class Garden implements Iserviced {\n    @Override\n    public void cleaned() {\n        System.out.println(\"花园被打扫了\");\n    }\n}\n\n\n\npackage com.bj.hz.hire;\n\n/**\n * Created with hzz\n * Description:\n *\n * @author: huangzhe\n * @date: 2018-07-19\n * @time: 9:17 PM\n */\npublic class Kitchen implements Iserviced {\n    @Override\n    public void cleaned() {\n        System.out.println(\"厨房被打扫了\");\n    }\n}\n\n\n```\n\n雇工 Servant\n```\npackage com.bj.hz.hire;\n\n/**\n * Created with hzz\n * Description:\n *\n * @author: huangzhe\n * @date: 2018-07-19\n * @time: 9:14 PM\n */\npublic class ServantHire {\n    public void clean(Iserviced serviced){\n        serviced.cleaned();\n    }\n}\n```\n\n场景类\nCient\n```\npackage com.bj.hz.hire;\n\n/**\n * Created with hzz\n * Description:\n *\n * @author: huangzhe\n * @date: 2018-07-19\n * @time: 9:15 PM\n */\npublic class Client {\n    public static void main(String[] args) {\n\n    }\n}\n```\n\n\n\n","tags":["雇工模式"],"categories":["power design"]},{"title":"Tcp学习_上","url":"%2F2018%2F07%2F20%2Ftcp%E5%AD%A6%E4%B9%A0%E4%B8%8A-2018-07-24%2F","content":"\n> 本文主要参考、copy陈皓老师的tcp那些事儿，再此谢谢陈皓老师\n\n\n### 简介\ntcp在网络OSI的七层模型中第四层--transport层，ip在第三层--network层，Arp在第二层--data link层，在第二层的数据，我们叫Frame，在第三层的数据我们叫Packet，第四层的数据叫segment\n\n### 数据流向\n数据 -> tcp(segment) -> ip(packet) -> data link(frame) \n每个层解析自己的协议，数据交给上层\n\n\n### Tcp头格式\n![tcp头部](/images/tcp/tcp-header01.png)\n\n<center>tcp头部</center>\n\n* tcp头部没有ip地址\b，那个是ip层的事，tcp包含源端口、与目标端口\n\n> 一个tcp连接需要源ip、目标ip、源端口、目标端口、\b以及协议才能表示同一个连接\n* sequence number:包序号，解决网络包乱序问题\n* acknowledgement number: 就是ack，用来确认收到消息，解决不丢包的问题\n* window ：advertised-window ，滑动窗口，解决流控\n* tcp flag：包类型，操控tcp的状态机\n\n![tcp头部其他定义](/images/tcp/tcp-header02.png)\n<center>tcp头部其他定义</center>\n\n### tcp的状态机\n网络上的传输是没有连接的，包括TCP也是一样的。而TCP所谓的“连接”，其实只不过是在通讯的双方维护一个“连接状态”，让它看上去好像有连接一样。所以，TCP的状态变换是非常重要的\n\n![tcp状态机](/images/tcp/tcp-fsm.png)\n<center>tcp状态机</center>\n\n![tcp开始关闭示意图](/images/tcp/tcp-open-close.jpg)\n<center>tcp开始关闭示意图</center>\n\n\n#### tcb\n在网络传输层，tcp模块中有一个tcb（传输控制模块，transmit control block），它用于记录tcp协议运行过程中的 变量。对于有多个连接的tcp，每个连接都有一个tcb。tcb结构的定义包括这个连接使用 的源端口、目的端口、目的ip、序号、应答序号、对方窗口大小、己方窗口大小、tcp状态、top输入/输出队列、应用层输出队列、tcp的重传有关变量。\n\n\n#### 对于建链接的3次握手\n主要是要初始化Sequence Number 的初始值。通信的双方要互相通知对方自己的初始化的Sequence Number（缩写为ISN：Inital Sequence Number）——所以叫SYN，全称Synchronize Sequence Numbers。也就上图中的 x 和 y。这个号要作为以后的数据通信的序号，以保证应用层接收到的数据不会因为网络上的传输的问题而乱序（TCP会用这个序号来拼接数据）。\n#### 对于4次挥手\n其实你仔细看是2次，因为TCP是全双工的，所以，发送方和接收方都需要Fin和Ack。只不过，有一方是被动的，所以看上去就成了所谓的4次挥手。如果两边同时断连接，那就会就进入到CLOSING状态，然后到达TIME_WAIT状态。下图是双方同时断连接的示意图（你同样可以对照着TCP状态机看）\n\n![tcp同步关闭示意图](/images/tcp/tcp-closesimul.png)\n<center>tcp同步关闭示意图</center>\n\n\n\n### tcp重传机制\n#### 超时重传机制\n不回ack，死等，当发现方发现收不到ack的超时后，会重传3，有严重的性能问题，会导致多次重传\n\n#### 快速重传机制\ntcp引入了一种叫做fast retransmit的算法，以数据为驱动，不以时间为驱动，解决了timeout的问题\n> 如果某个包没有连续到达，就ack最后那个可能被丢了的包，如果发送方连续收到三次相同的ack，就重传--好处是不用等到timeout再重传\n\n##### 问题\n如果发送发送多个对端，发现三次的ack传来，并不知道是一个对端、还是三个对端，这个时候，是重传丢失的，还是丢失后的都要传\n\n#### sack方法\nSelective Acknowledgment (SACK)，在tcp头里面加入sack的东西，ACK还是Fast Retransmit的ACK，SACK则是汇报收到的数据碎版\n这个协议需要两边都支持，因此在 Linux下，可以通过tcp_sack参数打开这个功能（Linux 2.4后默认打开\n\n![tcp-Sack](/images/tcp/tcp-sack_example.jpg)\n<center>tcp-Sack示意图</center>\n\n##### 问题\n* 问题——接收方Reneging\n所谓Reneging的意思就是接收方有权把已经报给发送端SACK里的数据给丢了。这样干是不被鼓励的，因为这个事会把问题复杂化了，但是，接收方这么做可能会有些极端情况，比如要把内存给别的更重要的东西。所以，发送方也不能完全依赖SACK，还是要依赖ACK，并维护Time-Out，如果后续的ACK没有增长，那么还是要把SACK的东西重传，另外，接收端这边永远不能把SACK的包标记为Ack。\n\n* 问题——性能问题\nSACK会消费发送方的资源，试想，如果一个攻击者给数据发送方发一堆SACK的选项，这会导致发送方开始要重传甚至遍历已经发出的数据，这会消耗很多发送端的资源。\n\n#### Duplicate SACK – 重复收到数据的问题\nLinux下的tcp_dsack参数用于开启这个功能（Linux 2.4后默认打开）\n\nD-SACK使用了SACK的第一个段来做标志，\n如果SACK的第一个段的范围被ACK所覆盖，那么就是D-SACK\n如果SACK的第一个段的范围被SACK的第二个段覆盖，那么就是D-SACK\n\n* 示例一：ACK丢包\n\n下面的示例中，丢了两个ACK，所以，发送端重传了第一个数据包（3000-3499），于是接收端发现重复收到，于是回了一个SACK=3000-3500，因为ACK都到了4000意味着收到了4000之前的所有数据，所以这个SACK就是D-SACK——旨在告诉发送端我收到了重复的数据，而且我们的发送端还知道，数据包没有丢，丢的是ACK包。\n\n```\nTransmitted  Received    ACK Sent\nSegment      Segment     (Including SACK Blocks)\n \n3000-3499    3000-3499   3500 (ACK dropped)\n3500-3999    3500-3999   4000 (ACK dropped)\n3000-3499    3000-3499   4000, SACK=3000-3500\n```\n\n\n* 示例二: 网络延误\n\n下面的示例中，网络包（1000-1499）被网络给延误了，导致发送方没有收到ACK，而后面到达的三个包触发了“Fast Retransmit算法”，所以重传，但重传时，被延误的包又到了，所以，回了一个SACK=1000-1500，因为ACK已到了3000，所以，这个SACK是D-SACK——标识收到了重复的包。\n\n这个案例下，发送端知道之前因为“Fast Retransmit算法”触发的重传不是因为发出去的包丢了，也不是因为回应的ACK包丢了，而是因为网络延时了。\n\n```\nTransmitted    Received    ACK Sent\nSegment        Segment     (Including SACK Blocks)\n \n500-999        500-999     1000\n1000-1499      (delayed)\n1500-1999      1500-1999   1000, SACK=1500-2000\n2000-2499      2000-2499   1000, SACK=1500-2500\n2500-2999      2500-2999   1000, SACK=1500-3000\n1000-1499      1000-1499   3000\n               1000-1499   3000, SACK=1000-1500\n```\n\n* 优点\n1）可以让发送方知道，是发出去的包丢了，还是回来的ACK包丢了。\n\n2）是不是自己的timeout太小了，导致重传。\n\n3）网络上出现了先发的包后到的情况（又称reordering）\n\n4）网络上是不是把我的数据包给复制了。\n\n\n\n### 名词解释\n* msl ：max segment lifetime    tpc segment在网络上的存活时间\n* isn ：init sequence number    初始化序列数字\n* time_wait: 确保有足够时间让对端收到ack，一来一回两个msl ，因此超时设置为2*msl\n* FIN ：finish 表示关闭连接\n* tcp_max_tw_buckets ： time_wait的最大数量，默认为180000\n\n\n\n### 最佳实践\n#### 处理大负载连接\n调整三个TCP参数可供你选择，第一个是：tcp_synack_retries 可以用他来减少重试次数；第二个是：tcp_max_syn_backlog，可以增大SYN连接数；第三个是：tcp_abort_on_overflow 处理不过来干脆就直接拒绝连接了。\n\ntcp_tw_reuse和tcp_tw_recycle来解决TIME_WAIT的问题是非常非常危险的，因为这两个参数违反了TCP协议\n","tags":["tcp"],"categories":["internet"]},{"title":"设计模式之对象池模式","url":"%2F2018%2F07%2F20%2F%E5%AF%B9%E8%B1%A1%E6%B1%A0%E6%A8%A1%E5%BC%8F-2018-07-20%2F","content":"\n## 设计模式之对象池模式\n* 23中模式之外的新模式\n\n### 简介\n对象池模式就是依赖于内存中的对象池（在应用启动时进行初始化），通过循环使用对象，减少资源初始化、以及销毁的昂贵损耗！典型的例子是：线程池、连接池\n\n\n### 类图\n![对象池](/images/2018-07-19-3.png)\n<center>对象池</center>\n\n\n\n### 最佳实践\n只有在重复生成对象的操作成为影响性能的关键因素时，才适合进行对象池化，但是若池化带来性能提高并不显著或重要的话，建议放弃对象池化技术。\n\n\n### 代码\n```\npackage com.bj.hz.pool;\n\nimport java.util.HashMap;\nimport java.util.Map;\n\n/**\n * Created with hzz\n * Description:\n *\n * @author: huangzhe\n * @date: 2018-07-19\n * @time: 8:41 PM\n */\npublic abstract class Pool <T>{\n    private  Map<T,ObjectStatus> pool=new HashMap();\n\n    public Pool() {\n        pool.put(create(),new ObjectStatus());\n    }\n\n    public synchronized T checkout(){\n        for (T t:pool.keySet()){\n            if (!pool.get(t).isIsuse()){\n                pool.get(t).setIsuse(true);\n                return t;\n            }\n        }\n        return null;\n    }\n\n\n    public synchronized void checkIn(T t){\n        pool.get(t).setIsuse(false);\n    }\n\n    public abstract T create();\n\n    private static class ObjectStatus{\n        private boolean isuse;\n\n        public boolean isIsuse() {\n            return isuse;\n        }\n\n        public void setIsuse(boolean isuse) {\n            this.isuse = isuse;\n        }\n\n\n\n    }\n}\n```","tags":["设计模式"],"categories":["power design"]},{"title":"设计模式之规格模式","url":"%2F2018%2F07%2F19%2F%E8%A7%84%E6%A0%BC%E6%A8%A1%E5%BC%8F-2018-07-19%2F","content":"\n## 设计模式之规格模式\n* 23中模式之外的新模式\n\n### 简介\n在一系列对象中根据条件搜索！类似sql，但不同的是从内存中的对象进行搜索\n具体类似于LINQ（Language Integrated Query）语言集成查询\n\n### 初步实践\n> 1.创建一个接口，实现按照某种条件筛选：IUserProvider\n  2.实现以上接口:UserProvider，通过具体的对象类进行抽象方法的实现（例如：遍历实体类数组，进行判断，然后返回结果数组或列表）\n  3.实现具体对象，类似User实体类\n  4.实现场景类，初始化一个拥有User的数组或列表，实例化UserProvider，并使用相关方法，获取结果\n\n* 请注意以上实现，我们可以发现一旦业务发生变更，我们需要改对应的接口方法、需要实现对应的接口，很不容易进行扩展。\n\n* 第二种：那么我们是否可以将对应的搜索条件进行封装，创建一个接口：IUserSpecification，定义是否满足的方法，返回bool值，这样就可以在多种条件下（业务变更等），进行无缝扩展。只用实现该接口，就可以扩展多个条件类。\n\n* 对于类似于sql的多个条件查询下，在数据量大的情况下容易造成性能较差，因为需要经过好多轮循环\n\n* 第三种：可以知道一般条件组合，基本离不开与或非、这三种模式是固定的，我们可以通过这三种模式进行统一的条件封装。\n> 1.我们创建一个条件规格接口：IUserSpecification,实现判断是否满足，返回bool值\n  2.创建一个抽象类实现IUserSpecification：ComposionSpecificaiton，并且通过模板方法实现与或非三种条件规格的生成，具体接口的实现由具体类来实现。此抽象类依赖于具体的实现（请按照实际情况分析，不要死学）\n  3.继承ComposionSpecificaiton，实现具体的判断方法\n  4.在场景类中，通过条件规格的实现类，使用与或非方法对多个条件进行封装，然后进行计算\n\n#### 第三种方法最优，使用了组合模式、策略模式、模板模式这三种模式组合成了规格模式。\n\n### 类图\n\n![第二种类图](/images/2018-07-19-2.jpg)\n<center>第二种类图</center>\n\n![第三种类图](/images/2018-07-19-1.jpg)\n<center>第三种类图</center>\n\n\n### 以下为代码\n\n* 定义一个用户：\n```\npackage com.bj.hz.specification.very;\n\n/**\n * Created with hzz\n * Description:\n *\n * @author: huangzhe\n * @date: 2018-07-18\n * @time: 9:48 PM\n */\npublic class User {\n    private String name;\n    private int age;\n\n    public User(String name, int age) {\n        this.name = name;\n        this.age = age;\n    }\n\n    public String getName() {\n        return name;\n    }\n\n    public void setName(String name) {\n        this.name = name;\n    }\n\n    public int getAge() {\n        return age;\n    }\n\n    public void setAge(int age) {\n        this.age = age;\n    }\n\n    @Override\n    public String toString() {\n        return \"User{\" +\n                \"name='\" + name + '\\'' +\n                \", age=\" + age +\n                '}';\n    }\n}\n\n```\n* 定义一个查询提供类接口以及实现\n\n```\npackage com.bj.hz.specification.very;\n\n\nimport java.util.ArrayList;\n\n/**\n * Created with hzz\n * Description:\n *\n * @author: huangzhe\n * @date: 2018-07-18\n * @time: 10:07 PM\n */\npublic interface IUserProvider {\n    ArrayList<User> findUser(IUserSpecification specification);\n}\n\n```\n* 提供实现\n```\npackage com.bj.hz.specification.very;\n\n\n\nimport java.util.ArrayList;\n\n/**\n * Created with hzz\n * Description:\n *\n * @author: huangzhe\n * @date: 2018-07-18\n * @time: 10:09 PM\n */\npublic class UserProvider implements IUserProvider {\n\n    private ArrayList<User> users;\n\n    public UserProvider(ArrayList<User> users) {\n        this.users = users;\n    }\n\n    @Override\n    public ArrayList<User> findUser(IUserSpecification specification) {\n        ArrayList<User> result=new ArrayList<>();\n        for (User u:users){\n            if (specification.isSatisfiedBy(u)){\n                result.add(u);\n            }\n        }\n        return result;\n    }\n}\n\n```\n* 规格条件接口\n```\npackage com.bj.hz.specification.very;\n\n/**\n * Created with hzz\n * Description:为了适应未来变化的需求，将运算封装到接口之内\n *\n * @author: huangzhe\n * @date: 2018-07-18\n * @time: 10:02 PM\n */\npublic interface IUserSpecification {\n    public boolean isSatisfiedBy(User user);\n}\n\n```\n* 组合模式的接口，其实可以定义三个装饰器（请自行想象）分别实现 与或非\n```\npackage com.bj.hz.specification.very;\n\n/**\n * Created with hzz\n * Description:\n *\n * @author: huangzhe\n * @date: 2018-07-19\n * @time: 9:06 AM\n */\npublic abstract class AbstractComposition implements IUserSpecification {\n\n\n\n    public IUserSpecification and(IUserSpecification userSpecification){\n        return new AndSpecification(this,userSpecification);\n    }\n\n    public IUserSpecification or(IUserSpecification userSpecification){\n        return new OrSpecification(this,userSpecification);\n    }\n    public IUserSpecification not(IUserSpecification userSpecification){\n        return new NotSpecification(this);\n    }\n\n}\n\n```\n* 分别是与或非实现\n\n```\npackage com.bj.hz.specification.very;\n\n/**\n * Created with hzz\n * Description:\n *\n * @author: huangzhe\n * @date: 2018-07-19\n * @time: 9:08 AM\n */\npublic class AndSpecification extends AbstractComposition {\n\n    private IUserSpecification _left;\n    private IUserSpecification _right;\n\n    public AndSpecification(IUserSpecification _left, IUserSpecification _right) {\n        this._left = _left;\n        this._right = _right;\n    }\n\n    @Override\n    public boolean isSatisfiedBy(User user) {\n        return _left.isSatisfiedBy(user) && _right.isSatisfiedBy(user);\n    }\n}\n\n\n```\n\n```\npackage com.bj.hz.specification.very;\n\n/**\n * Created with hzz\n * Description:\n *\n * @author: huangzhe\n * @date: 2018-07-19\n * @time: 9:09 AM\n */\npublic class OrSpecification extends AbstractComposition {\n\n    private IUserSpecification _left;\n    private IUserSpecification _right;\n\n    public OrSpecification(IUserSpecification _left, IUserSpecification _right) {\n        this._left = _left;\n        this._right = _right;\n    }\n\n    @Override\n    public boolean isSatisfiedBy(User user) {\n        return _left.isSatisfiedBy(user) || _right.isSatisfiedBy(user);\n    }\n}\n\n```\n\n```\npackage com.bj.hz.specification.very;\n\n/**\n * Created with hzz\n * Description:\n *\n * @author: huangzhe\n * @date: 2018-07-19\n * @time: 9:10 AM\n */\npublic class NotSpecification extends AbstractComposition {\n\n    private IUserSpecification userSpecification;\n\n    public NotSpecification(IUserSpecification userSpecification) {\n        this.userSpecification = userSpecification;\n    }\n\n    @Override\n    public boolean isSatisfiedBy(User user) {\n        return !userSpecification.isSatisfiedBy(user);\n    }\n}\n\n```\n* 根据名称查询\n```\npackage com.bj.hz.specification.very;\n\n/**\n * Created with hzz\n * Description:\n *\n * @author: huangzhe\n * @date: 2018-07-19\n * @time: 9:29 AM\n */\npublic class FindByNameSpecification extends AbstractComposition {\n\n    private String name;\n\n    public FindByNameSpecification(String name) {\n        this.name = name;\n    }\n\n    @Override\n    public boolean isSatisfiedBy(User user) {\n        return user.getName().equals(name);\n    }\n}\n\n```\n* 根据大于给定的年龄查询\n```\npackage com.bj.hz.specification.very;\n\n/**\n * Created with hzz\n * Description:\n *\n * @author: huangzhe\n * @date: 2018-07-19\n * @time: 9:31 AM\n */\npublic class FindByAgeThanSpecification extends AbstractComposition {\n\n    private int age;\n\n    public FindByAgeThanSpecification(int age) {\n        this.age = age;\n    }\n\n    @Override\n    public boolean isSatisfiedBy(User user) {\n        return user.getAge()>age;\n    }\n}\n\n```\n\n* 场景类具体实现\n```\npackage com.bj.hz.specification.very;\n\n\n\n\nimport java.util.ArrayList;\n\n/**\n * Created with hzz\n * Description:\n *\n * @author: huangzhe\n * @date: 2018-07-18\n * @time: 10:12 PM\n */\npublic class Client {\n    public static void main(String[] args) {\n        ArrayList<User> users = new ArrayList<>();\n        users.add(new User(\"121\", 3));\n        users.add(new User(\"犁牛\", 10));\n        users.add(new User(\"测试\", 18));\n        users.add(new User(\"hah\", 16));\n        users.add(new User(\"黄啦啦\", 19));\n        users.add(new User(\"吴啦啦\", 20));\n        System.out.println(\"========年龄大于16的==========\");\n        IUserProvider userProvider=new UserProvider(users);\n        for (User user:userProvider.findUser(new FindByNameSpecification(\"hah\").and(new FindByAgeThanSpecification(14)))){\n            System.out.println(user);\n        }\n\n    }\n}\n\n```\n\n\n\n","tags":["设计模式"],"categories":["power design"]},{"title":"netty编解码","url":"%2F2018%2F07%2F17%2Fnetty-codec-2018-07-17%2F","content":"\n\n## 关于netty的编解码\n\n关于netty的编解码学习，一般涉及到数据的出站与入站，在出站时调用编码、在入站时调用解码，编解码都是成对出现，不能出现只有一个。\n\n### netty的编解码类别\n\nnetty的编解码类别主要分为以下三种\n\n* ByteToMessage 入站解码\n* MessageToByte 出站编码\n* MessageToMessage  出站入站均可（编解码）\n\n* 解码继承：ByteToMessageDecoder,该类继承ChannelInboundHandlerAdapter   该类为进站处理\n* 编码继承：MessageToByteEncoder，该类继承ChannelOutboundHandlerAdapter  该类为出站处理\n\n## 例子实现编解码用一个组合handler来表示编解码（前两种）\n\n```\n例如：\npackage com.bj.hz.dzj;\n\nimport io.netty.buffer.ByteBuf;\nimport io.netty.channel.ChannelDuplexHandler;\nimport io.netty.channel.ChannelHandlerContext;\nimport io.netty.channel.ChannelInboundHandlerAdapter;\nimport io.netty.channel.CombinedChannelDuplexHandler;\nimport io.netty.handler.codec.ByteToMessageDecoder;\nimport io.netty.handler.codec.MessageToByteEncoder;\nimport java.util.List;\n\npublic class MyCodec extends CombinedChannelDuplexHandler {\n\n    public MyCodec(){\n        super(new Mydecode(),new Myencode());\n    }\n\n}\n\nclass Mydecode extends ByteToMessageDecoder{\n\n\n    @Override\n    protected void decode(ChannelHandlerContext channelHandlerContext, ByteBuf byteBuf, List<Object> list) throws Exception {\n        //这种是需要判断字节数组的容量是否足够解码，请参考最后使用ReplayingDecoder\n        if (byteBuf.readableBytes()>4){\n            list.add(byteBuf.readInt());\n        }\n    }\n}\n\nclass Myencode extends MessageToByteEncoder<Integer>{\n\n    @Override\n    protected void encode(ChannelHandlerContext channelHandlerContext, Integer integer, ByteBuf byteBuf) throws Exception {\n        byteBuf.writeInt(integer);\n    }\n}\n\n```\n\n\n\n### 使用codec可以统一编解码（前两种）\n* 使用codec 实现编解码一体\n\n```\npackage com.bj.hz.dzj;\n\nimport io.netty.buffer.ByteBuf;\nimport io.netty.channel.ChannelHandlerContext;\nimport io.netty.handler.codec.ByteToMessageCodec;\nimport java.util.List;\n\npublic class Mycodec1 extends ByteToMessageCodec<Integer> {\n\n    @Override\n    protected void decode(ChannelHandlerContext channelHandlerContext, ByteBuf byteBuf, List list) throws Exception {\n        if (byteBuf.readableBytes()>4){\n            list.add(byteBuf.readInt());\n        }\n    }\n\n    @Override\n    protected void encode(ChannelHandlerContext channelHandlerContext, Integer integer, ByteBuf byteBuf) throws Exception {\n        byteBuf.writeInt(integer);\n    }\n}\n```\n\n### 使用codec实现第三种\n该类型主要实现编码中协议（例如api等）转换\n\n```\npublic class MyMessagetoMessage extends MessageToMessageCodec<Integer,String> {\n    @Override\n    protected void encode(ChannelHandlerContext channelHandlerContext, String s, List<Object> list) throws Exception {\n        list.add(Integer.parseInt(s));\n    }\n\n    @Override\n    protected void decode(ChannelHandlerContext channelHandlerContext, Integer integer, List<Object> list) throws Exception {\n        list.add(String.valueOf(integer));\n    }\n}\n```\n\n### 使用ReplayingDecoder,来实现自动转换，当bytebuf中没有能够转换的足够字节，则会一直等待足够才会转换\n\n```\npackage com.bj.hz.dzj;\n\nimport io.netty.buffer.ByteBuf;\nimport io.netty.channel.ChannelHandlerContext;\nimport io.netty.handler.codec.ReplayingDecoder;\nimport java.util.List;\n\npublic class MyreplyingDecoder extends ReplayingDecoder<Integer> {\n    @Override\n    protected void decode(ChannelHandlerContext channelHandlerContext, ByteBuf byteBuf, List<Object> list) throws Exception {\n        list.add(byteBuf.readInt());\n    }\n}\n```\n\n","tags":["netty"],"categories":["codec"]},{"title":"solr安装分词","url":"%2F2018%2F04%2F03%2Fsolr%E5%AE%89%E8%A3%85%E5%88%86%E8%AF%8D%2F","content":"\n* 环境 centos7\n### 下载solr\n`地址：http://www.apache.org/dyn/closer.lua/lucene/solr/7.2.1`\n\n#### 解压\n```bash\ntar -xvf solr-7.2.1.tgz\n\n```\n### 1. 直接使用solr\n```\ncd solrHome(solrHome是solr的路径)\ncd bin\nsolr start\n```\n#### 1.1. 创建core 或者collection 意义一致\n```bash\nsolr create -c articles\n控制台：http://127.0.0.1:8983/solr\n```\n\n#### 1.2. 创建分词器\n```bash\n下载地址：https://pan.baidu.com/s/1smOxPhF\n将解分词资料里的ik-analyzer-solr5-5.x.jar拷贝到你的solr目录下的\\server\\solr-webapp\\webapp\\WEB-INF\\lib目录中去，\n将IKAnalyzer.cfg.xml，mydict.dic（搜狗的扩展词库），stopword.dic放在你的solr目录下的\\server\\solr-webapp\\webapp\\WEB-INF\\classes目录中去\n\n\n修改 articles集合目录下的managed-schema\n\n添加以下4行：\n\n<fieldType name=\"text_ik\" class=\"solr.TextField\">  \n        <analyzer class=\"org.wltea.analyzer.lucene.IKAnalyzer\"/>  \n</fieldType>  \n\n\n重启或者reload\n\n```\n#### 1.3. 创建字段\n```\n{\n    \"add-field\" : {\n        \"name\" : \"name\",\n        \"type\" : \"text_ik\"\n    },\n    \"add-field\" : {\n        \"name\" : \"content\",\n        \"type\" : \"text_ik\",\n        \"stored\" : \"true\"\n    },\n    \"add-field\" : {\n        \"name\" : \"createTime\",\n        \"type\" : \"date\"\n    }\n}\n\npost提交：\nhttp://localhost:8983/solr/articles/schema\n```\n\n#### 1.4. 删除字段\n\n```\n{\n    \"delete-field\" : {\n        \"name\" : \"name\"\n    },\n    \"delete-field\" : {\n        \"name\" : \"content\"\n    }\n}\nhttp://localhost:8983/solr/articles/schema\n```\n\n\n### 2. 使用tomcat作为容器运行solr\n#### 2.1 新创建一个solr_home_new文件夹\n\n```\nexport solr_home=/app/solr-7.2.1\nexport solr_home_new=/app/solr_home\n\n复制 ${solr_home}/server/solr-webapp/webapp 并重命名 ${tomcat}/webapp/solr\ncp -r ${solr_home}/dist  ${solr_home_new}/\ncp ${solr_home}/server/lib/ext/*.jar ${tomcat}/webapp/solr/WEB-INF/lib/\ncp ${solr_home}/server/lib/*.jar ${tomcat}/webapp/solr/WEB-INF/lib/\n#classes文件夹没有自己创建\ncp ${solr_home}/server/resources/log4j.properties ${tomcat}/webapp/solr/WEB-INF/classes \n\n\n#进入 ${tomcat}/webapp/solr/WEB-INF/ 修改web.xml\n修改：修改中间为自己的solr_home_new，我的solr_home_new为solr_home/solr\n\n <env-entry>\n         <env-entry-name>solr/home</env-entry-name>\n         <env-entry-value>/Users/huangzhe/app/solr_home/solr</env-entry-value>\n         <env-entry-type>java.lang.String</env-entry-type>\n</env-entry>\n并注释以下，防止403：\n<!--  <security-constraint>\n    <web-resource-collection>\n      <web-resource-name>Disable TRACE</web-resource-name>\n      <url-pattern>/</url-pattern>\n      <http-method>TRACE</http-method>\n    </web-resource-collection>\n    <auth-constraint/>\n  </security-constraint>\n  <security-constraint>\n    <web-resource-collection>\n      <web-resource-name>Enable everything but TRACE</web-resource-name>\n      <url-pattern>/</url-pattern>\n      <http-method-omission>TRACE</http-method-omission>\n    </web-resource-collection>\n  </security-constraint>\n-->\n\n```\n\n\n#### 2.2 创建core\n```\ncp -r ${solr_home}/server/solr ${solr_home_new}/\ncd ${solr_home_new}/solr\nmkdir new_core\ncp -r configsets/_default/conf new_core\n\n打开浏览器：http://localhost:8080/solr/index.html\n点击：core Admin ,然后更改schema.xml为 managed-schema，点击确定\n```\n\n\n#### 2.3 添加分词器\n与1.2一致，在tomcat下面对应的路径去改\n","tags":["search"],"categories":["solr"]},{"title":"localtunnel server端搭建","url":"%2F2018%2F03%2F15%2Flocaltunnel-server%E7%AB%AF%E6%90%AD%E5%BB%BA%2F","content":"\n## localtunnel server\n### 下载程序\n> 以下地址为localtunnel server的git页面\n\n`https://github.com/localtunnel/server`\n\n> 下载安装\n\n* 前提：本机安装git、 nodejs \n* 有独立域名、独立主机（公网ip）\n\n```bash\n$ git clone  https://github.com/localtunnel/server.git\n$ cd localtunnel-server\n$ npm install\n```\n\n> 启动\n\n```bash\n# 直接使用\n$ bin/server --port 2000\n# 配合 pm2 使用\n$ pm2 start bin/server --name lt -- --port 2000\n```\n\n> server配合nginx使用\n\n* 配置如下：\n\n```nginx\nupstream server {\n\n                server 127.0.0.1:8099;\n        }\nmap $http_upgrade $connection_upgrade {\n    default upgrade;\n    ''      close;\n}\n\nserver {\n        listen 80 default_server;\n        server_name example.com;\n    location / {\n        proxy_pass http://server;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header Host $http_host;\n        proxy_set_header X-Forwarded-Proto http;\n        proxy_set_header X-NginX-Proxy true;\n     #  proxy_set_header Upgrade $http_upgrade;\n     #  proxy_set_header Connection $connection_upgrade;\n\n        proxy_redirect off;\n                }\n        }\n\n server {\n        listen       443 default_server ssl;\n        server_name  example.com;\n        ssl on;\n        ssl_certificate      /etc/letsencrypt/live/example.com/fullchain.pem;\n        ssl_certificate_key  /etc/letsencrypt/live/example.com/privkey.pem;\n\n        ssl_session_cache    shared:SSL:1m;\n        ssl_session_timeout  5m;\n\n        ssl_ciphers  HIGH:!aNULL:!MD5;\n        ssl_prefer_server_ciphers  on;\n\n        location / {\n\n        proxy_pass http://server/;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header Host $http_host;\n        proxy_set_header X-Forwarded-Proto https;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection $connection_upgrade;\n\n        proxy_set_header X-NginX-Proxy true;\n        proxy_redirect off;\n        }\n    }\n```\n\n\n> client端使用\n\n```bash\n# 安装client端\n$ npm i localtunnel -g\n# 使用localtunnel默认服务器启动本地监听8080端口\n$ lt --port 8080\n# 使用自己搭建的服务器启动监听本地8080端口\n$ lt -h http://example.com --port 8080\n# 指定二级域名启动监听\n$ lt -s ceshi -h http://example.com --port 8080 \n```\n\n\n","tags":["内网穿透"],"categories":["内网穿透"]},{"title":"读源码注意的东西","url":"%2F2018%2F02%2F06%2F%E8%AF%BB%E6%BA%90%E7%A0%81%E6%B3%A8%E6%84%8F%E7%9A%84%E4%B8%9C%E8%A5%BF%2F","content":"## 修改相关\n###### 2018/2/6  创建\n\n## 怎样读源码，该注意什么问题\n\n*前提：读懂源码的动机与原因是什么。*\n     *看下该项目的设计文档与架构图，宏观上对一些概念有些认识*\n     *从感兴趣的点设置断点、开始debug*\n\n\n* 了解语言\n* 了解设计模式\n* 了解命名习惯-统一规约\n* 是了解整体架构，而不是地毯式遍历每一行代码\n* 了解架构： 从上至下（要有层次感） 层级、每个层级由多个角色构成，角色的互动\n    系统如何初始化（为接下来的所有任务做准备）-> 系统的相关的其他系统（界面等||设定系统的边界）-> 系统如何反应事件-> 系统如何处理异常与错误\n\n","tags":["方法"],"categories":["java"]},{"title":"字符串反转","url":"%2F2018%2F02%2F05%2F%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8F%8D%E8%BD%AC%2F","content":"\n## 以下为字符串反转的几种方法\n\n### 遍历字符数组\n\n```java\n\n    public static void reverse3(String src){\n        if(src==null){\n            throw new IllegalArgumentException(src);\n        }\n        int length=src.length();\n        char[] srcChar=src.toCharArray();\n        for(int i=0;i<length/2;i++){\n            char temp=srcChar[i];\n            srcChar[i]=srcChar[length-i-1];\n            srcChar[length-i-1]=temp;\n        }\n        System.out.println(new String(srcChar));\n    }\n\n\n\n    public static void reverse1(String src){\n        if(src==null){\n            throw new IllegalArgumentException(src);\n        }\n        int length=src.length();\n        char[] dest=new char[length];\n        char[] srcChar=src.toCharArray();\n        for(int i=0;i<length;i++){\n            dest[i]=srcChar[length-i-1];\n        }\n        System.out.println(new String(dest));\n    }\n```\n\n### 递归\n\n```java\n public static String reverse4(String src){\n        if(src==null){\n            throw new IllegalArgumentException(src);\n        }\n        int length=src.length();\n        if(length<=1){\n            return src;\n        }\n        String left=src.substring(0,length/2);\n        String right=src.substring(length/2,length);\n        return reverse4(right)+reverse4(left);\n\n    }\n\n\n```\n\n### 使用StringBuffer\n\n```java\n\n public static void reverse2(String src){\n        if(src==null){\n            throw new IllegalArgumentException(src);\n        }\n        StringBuffer sb=new StringBuffer(src);\n        sb.reverse();\n        System.out.println(sb.toString());\n    }\n\n```","tags":["工具"],"categories":["java"]},{"title":"linux删除文件除过某个文件","url":"%2F2018%2F02%2F01%2Flinux%E5%88%A0%E9%99%A4%E6%96%87%E4%BB%B6%E9%99%A4%E8%BF%87%E6%9F%90%E4%B8%AA%E6%96%87%E4%BB%B6%2F","content":"\n### 使用rm \n> 删除除了file1 的文件\n\n\n\n```bash\nrm -fr !(file1)\n```\n\n\n### 使用find\n> 删除除了file1\n\n```bash\nfind ./* -not -name \"file1\" | xargs rm -fr\nfind ./* -not -name \"file1\" -exec rm -fr {} \\;\n```\n\n\n\n","tags":["find"],"categories":["shell"]},{"title":"linux下使用rsync快速删除大量文件","url":"%2F2018%2F01%2F31%2Flinux%E4%B8%8B%E4%BD%BF%E7%94%A8rsync%E5%BF%AB%E9%80%9F%E5%88%A0%E9%99%A4%E5%A4%A7%E9%87%8F%E6%96%87%E4%BB%B6%2F","content":"\n## 问题：快速删除一个文件夹下的大量文件？\n* 使用rm 大量文件会很慢，更大时并且会报错\n> 实际原理：遍历删除\n\n```bash\n$ rm -fr *\n```\n\n* 使用rsync删除\n> 实际原理：使用空文件夹替换要删除的文件夹\n\n\n\n```bash\n#建立新的空文件夹\n$ mkdir src\n#建立实际有很多文件的文件夹\n$ mkdir dest\n#模拟生成大量文件  900000个文件\n$ touch file{1..900000}\n#使用rsync删除\n# -r 包含文件夹 -l 符号链接 -p 权限 permission -t 保持文件修改时间 -D 特殊设备\n$ rsync --delete-before -rlptD src/ dest\n#或者(与上面一样的效果)\n$ rsync -a --delete-before --no-o --no-g src/ dest\n```\n","tags":["rsync"],"categories":["shell"]},{"title":"hexo安装部署教程","url":"%2F2018%2F01%2F30%2Fhexo%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2%E6%95%99%E7%A8%8B%2F","content":"##    建立一个\bgithubpage项目\n### 使用自定义域名访问博客的前提：\n> 有域名解析至你的github page 我的域名为：blog.wudd.top\n\n\n####   建立一个分支 hexo\n* hexo为项目管理分支，即hexo博客项目的主分支\n* master分支为博客展示页面的分支（\b建好项目即存在的分支）\n\n##  在本地 \bclone hexo 分支\n\n```bash\n#克隆hexo分支\n$ git clone -b hexo git地址\n#进入\b克隆好的项目\n$ cd 项目名\n```\n##  安装hexo 以及相关的主题\n```bash\n#全局安装hexo\n$ sudo npm install -g hexo-cli\n#初始化hexo\n$ hexo init .\n```\n####  编辑项目目录下的 _config.yml文件\n##### ps\n* site:为博客自定义\b内容\n* 主题theme：主题配置项为第四步安装的，默认为自带的，也可不修改\n* deploy:填写自己的githubpage地址，分支为master\n* url:填写自己的博客访问url\n```bash\n#编辑项目根目录下的配置文件，修改以下其他可不修改：\b\n$ vim _config.yml\n \n  5 # Site\n  6 title: Hzhe\n  7 subtitle: you...\n  8 description: blog java\n  9 author: hzz\n 10 language:\n 11 timezone:\n 12\n 13 # URL\n 14 ## If your site is put in a subdirectory, set url as 'http://yoursite.com/ch    ild' and root as '/child/'\n 15 url: http://blog.wudd.top\n 16 root: /\n 17 permalink: :year/:month/:day/:title/\n 18 permalink_defaults:\n# Extensions\n 73 ## Plugins: https://hexo.io/plugins/\n 74 ## Themes: https://hexo.io/themes/ \n 75 theme: hexo-theme-laughing\n 76\n 77 # Deployment\n 78 ## Docs: https://hexo.io/docs/deployment.html\n 79 deploy:\n 80   type: git\n 81   repo: https://github.com/fastZhe/fastZhe.github.io\n 82   branch: master\n\n```\n##  安装hexo相关的主题\n* signature:个人签名\n* author.head:个人头像\n* navication:菜单栏\n* copyright：建议都关闭\n* socail:社交媒体连接\n```bash\n#进入theme文件夹\n$ cd theme\n#安装主题（不是必须）\n$ npm install hexo-renderer-pug --save\n$ git clone git@github.com:BoizZ/hexo-theme-laughing.git\n#删除主题文件夹内的.git\n$ cd hexo-theme-laughing ; rm -fr .git\n#编辑主题配置文件\n$ vim _config.yml\n\n  6 page_background: http://callfiles.ueibo.com/hexo-theme-laughing/page_backgro    und.jpg\n  7 page_menu_button: dark\n  8 post_background: http://callfiles.ueibo.com/hexo-theme-laughing/post_backgro    und.jpg\n  9 post_menu_button: light\n 10 title_plancehold: 随笔\n 11 author:\n 12   head: https://tva3.sinaimg.cn/crop.0.0.750.750.180/cbe52eb6jw8ew3l78tj4qj2    0ku0kv75s.jpg\n 13   signature: 世界那么大，我想去看看。。。KEEP FIGHTING\n 14 navication:\n 15   - name: Github\n 16     link: https://github.com/fastZhe\n 17 # content\n 18 content_width: 800\n\n 21 social:\n 22   - name: Github\n 23     icon: github\n 24     link: https://github.com\n 25   - name: Weibo\n 26     icon: weibo\n 27     link: https://weibo.com/p/1005053420794550/home?from=page_100505&mod=TAB    &is_all=1\n\n # Copyright\n 33 copyright:\n 34   record: false\n 35   hexo: false\n 36   laughing: true\n```\n\n##  编辑githubpage 项目根目录下的.gitignore\n* 配置成以下：避免项目管理分支缺少相关目录\n* 推送至hexo分支\n```bash\n$ vim .gitignore\n\n.DS_Store\nThumbs.db\n*.log\n.deploy*/\n\n$ git add .gitignore \n$ git commit -m \"\"\n$ git push origin hexo\n```\n\n##  新建编辑CNAME 自动\b映射对应的域名\n* 填写自己访问的博客地址\n* ps 这个是我的域名，请换成自己的\n* 推送至hexo分支\n```bash\n$ vim source/CNAME\nblog.wudd.top\n\n$ git add . \n$ git commit -m \"\"\n$ git push origin hexo\n```\n\n\n##  发布博客以及推送操作\n```bash\n#新建博客\n$ hexo new \"博客名\"\nINFO  Created: ~/me/blog/fast/fastZhe.github.io/source/_posts/hexo安装部署教程.md\n#编辑博客\n$ vim ~/me/blog/fast/fastZhe.github.io/source/_posts/hexo安装部署教程.md\n#推送至远程项目目录进行保存分支为hexo（保存项目目录，多机操作）\n$ git add .\n$ git commit -m \"最新博客等。。。\"\n$ git push origin hexo\n#生成博客\n$ hexo g\n#本地预览（在本地验证博客是否有问题）,访问以下地址即可\n$ hexo server\n➜  fastZhe.github.io git:(hexo) ✗ hexo server\nINFO  Start processing\nINFO  Hexo is running at http://localhost:4000/. Press Ctrl+C to stop.\n\n#部署博客至githubpage\nhexo d\n```\n\n### 打开页面 \b你的域名，请尽情欣赏吧！！！\n","tags":["hexo"]},{"title":"Hello World","url":"%2F2018%2F01%2F30%2Fhello-world%2F","content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n<!--more-->\n\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/deployment.html)\n"}]