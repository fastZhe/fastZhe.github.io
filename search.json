[{"title":"tcp-socket-http区别","url":"/2018/08/01/tcp-socket-http区别-2018-8-1/","content":"\n\n### 简介\n这三个概念是很容易混淆的，我们将通过以下来阐述具体的区别\n\n### HTTP与socket、tcp的关系\n这是OSI（开放系统连接--open system interconnection）模型\n![osi](/images/internet/2018-8-1-3.png)\n\n\n这是三者的关系\n![tcp/http/socket](/images/internet/2018-8-1-4.png)\n\n\n\n### http 与tcp\nhttp是基于tcp的，客户端往服务端发送一个HTTP请求时第一步就是要建立与服务端的TCP连接，也就是先三次握手，“你好，你好，你好”。从HTTP 1.1开始支持持久连接，也就是一次TCP连接可以发送多次的HTTP请求。\n\n**总结**\nHTTP是基于tcp的，属于应用层协议\n\n### http 与socket\n\n由于通常情况下Socket(基于tcp)连接就是TCP连接，因此Socket连接一旦建立，通信双方即可开始相互发送数据内容，直到双方连接断开。但在实际网络应用中，客户端到服务器之间的通信往往需要穿越多个中间节点，例如路由器、网关、防火墙等，大部分防火墙默认会关闭长时间处于非活跃状态的连接而导致 Socket 连接断连，因此需要通过轮询告诉网络，该连接处于活跃状态。\n\n而HTTP连接使用的是“请求—响应”的方式，不仅在请求时需要先建立连接，而且需要客户端向服务器发出请求后，服务器端才能回复数据。\n\n很多情况下，需要服务器端主动向客户端推送数据，保持客户端与服务器数据的实时与同步。此时若双方建立的是Socket连接，服务器就可以直接将数据传送给客户端；若双方建立的是HTTP连接，则服务器需要等到客户端发送一次请求后才能将数据传回给客户端，因此，客户端定时向服务器端发送连接请求，不仅可以保持在线，同时也是在“询问”服务器是否有新的数据，如果有就将数据传给客户端。\n\n**总结**\nhttp协议是应用层的协义，有个比较形象的描述：HTTP是轿车，提供了封装或者显示数据的具体形式；Socket是发动机，提供了网络通信的能力。 \n\n### socket 与tcp/ip\n\n**总结**\nsocket本就是传输层tcp与udp的封装，不是协议，是编程接口，因此可以说tcp与udp的具体实现编程接口是由socket实现的\n\n\n\n\n### 总结\n\n用HTTP的情况：双方不需要时刻保持连接在线，比如客户端资源的获取、文件上传等。\n用Socket的情况：大部分即时通讯应用(QQ、微信)、聊天室等\n\n\n\n\n","tags":["socket"],"categories":["internet"]},{"title":"HTTP协议","url":"/2018/08/01/http协议学习-2018-8-1/","content":"\n\n### 简介\nHTTP 本质是位于OSI应用层的一种协议，全拼： hypertext transfer protocol 超文本传输协议（就是说什么数据格式都能传输）\n\n本质是 请求---响应\n\n### 请求\n由三部分组成：请求行、请求头、请求体\n\n如图：\n![osi](/images/internet/2018-8-1-1.png)\n\n\n\n#### 请求行\n第一行是请求行：\n请求方法（METHOD） 统一资源标识符（URI） HTTP版本号\n\n```\n请求方法： POST /GET /HEAD /PUT /DELETE\nURI：URI就是URL中排除掉HOST剩下的部分，也就是资源在服务器上的地址\nHTTP版本号目前主流是1.1\n```\n**区别**\n>HTTP 1.0需要使用keep-alive参数来告知服务器端要建立一个长连接，而HTTP1.1默认支持长连接。\n>HTTP2.0使用了多路复用的技术，做到同一个连接并发处理多个请求，而且并发请求的数量比HTTP1.1大了好几个数量级。\n>当然HTTP1.1也可以多建立几个TCP连接，来支持处理更多并发的请求，但是创建TCP连接本身也是有开销的\n>HTTP1.1不支持header数据的压缩，HTTP2.0使用HPACK算法对header的数据进行压缩，这样数据体积小了，在网络上传输就会更快。\n\n#### 请求头header\n```\nHost: 目标服务器的网络地址\n\nAccept: 让服务端知道客户端所能接收的数据类型，如text/html */*\n\nContent-Type: body中的数据类型，如application/json; charset=UTF-8\n\nAccept-Language: 客户端的语言环境，如zh-cn\n\nAccept-Encoding: 客户端支持的数据压缩格式，如gzip\n\nUser-Agent: 客户端的软件环境，我们可以更改该字段为自己客户端的名字，比如QQ music v1.11，比如浏览器Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) AppleWebKit/600.8.9 (KHTML, like Gecko) Maxthon/4.5.2\n\nConnection: keep-alive，该字段是从HTTP 1.1才开始有的，用来告诉服务端这是一个持久连接，“请服务端不要在发出响应后立即断开TCP连接”。关于该字段的更多解释将在后面的HTTP版本简介中展开。\n\nContent-Length: body的长度，如果body为空则该字段值为0。该字段一般在POST请求中才会有。\nCookie: 记录者用户信息的保存在本地的用户数据，如果有会被自动附上\n```\n\n#### 请求体\n真正需要发给服务端的数据，在使用POST-multipart上传请求中请求体就是上传文件的二进制NSData类型数据；在GET请求中请求体为空；在普通的POST请求中请求体就是一些表单数据。\n\n\n### 响应\n![osi](/images/internet/2018-8-1-2.png)\n\n\n\n#### 响应行\n包含HTTP版本号、状态码、状态码对应的英文名称\n\n**状态码对应的信息**\n```\n1XX：信息提示。不代表成功或者失败，表示临时响应，比如100表示继续，101表示切换协议\n\n2XX: 成功\n\n3XX: 重定向\n\n4XX:客户端错误，很有可能是客户端发生问题，如亲切可爱的404表示未找到文件，说明你的URI是有问题的，服务器机子上该目录是没有该文件的；414URI太长\n\n5XX: 服务器错误，比如504网关超时\n```\n\n#### 响应头与响应体\n与请求头与请求体基本一致，除却一些字段\n\n### HTTP版本差异\n\nHTTP 1.1之前\n```\n不支持持久连接。一旦服务器对客户端发出响应就立即断开TCP连接(频繁创建会话费资源、影响性能)\n\n无请求头跟响应头\n\n客户端的前后请求是同步的。下一个请求必须等上一个请求从服务端拿到响应后才能发出，有点类似多线程的同步机制。（异步会走多线程，快捷）\n```\nHTTP 1.1(主流版本)\n```\n与1.1之前的版本相比，做了以下性能上的提升\n\n增加请求头跟响应头\n\n支持持久连接。客户端通过请求头中指定Connection为keep-alive告知服务端不要在完成响应后立即释放连接。HTTP是基于TCP的，在HTTP 1.1中一次TCP连接可以处理多次HTTP请求\n\n客户端不同请求之间是异步的。下一个请求不必等到上一个请求回来后再发出，而可以连续发出请求，有点类似多线程的异步处理。\n```\n\nHTTP 2.0\n```\n本着向下兼容的原则，1.1版本有的特性2.0都具备，也使用相同的API。但是2.0将只用于https网址。\n```\n\n\n\n\n\n\n\n\n","tags":["http"],"categories":["http"]},{"title":"socket","url":"/2018/08/01/socket知识-2018-8-1/","content":"\n\n\n\n### socket的概念\n\n套接字（socket）是通信的基石，是支持TCP/IP协议的网络通信的基本操作单元。它是网络通信过程中端点的抽象表示，包含进行网络通信必须的五种信息：连接使用的协议，本地主机的IP地址，本地进程的协议端口，远地主机的IP地址，远地进程的协议端口。\n\n应用层通过传输层进行数据通信时，TCP会遇到同时为多个应用程序进程提供并发服务的问题。多个TCP连接或多个应用程序进程可能需要通过同一个TCP协议端口传输数据。为了区别不同的应用程序进程和连接，许多计算机操作系统为应用程序与TCP／IP协议交互提供了套接字(Socket)接口。应用层可以和传输层通过Socket接口，区分来自不同应用程序进程或网络连接的通信，实现数据传输的并发服务。\n\n\n创建Socket连接时，可以指定使用的传输层协议，Socket可以支持不同的传输层协议（TCP或UDP），当使用TCP协议进行连接时，该Socket连接就是一个TCP连接。\n\nsocket则是对TCP/IP协议的封装和应用（程序员层面上）。也可以说，TPC/IP协议是传输层协议，主要解决数据 如何在网络中传输，而HTTP是应用层协议，主要解决如何包装数据。关于TCP/IP和HTTP协议的关系，网络有一段比较容易理解的介绍：\n```\n我们在传输数据时，可以只使用（传输层）TCP/IP协议，但是那样的话，如 果没有应用层，便无法识别数据内容，如果想要使传输的数据有意义，则必须使用到应用层协议，应用层协议有很多，比如HTTP、FTP、TELNET等，也可以自己定义应用层协议。WEB使用HTTP协议作应用层协议，以封装HTTP文本信息，然后使用TCP/IP做传输层协议将它发到网络上。\n```\n\n\n我们平时说的最多的socket是什么呢，实际上socket是对TCP/IP协议的封装，Socket本身并不是协议，而是一个调用接口\n（API），通过Socket，我们才能使用TCP/IP协议。 实际上，Socket跟TCP/IP协议没有必然的联系。Socket编程接\n口在设计的时候，就希望也能适应其他的网络协议。所以说，Socket的出现 只是使得程序员更方便地使用TCP/IP协议栈而已，是对TCP/IP协议的抽象，从而形成了我们知道的一些最基本的函数接口，比如create、 listen、connect、accept、send、read和write等等\n\n\n**总结**\nsocket是基于tcp、udp协议的抽象，是编程的接口,socket不是协议，socket既可以基于tcp（有状态、连接），也可以基于UDP（无状态连接）\n","tags":["socket"],"categories":["socket"]},{"title":"Tcp学习-下","url":"/2018/07/25/tcp学习下-2018-07-26/","content":"\n\n### 简介\ntcp要解决一个很大的事情，就是要在一个网络根据不同的情况来动态调整自己的发包速度---小则让自己更稳定，大则让整个网络更稳定\n\n\n### tcp的rtt算法\ntimeout 太大->重发慢->丢了半天重发-> 没效率->性能差\n\ntimeout 太小->可能没有丢就重发->重发就快、增加网络拥堵，导致更多超时 (恶性循环导致更多重发)\n\n* RTT：round trip time 就是一个数据包从发出去到回来的时间。这样发送端就可以设置RTO\n* RTO：retransmission timeout 重传超时\n* SRTT：smoothed RTT 平滑RTT\n\n\n### tcp滑动窗口\ntcp必须解决的可靠传输以及包乱序问题，所以tcp必须知道网络实际的数据处理带宽或者数据处理的速度，这样才不会引起网络拥塞，导致丢包\n\n所以tcp，引入了一些技术做网络流控，sliding window是其中的一个技术，tcp里面有一个字段叫做window，又叫Advertised-window,这个字段是接收端告诉发送端自己还有多少缓冲区可以接收数据。于是发送端就可以根据这个接收端的处理能力发送数据，而不会导致接收端处理不过来。\n\n#### Zero Window\n接收端可能没有多余的窗口了，那么当恢复到足够的窗口大小时，怎么通知发送端呢？ \n\n解决这个问题使用了Zero Window Probe，缩写为zwp，也就是说，发送端在窗口的值变成0后，会发zwp的包给接收方，让接收方来ack他的window，一般这个值会设置3次，第三次大约30-60s，如果3次过后还是0的话，tcp就会发RST把连接断掉\n\n#### Silly Window Syndrome\n糊涂窗口综合征，接收方太忙了，来不及取走Receive window里的数据，那么，会导致发送方越来越小，到最后，如果接收方有几个字节并告诉发送方，那么发送方会义无反顾发送几个字节。\n\n* MTU：以太网 MTU是1500字节，出去TCP+IP头的40个字节，真正的数据传输为1460，这就是MSS，Maximum Transmission Unit，MTU\n* MSS：max segment size 最大tcp包大小\n\n\n\n### TCP的拥塞处理 – Congestion Handling\nTCP不是一个自私的协议，当拥塞发生的时候，要做自我牺牲。就像交通阻塞一样，每个车都应该把路让出来，而不要再去抢路了\n\n拥塞处理的四种算法：\n\n1）慢启动，2）拥塞避免，3）拥塞发生，4）快速恢复\n\n首先，我们来看一下TCP的慢热启动。慢启动的意思是，刚刚加入网络的连接，一点一点地提速，不要一上来就像那些特权车一样霸道地把路占满。新同学上高速还是要慢一点，不要把已经在高速上的秩序给搞乱了。\n\n#### 慢启动的算法如下(cwnd全称Congestion Window)：\n\n1）连接建好的开始先初始化cwnd = 1，表明可以传一个MSS大小的数据。\n\n2）每当收到一个ACK，cwnd++; 呈线性上升\n\n3）每当过了一个RTT，cwnd = cwnd*2; 呈指数让升\n\n4）还有一个ssthresh（slow start threshold），是一个上限，当cwnd >= ssthresh时，就会进入“拥塞避免算法”（后面会说这个算法）\n\n所以，我们可以看到，如果网速很快的话，ACK也会返回得快，RTT也会短，那么，这个慢启动就一点也不慢。下图说明了这个过程。\n\n\n\n#### 拥塞避免算法 – Congestion Avoidance\n前面说过，还有一个ssthresh（slow start threshold），是一个上限，当cwnd >= ssthresh时，就会进入“拥塞避免算法”。一般来说ssthresh的值是65535，单位是字节，当cwnd达到这个值时后，算法如下：\n\n1）收到一个ACK时，cwnd = cwnd + 1/cwnd\n\n2）当每过一个RTT时，cwnd = cwnd + 1\n\n这样就可以避免增长过快导致网络拥塞，慢慢的增加调整到网络的最佳值。很明显，是一个线性上升的算法。\n\n\n前面我们说过，当丢包的时候，会有两种情况：\n\n1）等到RTO超时，重传数据包。TCP认为这种情况太糟糕，反应也很强烈。\n```\nsshthresh =  cwnd /2\ncwnd 重置为 1\n进入慢启动过程\n2）Fast Retransmit算法，也就是在收到3个duplicate ACK时就开启重传，而不用等到RTO超时。\n\nTCP Tahoe的实现和RTO超时一样。\nTCP Reno的实现是：\ncwnd = cwnd /2\nsshthresh = cwnd\n进入快速恢复算法——Fast Recovery\n上面我们可以看到RTO超时后，sshthresh会变成cwnd的一半，这意味着，如果cwnd<=sshthresh时出现的丢包，那么TCP的sshthresh就会减了一半，然后等cwnd又很快地以指数级增涨爬到这个地方时，就会成慢慢的线性增涨。我们可以看到，TCP是怎么通过这种强烈地震荡快速而小心得找到网站流量的平衡点的。\n```\n\n#### 快速恢复算法 – Fast Recovery\nTCP Reno\n\n这个算法定义在RFC5681。快速重传和快速恢复算法一般同时使用。快速恢复算法是认为，你还有3个Duplicated Acks说明网络也不那么糟糕，所以没有必要像RTO超时那么强烈。 注意，正如前面所说，进入Fast Recovery之前，cwnd 和 sshthresh已被更新：\n```\ncwnd = cwnd /2\nsshthresh = cwnd\n然后，真正的Fast Recovery算法如下：\n\ncwnd = sshthresh  + 3 * MSS （3的意思是确认有3个数据包被收到了）\n重传Duplicated ACKs指定的数据包\n如果再收到 duplicated Acks，那么cwnd = cwnd +1\n如果收到了新的Ack，那么，cwnd = sshthresh ，然后就进入了拥塞避免的算法了。\n如果你仔细思考一下上面的这个算法，你就会知道，上面这个算法也有问题，那就是——它依赖于3个重复的Acks。注意，3个重复的Acks并不代表只丢了一个数据包，很有可能是丢了好多包。但这个算法只会重传一个，而剩下的那些包只能等到RTO超时，于是，进入了恶梦模式——超时一个窗口就减半一下，多个超时会超成TCP的传输速度呈级数下降，而且也不会触发Fast Recovery算法了。\n\n通常来说，正如我们前面所说的，SACK或D-SACK的方法可以让Fast Recovery或Sender在做决定时更聪明一些，但是并不是所有的TCP的实现都支持SACK（SACK需要两端都支持），所以，需要一个没有SACK的解决方案。而通过SACK进行拥塞控制的算法是FACK（后面会讲）\n```\n","tags":["tcp"],"categories":["tcp"]},{"title":"Tcp名词解析","url":"/2018/07/25/tcp名词解析-2018-07-25/","content":"\n### 简介\n主要介绍一些tcp的专业名词以及相关的含义\n\n#### 在TCP层，有个FLAGS字段，这个字段有以下几个标识：SYN, FIN, ACK, PSH, RST, URG.\n\n\n* SYN表示建立连接\n\n* FIN表示关闭连接\n\n* ACK表示响应\n\n* PSH表示有 DATA数据传输\n\n* RST表示连接重置\n\n\n> 其中，ACK是可能与SYN，FIN等同时使用的，比如SYN和ACK可能同时为1，它表示的就是建立连接之后的响应，\n> 如果只是单个的一个SYN，它表示的只是建立连接。\n> TCP的几次握手就是通过这样的ACK表现出来的。\n> 但SYN与FIN是不会同时为1的，因为前者表示的是建立连接，而后者表示的是断开连接。\n> RST一般是在FIN之后才会出现为1的情况，表示的是连接重置。\n> 一般地，当出现FIN包或RST包时，我们便认为客户端与服务器端断开了连接；而当出现SYN和SYN＋ACK包时，我们认为客户端与服务器建立了一个连接。\n> PSH为1的情况，一般只出现在 DATA内容不为0的包中，也就是说PSH为1表示的是有真正的TCP数据包内容被传递。\n\n\n#### 重传的相关名词\n\n* 处理大负载连接的名词\n```\ntcp_synack_retries   ： 可以用他来减少重试次数\ntcp_max_syn_backlog  ： 可以增大SYN连接数\ntcp_abort_on_overflow： 处理不过来干脆就直接拒绝连接了\n```\n\n* 相关注意的\n\n```\nISN ：init sequence number 初始化序列码\n\nMSL ： max segment lifetime 最大tcp segment存活时间\n\nTIME_WAIT： 为主动关闭方的tcp状态机的状态\n主要有两个原因：1）TIME_WAIT确保有足够的时间让对端收到了ACK，如果被动关闭的那方没有收到Ack，就会触发被动端重发Fin，一来一去正好2个MSL，2）有足够的时间让这个连接不会跟后面的连接混在一起\n\ntcp_tw_reuse：官方文档上说tcp_tw_reuse 加上tcp_timestamps（又叫PAWS, for Protection Against Wrapped Sequence Numbers）可以保证协议的角度上的安全，但是你需要tcp_timestamps在两边都被打开\n\ntcp_tw_recycle：如果是tcp_tw_recycle被打开了话，会假设对端开启了tcp_timestamps，然后会去比较时间戳，如果时间戳变大了，就可以重用。但是，如果对端是一个NAT网络的话（如：一个公司只用一个IP出公网）或是对端的IP被另一台重用了，这个事就复杂了。建链接的SYN可能就被直接丢掉了\n\ntcp_max_tw_buckets：这个是控制并发的TIME_WAIT的数量，默认值是180000，如果超限，那么，系统会把多的给destory掉，然后在日志里打一个警告（如：time wait bucket table overflow），官网文档说这个参数是用来对抗DDoS攻击的。\n\nFast Retransmit ：快速重传机制，当对端没有收到对应的包时，对端会发送三次一样的ack，我们可以通过发送的这种机制，重传丢失的segment\n\nSACK ：Selective Acknowledgment (SACK)，主要是对端接收到的数据块，可以让己方发现哪些没有收到\n\nD-ACK:Duplicate SACK – 重复收到数据的问题,其主要使用了SACK来告诉发送方有哪些数据被重复接收了。\n如果SACK的第一个段的范围被ACK所覆盖，那么就是D-SACK\n如果SACK的第一个段的范围被SACK的第二个段覆盖，那么就是D-SACK\n\n```\n\n\n\nTCP的连接建立和连接关闭，都是通过请求－响应的模式完成的。\n\n### 概念补充-TCP三次握手：\n\nTCP(Transmission Control Protocol)传输控制协议\n\nTCP是主机对主机层的传输控制协议，提供可靠的连接服务，采用三次握手确认建立一个连接：\n\n位码即tcp标志位，有6种标示：SYN(synchronous建立联机) ACK(acknowledgement 确认) PSH(push传送) FIN(finish结束) RST(reset重置) URG(urgent紧急)Sequence number(顺序号码) Acknowledge number(确认号码)\n\n```\n第一次握手：主机A发送位码为syn＝1，随机产生seq number=1234567的数据包到服务器，主机B由SYN=1知道，A要求建立联机；\n第二次握手：主机B收到请求后要确认联机信息，向A发送ack number=(主机A的seq+1)，syn=1，ACK=1，随机产生seq=7654321的包；\n第三次握手：主机A收到后检查ack number是否正确，即第一次发送的seq number+1，以及位码ACK是否为1，若正确，主机A会再发送ack number=(主机B的seq+1)，ACK=1，主机B收到后确认seq值与ACK=1则连接建立成功。\n\n完成三次握手，主机A与主机B开始传送数据。\n\n\n在TCP/IP协议中，TCP协议提供可靠的连接服务，采用三次握手建立一个连接。\n第一次握手：建立连接时，客户端发送syn包(syn=j)到服务器，并进入SYN_SEND状态，等待服务器确认；\n第二次握手：服务器收到syn包，必须确认客户的SYN（ack=j+1），同时自己也发送一个SYN包（syn=k），即SYN+ACK包，此时服务器进入SYN_RECV状态；\n第三次握手：客户端收到服务器的SYN＋ACK包，向服务器发送确认包ACK(ack=k+1)，此包发送完毕，客户端和服务器进入ESTABLISHED状态，完成三次握手。完成三次握手，客户端与服务器开始传送数据.\n```\n\n### 概念补充-TCP四次挥手：\n* 以客户端主动挥手为例\n```\n第一次挥手：客户端发送fin=1 ,seq=x,ack=y，此时客户端状态为fin_wait1,等待服务器确认\n第二次挥手：服务端接收后，先发送ack=x+1，此时服务端状态进入close_wait,客户端接收后状态进入fin_wait2\n第三次挥手：服务端发送fin=1,seq=y+1,此时服务端状态进入last_ack，客户端接收后进入time_wait\n第四次挥手：客户端接收到上面两个后，发送ack=y+2,服务端收到后会关闭;\n\n客户端time_wait状态等待timeout时间后，才会释放关闭\n```\n\n* 客户端与服务端同时关闭\n```\n第一次与第二次挥手同时进行\n1.客户端与服务端同时发送fin,seq,ack,两者接收后，此时客户端与服务端同时进入fin_wait1,等待对方确认\n2.客户端与服务端同时发送ack,两者接收后同时进入time_wait\n\n两者都在time_wait状态等待timeout时间后，才会释放关闭\n```\n\n\n\n\n\n\n\n\n\n","tags":["tcp"],"categories":["tcp"]},{"title":"设计模式之空对象模式","url":"/2018/07/23/空对象模式-2018-07-23/","content":"\n## 设计模式之空对象模式\n* 23中模式之外的新模式\n\n### 简介\n通过实现一个默认的无意义对象类避免null值实现\n\n### 最佳实践\n* 就是指定默认的一个映射对象，方法不实现，默认为空，与实际对象实现同一个接口，这样在源头中解决null值\n* 使用类似于Option这样的对象，获取时判断有值没，再获取\n","tags":["空对象模式"],"categories":["power design"]},{"title":"设计模式之黑板模式","url":"/2018/07/22/黑板模式-2018-07-22/","content":"\n## 设计模式之黑板模式\n* 23中模式之外的新模式\n\n### 简介\n黑板模式是观察者模式的一个扩展，允许消息的读写同时进行，广泛地交互消息\n就像一个黑板，任何一个老师都可以写东西，同学都可以看东西，在时间上和空间上彻底解耦\n\n\n### 示意图\n![黑板模式示意图](/images/designPatterns/2018-07-22-1.png)\n<center>黑板模式示意图</center>\n\n### 最佳实践\n* 使用数据库作为黑板，大量消息访问下回影响性能。\n* 使用消息队列作为黑板，订阅发布式\n\n> 消息队列：使用推模式、拉模式实现，具体请参考一些消息队列，kafka\n\n","tags":["黑板模式"],"categories":["power design"]},{"title":"设计模式之雇工模式","url":"/2018/07/21/雇工模式-2018-07-21/","content":"\n## 设计模式之雇工模式\n* 23中模式之外的新模式\n\n### 简介\n雇工模式也叫做仆人模式：雇工模式是行为模式的一种，它为一组类提供通用的功能，而不需要类实现这些功能，他是命令模式的一种扩展。\n> 类似于厨师、裁缝、园丁等都是一组类，具有清洁的能力，但是我们并没有实现，使用雇工模式，就是简化版的命令模式。让被服务对象实现具体的方法，使用雇工来干活\n\n### 类图\n![雇工模式示意图](/images/designPatterns/2018-07-19-4.png)\n<center>雇工模式示意图</center>\n\n### 代码\n\n具有一组能力的对象，以及对应对象的实现\nIserviced\n```\npackage com.bj.hz.hire;\n\n/**\n * Created with hzz\n * Description:\n *\n * @author: huangzhe\n * @date: 2018-07-19\n * @time: 9:08 PM\n */\npublic interface Iserviced {\n    public void cleaned();\n}\n\n\npackage com.bj.hz.hire;\n\n/**\n * Created with hzz\n * Description:\n *\n * @author: huangzhe\n * @date: 2018-07-19\n * @time: 9:15 PM\n */\npublic class Garden implements Iserviced {\n    @Override\n    public void cleaned() {\n        System.out.println(\"花园被打扫了\");\n    }\n}\n\n\n\npackage com.bj.hz.hire;\n\n/**\n * Created with hzz\n * Description:\n *\n * @author: huangzhe\n * @date: 2018-07-19\n * @time: 9:17 PM\n */\npublic class Kitchen implements Iserviced {\n    @Override\n    public void cleaned() {\n        System.out.println(\"厨房被打扫了\");\n    }\n}\n\n\n```\n\n雇工 Servant\n```\npackage com.bj.hz.hire;\n\n/**\n * Created with hzz\n * Description:\n *\n * @author: huangzhe\n * @date: 2018-07-19\n * @time: 9:14 PM\n */\npublic class ServantHire {\n    public void clean(Iserviced serviced){\n        serviced.cleaned();\n    }\n}\n```\n\n场景类\nCient\n```\npackage com.bj.hz.hire;\n\n/**\n * Created with hzz\n * Description:\n *\n * @author: huangzhe\n * @date: 2018-07-19\n * @time: 9:15 PM\n */\npublic class Client {\n    public static void main(String[] args) {\n\n    }\n}\n```\n\n\n\n","tags":["雇工模式"],"categories":["power design"]},{"title":"设计模式之对象池模式","url":"/2018/07/20/对象池模式-2018-07-20/","content":"\n## 设计模式之对象池模式\n* 23中模式之外的新模式\n\n### 简介\n对象池模式就是依赖于内存中的对象池（在应用启动时进行初始化），通过循环使用对象，减少资源初始化、以及销毁的昂贵损耗！典型的例子是：线程池、连接池\n\n\n### 类图\n![对象池](/images/2018-07-19-3.png)\n<center>对象池</center>\n\n\n\n### 最佳实践\n只有在重复生成对象的操作成为影响性能的关键因素时，才适合进行对象池化，但是若池化带来性能提高并不显著或重要的话，建议放弃对象池化技术。\n\n\n### 代码\n```\npackage com.bj.hz.pool;\n\nimport java.util.HashMap;\nimport java.util.Map;\n\n/**\n * Created with hzz\n * Description:\n *\n * @author: huangzhe\n * @date: 2018-07-19\n * @time: 8:41 PM\n */\npublic abstract class Pool <T>{\n    private  Map<T,ObjectStatus> pool=new HashMap();\n\n    public Pool() {\n        pool.put(create(),new ObjectStatus());\n    }\n\n    public synchronized T checkout(){\n        for (T t:pool.keySet()){\n            if (!pool.get(t).isIsuse()){\n                pool.get(t).setIsuse(true);\n                return t;\n            }\n        }\n        return null;\n    }\n\n\n    public synchronized void checkIn(T t){\n        pool.get(t).setIsuse(false);\n    }\n\n    public abstract T create();\n\n    private static class ObjectStatus{\n        private boolean isuse;\n\n        public boolean isIsuse() {\n            return isuse;\n        }\n\n        public void setIsuse(boolean isuse) {\n            this.isuse = isuse;\n        }\n\n\n\n    }\n}\n```","tags":["设计模式"],"categories":["power design"]},{"title":"Tcp学习_上","url":"/2018/07/20/tcp学习上-2018-07-24/","content":"\n> 本文主要参考、copy陈皓老师的tcp那些事儿，再此谢谢陈皓老师\n\n\n### 简介\ntcp在网络OSI的七层模型中第四层--transport层，ip在第三层--network层，Arp在第二层--data link层，在第二层的数据，我们叫Frame，在第三层的数据我们叫Packet，第四层的数据叫segment\n\n### 数据流向\n数据 -> tcp(segment) -> ip(packet) -> data link(frame) \n每个层解析自己的协议，数据交给上层\n\n\n### Tcp头格式\n![tcp头部](/images/tcp/tcp-header01.png)\n\n<center>tcp头部</center>\n\n* tcp头部没有ip地址\b，那个是ip层的事，tcp包含源端口、与目标端口\n\n> 一个tcp连接需要源ip、目标ip、源端口、目标端口、\b以及协议才能表示同一个连接\n* sequence number:包序号，解决网络包乱序问题\n* acknowledgement number: 就是ack，用来确认收到消息，解决不丢包的问题\n* window ：advertised-window ，滑动窗口，解决流控\n* tcp flag：包类型，操控tcp的状态机\n\n![tcp头部其他定义](/images/tcp/tcp-header02.png)\n<center>tcp头部其他定义</center>\n\n### tcp的状态机\n网络上的传输是没有连接的，包括TCP也是一样的。而TCP所谓的“连接”，其实只不过是在通讯的双方维护一个“连接状态”，让它看上去好像有连接一样。所以，TCP的状态变换是非常重要的\n\n![tcp状态机](/images/tcp/tcp-fsm.png)\n<center>tcp状态机</center>\n\n![tcp开始关闭示意图](/images/tcp/tcp-open-close.jpg)\n<center>tcp开始关闭示意图</center>\n\n\n#### tcb\n在网络传输层，tcp模块中有一个tcb（传输控制模块，transmit control block），它用于记录tcp协议运行过程中的 变量。对于有多个连接的tcp，每个连接都有一个tcb。tcb结构的定义包括这个连接使用 的源端口、目的端口、目的ip、序号、应答序号、对方窗口大小、己方窗口大小、tcp状态、top输入/输出队列、应用层输出队列、tcp的重传有关变量。\n\n\n#### 对于建链接的3次握手\n主要是要初始化Sequence Number 的初始值。通信的双方要互相通知对方自己的初始化的Sequence Number（缩写为ISN：Inital Sequence Number）——所以叫SYN，全称Synchronize Sequence Numbers。也就上图中的 x 和 y。这个号要作为以后的数据通信的序号，以保证应用层接收到的数据不会因为网络上的传输的问题而乱序（TCP会用这个序号来拼接数据）。\n#### 对于4次挥手\n其实你仔细看是2次，因为TCP是全双工的，所以，发送方和接收方都需要Fin和Ack。只不过，有一方是被动的，所以看上去就成了所谓的4次挥手。如果两边同时断连接，那就会就进入到CLOSING状态，然后到达TIME_WAIT状态。下图是双方同时断连接的示意图（你同样可以对照着TCP状态机看）\n\n![tcp同步关闭示意图](/images/tcp/tcp-closesimul.png)\n<center>tcp同步关闭示意图</center>\n\n\n\n### tcp重传机制\n#### 超时重传机制\n不回ack，死等，当发现方发现收不到ack的超时后，会重传3，有严重的性能问题，会导致多次重传\n\n#### 快速重传机制\ntcp引入了一种叫做fast retransmit的算法，以数据为驱动，不以时间为驱动，解决了timeout的问题\n> 如果某个包没有连续到达，就ack最后那个可能被丢了的包，如果发送方连续收到三次相同的ack，就重传--好处是不用等到timeout再重传\n\n##### 问题\n如果发送发送多个对端，发现三次的ack传来，并不知道是一个对端、还是三个对端，这个时候，是重传丢失的，还是丢失后的都要传\n\n#### sack方法\nSelective Acknowledgment (SACK)，在tcp头里面加入sack的东西，ACK还是Fast Retransmit的ACK，SACK则是汇报收到的数据碎版\n这个协议需要两边都支持，因此在 Linux下，可以通过tcp_sack参数打开这个功能（Linux 2.4后默认打开\n\n![tcp-Sack](/images/tcp/tcp-sack_example.jpg)\n<center>tcp-Sack示意图</center>\n\n##### 问题\n* 问题——接收方Reneging\n所谓Reneging的意思就是接收方有权把已经报给发送端SACK里的数据给丢了。这样干是不被鼓励的，因为这个事会把问题复杂化了，但是，接收方这么做可能会有些极端情况，比如要把内存给别的更重要的东西。所以，发送方也不能完全依赖SACK，还是要依赖ACK，并维护Time-Out，如果后续的ACK没有增长，那么还是要把SACK的东西重传，另外，接收端这边永远不能把SACK的包标记为Ack。\n\n* 问题——性能问题\nSACK会消费发送方的资源，试想，如果一个攻击者给数据发送方发一堆SACK的选项，这会导致发送方开始要重传甚至遍历已经发出的数据，这会消耗很多发送端的资源。\n\n#### Duplicate SACK – 重复收到数据的问题\nLinux下的tcp_dsack参数用于开启这个功能（Linux 2.4后默认打开）\n\nD-SACK使用了SACK的第一个段来做标志，\n如果SACK的第一个段的范围被ACK所覆盖，那么就是D-SACK\n如果SACK的第一个段的范围被SACK的第二个段覆盖，那么就是D-SACK\n\n* 示例一：ACK丢包\n\n下面的示例中，丢了两个ACK，所以，发送端重传了第一个数据包（3000-3499），于是接收端发现重复收到，于是回了一个SACK=3000-3500，因为ACK都到了4000意味着收到了4000之前的所有数据，所以这个SACK就是D-SACK——旨在告诉发送端我收到了重复的数据，而且我们的发送端还知道，数据包没有丢，丢的是ACK包。\n\n```\nTransmitted  Received    ACK Sent\nSegment      Segment     (Including SACK Blocks)\n \n3000-3499    3000-3499   3500 (ACK dropped)\n3500-3999    3500-3999   4000 (ACK dropped)\n3000-3499    3000-3499   4000, SACK=3000-3500\n```\n\n\n* 示例二: 网络延误\n\n下面的示例中，网络包（1000-1499）被网络给延误了，导致发送方没有收到ACK，而后面到达的三个包触发了“Fast Retransmit算法”，所以重传，但重传时，被延误的包又到了，所以，回了一个SACK=1000-1500，因为ACK已到了3000，所以，这个SACK是D-SACK——标识收到了重复的包。\n\n这个案例下，发送端知道之前因为“Fast Retransmit算法”触发的重传不是因为发出去的包丢了，也不是因为回应的ACK包丢了，而是因为网络延时了。\n\n```\nTransmitted    Received    ACK Sent\nSegment        Segment     (Including SACK Blocks)\n \n500-999        500-999     1000\n1000-1499      (delayed)\n1500-1999      1500-1999   1000, SACK=1500-2000\n2000-2499      2000-2499   1000, SACK=1500-2500\n2500-2999      2500-2999   1000, SACK=1500-3000\n1000-1499      1000-1499   3000\n               1000-1499   3000, SACK=1000-1500\n```\n\n* 优点\n1）可以让发送方知道，是发出去的包丢了，还是回来的ACK包丢了。\n\n2）是不是自己的timeout太小了，导致重传。\n\n3）网络上出现了先发的包后到的情况（又称reordering）\n\n4）网络上是不是把我的数据包给复制了。\n\n\n\n### 名词解释\n* msl ：max segment lifetime    tpc segment在网络上的存活时间\n* isn ：init sequence number    初始化序列数字\n* time_wait: 确保有足够时间让对端收到ack，一来一回两个msl ，因此超时设置为2*msl\n* FIN ：finish 表示关闭连接\n* tcp_max_tw_buckets ： time_wait的最大数量，默认为180000\n\n\n\n### 最佳实践\n#### 处理大负载连接\n调整三个TCP参数可供你选择，第一个是：tcp_synack_retries 可以用他来减少重试次数；第二个是：tcp_max_syn_backlog，可以增大SYN连接数；第三个是：tcp_abort_on_overflow 处理不过来干脆就直接拒绝连接了。\n\ntcp_tw_reuse和tcp_tw_recycle来解决TIME_WAIT的问题是非常非常危险的，因为这两个参数违反了TCP协议\n","tags":["tcp"],"categories":["internet"]},{"title":"设计模式之规格模式","url":"/2018/07/19/规格模式-2018-07-19/","content":"\n## 设计模式之规格模式\n* 23中模式之外的新模式\n\n### 简介\n在一系列对象中根据条件搜索！类似sql，但不同的是从内存中的对象进行搜索\n具体类似于LINQ（Language Integrated Query）语言集成查询\n\n### 初步实践\n> 1.创建一个接口，实现按照某种条件筛选：IUserProvider\n  2.实现以上接口:UserProvider，通过具体的对象类进行抽象方法的实现（例如：遍历实体类数组，进行判断，然后返回结果数组或列表）\n  3.实现具体对象，类似User实体类\n  4.实现场景类，初始化一个拥有User的数组或列表，实例化UserProvider，并使用相关方法，获取结果\n\n* 请注意以上实现，我们可以发现一旦业务发生变更，我们需要改对应的接口方法、需要实现对应的接口，很不容易进行扩展。\n\n* 第二种：那么我们是否可以将对应的搜索条件进行封装，创建一个接口：IUserSpecification，定义是否满足的方法，返回bool值，这样就可以在多种条件下（业务变更等），进行无缝扩展。只用实现该接口，就可以扩展多个条件类。\n\n* 对于类似于sql的多个条件查询下，在数据量大的情况下容易造成性能较差，因为需要经过好多轮循环\n\n* 第三种：可以知道一般条件组合，基本离不开与或非、这三种模式是固定的，我们可以通过这三种模式进行统一的条件封装。\n> 1.我们创建一个条件规格接口：IUserSpecification,实现判断是否满足，返回bool值\n  2.创建一个抽象类实现IUserSpecification：ComposionSpecificaiton，并且通过模板方法实现与或非三种条件规格的生成，具体接口的实现由具体类来实现。此抽象类依赖于具体的实现（请按照实际情况分析，不要死学）\n  3.继承ComposionSpecificaiton，实现具体的判断方法\n  4.在场景类中，通过条件规格的实现类，使用与或非方法对多个条件进行封装，然后进行计算\n\n#### 第三种方法最优，使用了组合模式、策略模式、模板模式这三种模式组合成了规格模式。\n\n### 类图\n\n![第二种类图](/images/2018-07-19-2.jpg)\n<center>第二种类图</center>\n\n![第三种类图](/images/2018-07-19-1.jpg)\n<center>第三种类图</center>\n\n\n### 以下为代码\n\n* 定义一个用户：\n```\npackage com.bj.hz.specification.very;\n\n/**\n * Created with hzz\n * Description:\n *\n * @author: huangzhe\n * @date: 2018-07-18\n * @time: 9:48 PM\n */\npublic class User {\n    private String name;\n    private int age;\n\n    public User(String name, int age) {\n        this.name = name;\n        this.age = age;\n    }\n\n    public String getName() {\n        return name;\n    }\n\n    public void setName(String name) {\n        this.name = name;\n    }\n\n    public int getAge() {\n        return age;\n    }\n\n    public void setAge(int age) {\n        this.age = age;\n    }\n\n    @Override\n    public String toString() {\n        return \"User{\" +\n                \"name='\" + name + '\\'' +\n                \", age=\" + age +\n                '}';\n    }\n}\n\n```\n* 定义一个查询提供类接口以及实现\n\n```\npackage com.bj.hz.specification.very;\n\n\nimport java.util.ArrayList;\n\n/**\n * Created with hzz\n * Description:\n *\n * @author: huangzhe\n * @date: 2018-07-18\n * @time: 10:07 PM\n */\npublic interface IUserProvider {\n    ArrayList<User> findUser(IUserSpecification specification);\n}\n\n```\n* 提供实现\n```\npackage com.bj.hz.specification.very;\n\n\n\nimport java.util.ArrayList;\n\n/**\n * Created with hzz\n * Description:\n *\n * @author: huangzhe\n * @date: 2018-07-18\n * @time: 10:09 PM\n */\npublic class UserProvider implements IUserProvider {\n\n    private ArrayList<User> users;\n\n    public UserProvider(ArrayList<User> users) {\n        this.users = users;\n    }\n\n    @Override\n    public ArrayList<User> findUser(IUserSpecification specification) {\n        ArrayList<User> result=new ArrayList<>();\n        for (User u:users){\n            if (specification.isSatisfiedBy(u)){\n                result.add(u);\n            }\n        }\n        return result;\n    }\n}\n\n```\n* 规格条件接口\n```\npackage com.bj.hz.specification.very;\n\n/**\n * Created with hzz\n * Description:为了适应未来变化的需求，将运算封装到接口之内\n *\n * @author: huangzhe\n * @date: 2018-07-18\n * @time: 10:02 PM\n */\npublic interface IUserSpecification {\n    public boolean isSatisfiedBy(User user);\n}\n\n```\n* 组合模式的接口，其实可以定义三个装饰器（请自行想象）分别实现 与或非\n```\npackage com.bj.hz.specification.very;\n\n/**\n * Created with hzz\n * Description:\n *\n * @author: huangzhe\n * @date: 2018-07-19\n * @time: 9:06 AM\n */\npublic abstract class AbstractComposition implements IUserSpecification {\n\n\n\n    public IUserSpecification and(IUserSpecification userSpecification){\n        return new AndSpecification(this,userSpecification);\n    }\n\n    public IUserSpecification or(IUserSpecification userSpecification){\n        return new OrSpecification(this,userSpecification);\n    }\n    public IUserSpecification not(IUserSpecification userSpecification){\n        return new NotSpecification(this);\n    }\n\n}\n\n```\n* 分别是与或非实现\n\n```\npackage com.bj.hz.specification.very;\n\n/**\n * Created with hzz\n * Description:\n *\n * @author: huangzhe\n * @date: 2018-07-19\n * @time: 9:08 AM\n */\npublic class AndSpecification extends AbstractComposition {\n\n    private IUserSpecification _left;\n    private IUserSpecification _right;\n\n    public AndSpecification(IUserSpecification _left, IUserSpecification _right) {\n        this._left = _left;\n        this._right = _right;\n    }\n\n    @Override\n    public boolean isSatisfiedBy(User user) {\n        return _left.isSatisfiedBy(user) && _right.isSatisfiedBy(user);\n    }\n}\n\n\n```\n\n```\npackage com.bj.hz.specification.very;\n\n/**\n * Created with hzz\n * Description:\n *\n * @author: huangzhe\n * @date: 2018-07-19\n * @time: 9:09 AM\n */\npublic class OrSpecification extends AbstractComposition {\n\n    private IUserSpecification _left;\n    private IUserSpecification _right;\n\n    public OrSpecification(IUserSpecification _left, IUserSpecification _right) {\n        this._left = _left;\n        this._right = _right;\n    }\n\n    @Override\n    public boolean isSatisfiedBy(User user) {\n        return _left.isSatisfiedBy(user) || _right.isSatisfiedBy(user);\n    }\n}\n\n```\n\n```\npackage com.bj.hz.specification.very;\n\n/**\n * Created with hzz\n * Description:\n *\n * @author: huangzhe\n * @date: 2018-07-19\n * @time: 9:10 AM\n */\npublic class NotSpecification extends AbstractComposition {\n\n    private IUserSpecification userSpecification;\n\n    public NotSpecification(IUserSpecification userSpecification) {\n        this.userSpecification = userSpecification;\n    }\n\n    @Override\n    public boolean isSatisfiedBy(User user) {\n        return !userSpecification.isSatisfiedBy(user);\n    }\n}\n\n```\n* 根据名称查询\n```\npackage com.bj.hz.specification.very;\n\n/**\n * Created with hzz\n * Description:\n *\n * @author: huangzhe\n * @date: 2018-07-19\n * @time: 9:29 AM\n */\npublic class FindByNameSpecification extends AbstractComposition {\n\n    private String name;\n\n    public FindByNameSpecification(String name) {\n        this.name = name;\n    }\n\n    @Override\n    public boolean isSatisfiedBy(User user) {\n        return user.getName().equals(name);\n    }\n}\n\n```\n* 根据大于给定的年龄查询\n```\npackage com.bj.hz.specification.very;\n\n/**\n * Created with hzz\n * Description:\n *\n * @author: huangzhe\n * @date: 2018-07-19\n * @time: 9:31 AM\n */\npublic class FindByAgeThanSpecification extends AbstractComposition {\n\n    private int age;\n\n    public FindByAgeThanSpecification(int age) {\n        this.age = age;\n    }\n\n    @Override\n    public boolean isSatisfiedBy(User user) {\n        return user.getAge()>age;\n    }\n}\n\n```\n\n* 场景类具体实现\n```\npackage com.bj.hz.specification.very;\n\n\n\n\nimport java.util.ArrayList;\n\n/**\n * Created with hzz\n * Description:\n *\n * @author: huangzhe\n * @date: 2018-07-18\n * @time: 10:12 PM\n */\npublic class Client {\n    public static void main(String[] args) {\n        ArrayList<User> users = new ArrayList<>();\n        users.add(new User(\"121\", 3));\n        users.add(new User(\"犁牛\", 10));\n        users.add(new User(\"测试\", 18));\n        users.add(new User(\"hah\", 16));\n        users.add(new User(\"黄啦啦\", 19));\n        users.add(new User(\"吴啦啦\", 20));\n        System.out.println(\"========年龄大于16的==========\");\n        IUserProvider userProvider=new UserProvider(users);\n        for (User user:userProvider.findUser(new FindByNameSpecification(\"hah\").and(new FindByAgeThanSpecification(14)))){\n            System.out.println(user);\n        }\n\n    }\n}\n\n```\n\n\n\n","tags":["设计模式"],"categories":["power design"]},{"title":"netty编解码","url":"/2018/07/17/netty-codec-2018-07-17/","content":"\n\n## 关于netty的编解码\n\n关于netty的编解码学习，一般涉及到数据的出站与入站，在出站时调用编码、在入站时调用解码，编解码都是成对出现，不能出现只有一个。\n\n### netty的编解码类别\n\nnetty的编解码类别主要分为以下三种\n\n* ByteToMessage 入站解码\n* MessageToByte 出站编码\n* MessageToMessage  出站入站均可（编解码）\n\n* 解码继承：ByteToMessageDecoder,该类继承ChannelInboundHandlerAdapter   该类为进站处理\n* 编码继承：MessageToByteEncoder，该类继承ChannelOutboundHandlerAdapter  该类为出站处理\n\n## 例子实现编解码用一个组合handler来表示编解码（前两种）\n\n```\n例如：\npackage com.bj.hz.dzj;\n\nimport io.netty.buffer.ByteBuf;\nimport io.netty.channel.ChannelDuplexHandler;\nimport io.netty.channel.ChannelHandlerContext;\nimport io.netty.channel.ChannelInboundHandlerAdapter;\nimport io.netty.channel.CombinedChannelDuplexHandler;\nimport io.netty.handler.codec.ByteToMessageDecoder;\nimport io.netty.handler.codec.MessageToByteEncoder;\nimport java.util.List;\n\npublic class MyCodec extends CombinedChannelDuplexHandler {\n\n    public MyCodec(){\n        super(new Mydecode(),new Myencode());\n    }\n\n}\n\nclass Mydecode extends ByteToMessageDecoder{\n\n\n    @Override\n    protected void decode(ChannelHandlerContext channelHandlerContext, ByteBuf byteBuf, List<Object> list) throws Exception {\n        //这种是需要判断字节数组的容量是否足够解码，请参考最后使用ReplayingDecoder\n        if (byteBuf.readableBytes()>4){\n            list.add(byteBuf.readInt());\n        }\n    }\n}\n\nclass Myencode extends MessageToByteEncoder<Integer>{\n\n    @Override\n    protected void encode(ChannelHandlerContext channelHandlerContext, Integer integer, ByteBuf byteBuf) throws Exception {\n        byteBuf.writeInt(integer);\n    }\n}\n\n```\n\n\n\n### 使用codec可以统一编解码（前两种）\n* 使用codec 实现编解码一体\n\n```\npackage com.bj.hz.dzj;\n\nimport io.netty.buffer.ByteBuf;\nimport io.netty.channel.ChannelHandlerContext;\nimport io.netty.handler.codec.ByteToMessageCodec;\nimport java.util.List;\n\npublic class Mycodec1 extends ByteToMessageCodec<Integer> {\n\n    @Override\n    protected void decode(ChannelHandlerContext channelHandlerContext, ByteBuf byteBuf, List list) throws Exception {\n        if (byteBuf.readableBytes()>4){\n            list.add(byteBuf.readInt());\n        }\n    }\n\n    @Override\n    protected void encode(ChannelHandlerContext channelHandlerContext, Integer integer, ByteBuf byteBuf) throws Exception {\n        byteBuf.writeInt(integer);\n    }\n}\n```\n\n### 使用codec实现第三种\n该类型主要实现编码中协议（例如api等）转换\n\n```\npublic class MyMessagetoMessage extends MessageToMessageCodec<Integer,String> {\n    @Override\n    protected void encode(ChannelHandlerContext channelHandlerContext, String s, List<Object> list) throws Exception {\n        list.add(Integer.parseInt(s));\n    }\n\n    @Override\n    protected void decode(ChannelHandlerContext channelHandlerContext, Integer integer, List<Object> list) throws Exception {\n        list.add(String.valueOf(integer));\n    }\n}\n```\n\n### 使用ReplayingDecoder,来实现自动转换，当bytebuf中没有能够转换的足够字节，则会一直等待足够才会转换\n\n```\npackage com.bj.hz.dzj;\n\nimport io.netty.buffer.ByteBuf;\nimport io.netty.channel.ChannelHandlerContext;\nimport io.netty.handler.codec.ReplayingDecoder;\nimport java.util.List;\n\npublic class MyreplyingDecoder extends ReplayingDecoder<Integer> {\n    @Override\n    protected void decode(ChannelHandlerContext channelHandlerContext, ByteBuf byteBuf, List<Object> list) throws Exception {\n        list.add(byteBuf.readInt());\n    }\n}\n```\n\n","tags":["netty"],"categories":["codec"]},{"title":"solr安装分词","url":"/2018/04/03/solr安装分词/","content":"\n* 环境 centos7\n### 下载solr\n`地址：http://www.apache.org/dyn/closer.lua/lucene/solr/7.2.1`\n\n#### 解压\n```bash\ntar -xvf solr-7.2.1.tgz\n\n```\n### 1. 直接使用solr\n```\ncd solrHome(solrHome是solr的路径)\ncd bin\nsolr start\n```\n#### 1.1. 创建core 或者collection 意义一致\n```bash\nsolr create -c articles\n控制台：http://127.0.0.1:8983/solr\n```\n\n#### 1.2. 创建分词器\n```bash\n下载地址：https://pan.baidu.com/s/1smOxPhF\n将解分词资料里的ik-analyzer-solr5-5.x.jar拷贝到你的solr目录下的\\server\\solr-webapp\\webapp\\WEB-INF\\lib目录中去，\n将IKAnalyzer.cfg.xml，mydict.dic（搜狗的扩展词库），stopword.dic放在你的solr目录下的\\server\\solr-webapp\\webapp\\WEB-INF\\classes目录中去\n\n\n修改 articles集合目录下的managed-schema\n\n添加以下4行：\n\n<fieldType name=\"text_ik\" class=\"solr.TextField\">  \n        <analyzer class=\"org.wltea.analyzer.lucene.IKAnalyzer\"/>  \n</fieldType>  \n\n\n重启或者reload\n\n```\n#### 1.3. 创建字段\n```\n{\n    \"add-field\" : {\n        \"name\" : \"name\",\n        \"type\" : \"text_ik\"\n    },\n    \"add-field\" : {\n        \"name\" : \"content\",\n        \"type\" : \"text_ik\",\n        \"stored\" : \"true\"\n    },\n    \"add-field\" : {\n        \"name\" : \"createTime\",\n        \"type\" : \"date\"\n    }\n}\n\npost提交：\nhttp://localhost:8983/solr/articles/schema\n```\n\n#### 1.4. 删除字段\n\n```\n{\n    \"delete-field\" : {\n        \"name\" : \"name\"\n    },\n    \"delete-field\" : {\n        \"name\" : \"content\"\n    }\n}\nhttp://localhost:8983/solr/articles/schema\n```\n\n\n### 2. 使用tomcat作为容器运行solr\n#### 2.1 新创建一个solr_home_new文件夹\n\n```\nexport solr_home=/app/solr-7.2.1\nexport solr_home_new=/app/solr_home\n\n复制 ${solr_home}/server/solr-webapp/webapp 并重命名 ${tomcat}/webapp/solr\ncp -r ${solr_home}/dist  ${solr_home_new}/\ncp ${solr_home}/server/lib/ext/*.jar ${tomcat}/webapp/solr/WEB-INF/lib/\ncp ${solr_home}/server/lib/*.jar ${tomcat}/webapp/solr/WEB-INF/lib/\n#classes文件夹没有自己创建\ncp ${solr_home}/server/resources/log4j.properties ${tomcat}/webapp/solr/WEB-INF/classes \n\n\n#进入 ${tomcat}/webapp/solr/WEB-INF/ 修改web.xml\n修改：修改中间为自己的solr_home_new，我的solr_home_new为solr_home/solr\n\n <env-entry>\n         <env-entry-name>solr/home</env-entry-name>\n         <env-entry-value>/Users/huangzhe/app/solr_home/solr</env-entry-value>\n         <env-entry-type>java.lang.String</env-entry-type>\n</env-entry>\n并注释以下，防止403：\n<!--  <security-constraint>\n    <web-resource-collection>\n      <web-resource-name>Disable TRACE</web-resource-name>\n      <url-pattern>/</url-pattern>\n      <http-method>TRACE</http-method>\n    </web-resource-collection>\n    <auth-constraint/>\n  </security-constraint>\n  <security-constraint>\n    <web-resource-collection>\n      <web-resource-name>Enable everything but TRACE</web-resource-name>\n      <url-pattern>/</url-pattern>\n      <http-method-omission>TRACE</http-method-omission>\n    </web-resource-collection>\n  </security-constraint>\n-->\n\n```\n\n\n#### 2.2 创建core\n```\ncp -r ${solr_home}/server/solr ${solr_home_new}/\ncd ${solr_home_new}/solr\nmkdir new_core\ncp -r configsets/_default/conf new_core\n\n打开浏览器：http://localhost:8080/solr/index.html\n点击：core Admin ,然后更改schema.xml为 managed-schema，点击确定\n```\n\n\n#### 2.3 添加分词器\n与1.2一致，在tomcat下面对应的路径去改\n","tags":["search"],"categories":["solr"]},{"title":"localtunnel server端搭建","url":"/2018/03/15/localtunnel-server端搭建/","content":"\n## localtunnel server\n### 下载程序\n> 以下地址为localtunnel server的git页面\n\n`https://github.com/localtunnel/server`\n\n> 下载安装\n\n* 前提：本机安装git、 nodejs \n* 有独立域名、独立主机（公网ip）\n\n```bash\n$ git clone  https://github.com/localtunnel/server.git\n$ cd localtunnel-server\n$ npm install\n```\n\n> 启动\n\n```bash\n# 直接使用\n$ bin/server --port 2000\n# 配合 pm2 使用\n$ pm2 start bin/server --name lt -- --port 2000\n```\n\n> server配合nginx使用\n\n* 配置如下：\n\n```nginx\nupstream server {\n\n                server 127.0.0.1:8099;\n        }\nmap $http_upgrade $connection_upgrade {\n    default upgrade;\n    ''      close;\n}\n\nserver {\n        listen 80 default_server;\n        server_name example.com;\n    location / {\n        proxy_pass http://server;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header Host $http_host;\n        proxy_set_header X-Forwarded-Proto http;\n        proxy_set_header X-NginX-Proxy true;\n     #  proxy_set_header Upgrade $http_upgrade;\n     #  proxy_set_header Connection $connection_upgrade;\n\n        proxy_redirect off;\n                }\n        }\n\n server {\n        listen       443 default_server ssl;\n        server_name  example.com;\n        ssl on;\n        ssl_certificate      /etc/letsencrypt/live/example.com/fullchain.pem;\n        ssl_certificate_key  /etc/letsencrypt/live/example.com/privkey.pem;\n\n        ssl_session_cache    shared:SSL:1m;\n        ssl_session_timeout  5m;\n\n        ssl_ciphers  HIGH:!aNULL:!MD5;\n        ssl_prefer_server_ciphers  on;\n\n        location / {\n\n        proxy_pass http://server/;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header Host $http_host;\n        proxy_set_header X-Forwarded-Proto https;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection $connection_upgrade;\n\n        proxy_set_header X-NginX-Proxy true;\n        proxy_redirect off;\n        }\n    }\n```\n\n\n> client端使用\n\n```bash\n# 安装client端\n$ npm i localtunnel -g\n# 使用localtunnel默认服务器启动本地监听8080端口\n$ lt --port 8080\n# 使用自己搭建的服务器启动监听本地8080端口\n$ lt -h http://example.com --port 8080\n# 指定二级域名启动监听\n$ lt -s ceshi -h http://example.com --port 8080 \n```\n\n\n","tags":["内网穿透"],"categories":["内网穿透"]},{"title":"读源码注意的东西","url":"/2018/02/06/读源码注意的东西/","content":"## 修改相关\n###### 2018/2/6  创建\n\n## 怎样读源码，该注意什么问题\n\n*前提：读懂源码的动机与原因是什么。*\n     *看下该项目的设计文档与架构图，宏观上对一些概念有些认识*\n     *从感兴趣的点设置断点、开始debug*\n\n\n* 了解语言\n* 了解设计模式\n* 了解命名习惯-统一规约\n* 是了解整体架构，而不是地毯式遍历每一行代码\n* 了解架构： 从上至下（要有层次感） 层级、每个层级由多个角色构成，角色的互动\n    系统如何初始化（为接下来的所有任务做准备）-> 系统的相关的其他系统（界面等||设定系统的边界）-> 系统如何反应事件-> 系统如何处理异常与错误\n\n","tags":["方法"],"categories":["java"]},{"title":"字符串反转","url":"/2018/02/05/字符串反转/","content":"\n## 以下为字符串反转的几种方法\n\n### 遍历字符数组\n\n```java\n\n    public static void reverse3(String src){\n        if(src==null){\n            throw new IllegalArgumentException(src);\n        }\n        int length=src.length();\n        char[] srcChar=src.toCharArray();\n        for(int i=0;i<length/2;i++){\n            char temp=srcChar[i];\n            srcChar[i]=srcChar[length-i-1];\n            srcChar[length-i-1]=temp;\n        }\n        System.out.println(new String(srcChar));\n    }\n\n\n\n    public static void reverse1(String src){\n        if(src==null){\n            throw new IllegalArgumentException(src);\n        }\n        int length=src.length();\n        char[] dest=new char[length];\n        char[] srcChar=src.toCharArray();\n        for(int i=0;i<length;i++){\n            dest[i]=srcChar[length-i-1];\n        }\n        System.out.println(new String(dest));\n    }\n```\n\n### 递归\n\n```java\n public static String reverse4(String src){\n        if(src==null){\n            throw new IllegalArgumentException(src);\n        }\n        int length=src.length();\n        if(length<=1){\n            return src;\n        }\n        String left=src.substring(0,length/2);\n        String right=src.substring(length/2,length);\n        return reverse4(right)+reverse4(left);\n\n    }\n\n\n```\n\n### 使用StringBuffer\n\n```java\n\n public static void reverse2(String src){\n        if(src==null){\n            throw new IllegalArgumentException(src);\n        }\n        StringBuffer sb=new StringBuffer(src);\n        sb.reverse();\n        System.out.println(sb.toString());\n    }\n\n```","tags":["工具"],"categories":["java"]},{"title":"linux删除文件除过某个文件","url":"/2018/02/01/linux删除文件除过某个文件/","content":"\n### 使用rm \n> 删除除了file1 的文件\n\n\n\n```bash\nrm -fr !(file1)\n```\n\n\n### 使用find\n> 删除除了file1\n\n```bash\nfind ./* -not -name \"file1\" | xargs rm -fr\nfind ./* -not -name \"file1\" -exec rm -fr {} \\;\n```\n\n\n\n","tags":["find"],"categories":["shell"]},{"title":"linux下使用rsync快速删除大量文件","url":"/2018/01/31/linux下使用rsync快速删除大量文件/","content":"\n## 问题：快速删除一个文件夹下的大量文件？\n* 使用rm 大量文件会很慢，更大时并且会报错\n> 实际原理：遍历删除\n\n```bash\n$ rm -fr *\n```\n\n* 使用rsync删除\n> 实际原理：使用空文件夹替换要删除的文件夹\n\n\n\n```bash\n#建立新的空文件夹\n$ mkdir src\n#建立实际有很多文件的文件夹\n$ mkdir dest\n#模拟生成大量文件  900000个文件\n$ touch file{1..900000}\n#使用rsync删除\n# -r 包含文件夹 -l 符号链接 -p 权限 permission -t 保持文件修改时间 -D 特殊设备\n$ rsync --delete-before -rlptD src/ dest\n#或者(与上面一样的效果)\n$ rsync -a --delete-before --no-o --no-g src/ dest\n```\n","tags":["rm"],"categories":["shell"]},{"title":"hexo安装部署教程","url":"/2018/01/30/hexo安装部署教程/","content":"##    建立一个\bgithubpage项目\n### 使用自定义域名访问博客的前提：\n> 有域名解析至你的github page 我的域名为：blog.wudd.top\n\n\n####   建立一个分支 hexo\n* hexo为项目管理分支，即hexo博客项目的主分支\n* master分支为博客展示页面的分支（\b建好项目即存在的分支）\n\n##  在本地 \bclone hexo 分支\n\n```bash\n#克隆hexo分支\n$ git clone -b hexo git地址\n#进入\b克隆好的项目\n$ cd 项目名\n```\n##  安装hexo 以及相关的主题\n```bash\n#全局安装hexo\n$ sudo npm install -g hexo-cli\n#初始化hexo\n$ hexo init .\n```\n####  编辑项目目录下的 _config.yml文件\n##### ps\n* site:为博客自定义\b内容\n* 主题theme：主题配置项为第四步安装的，默认为自带的，也可不修改\n* deploy:填写自己的githubpage地址，分支为master\n* url:填写自己的博客访问url\n```bash\n#编辑项目根目录下的配置文件，修改以下其他可不修改：\b\n$ vim _config.yml\n \n  5 # Site\n  6 title: Hzhe\n  7 subtitle: you...\n  8 description: blog java\n  9 author: hzz\n 10 language:\n 11 timezone:\n 12\n 13 # URL\n 14 ## If your site is put in a subdirectory, set url as 'http://yoursite.com/ch    ild' and root as '/child/'\n 15 url: http://blog.wudd.top\n 16 root: /\n 17 permalink: :year/:month/:day/:title/\n 18 permalink_defaults:\n# Extensions\n 73 ## Plugins: https://hexo.io/plugins/\n 74 ## Themes: https://hexo.io/themes/ \n 75 theme: hexo-theme-laughing\n 76\n 77 # Deployment\n 78 ## Docs: https://hexo.io/docs/deployment.html\n 79 deploy:\n 80   type: git\n 81   repo: https://github.com/fastZhe/fastZhe.github.io\n 82   branch: master\n\n```\n##  安装hexo相关的主题\n* signature:个人签名\n* author.head:个人头像\n* navication:菜单栏\n* copyright：建议都关闭\n* socail:社交媒体连接\n```bash\n#进入theme文件夹\n$ cd theme\n#安装主题（不是必须）\n$ npm install hexo-renderer-pug --save\n$ git clone git@github.com:BoizZ/hexo-theme-laughing.git\n#删除主题文件夹内的.git\n$ cd hexo-theme-laughing ; rm -fr .git\n#编辑主题配置文件\n$ vim _config.yml\n\n  6 page_background: http://callfiles.ueibo.com/hexo-theme-laughing/page_backgro    und.jpg\n  7 page_menu_button: dark\n  8 post_background: http://callfiles.ueibo.com/hexo-theme-laughing/post_backgro    und.jpg\n  9 post_menu_button: light\n 10 title_plancehold: 随笔\n 11 author:\n 12   head: https://tva3.sinaimg.cn/crop.0.0.750.750.180/cbe52eb6jw8ew3l78tj4qj2    0ku0kv75s.jpg\n 13   signature: 世界那么大，我想去看看。。。KEEP FIGHTING\n 14 navication:\n 15   - name: Github\n 16     link: https://github.com/fastZhe\n 17 # content\n 18 content_width: 800\n\n 21 social:\n 22   - name: Github\n 23     icon: github\n 24     link: https://github.com\n 25   - name: Weibo\n 26     icon: weibo\n 27     link: https://weibo.com/p/1005053420794550/home?from=page_100505&mod=TAB    &is_all=1\n\n # Copyright\n 33 copyright:\n 34   record: false\n 35   hexo: false\n 36   laughing: true\n```\n\n##  编辑githubpage 项目根目录下的.gitignore\n* 配置成以下：避免项目管理分支缺少相关目录\n* 推送至hexo分支\n```bash\n$ vim .gitignore\n\n.DS_Store\nThumbs.db\n*.log\n.deploy*/\n\n$ git add .gitignore \n$ git commit -m \"\"\n$ git push origin hexo\n```\n\n##  新建编辑CNAME 自动\b映射对应的域名\n* 填写自己访问的博客地址\n* ps 这个是我的域名，请换成自己的\n* 推送至hexo分支\n```bash\n$ vim source/CNAME\nblog.wudd.top\n\n$ git add . \n$ git commit -m \"\"\n$ git push origin hexo\n```\n\n\n##  发布博客以及推送操作\n```bash\n#新建博客\n$ hexo new \"博客名\"\nINFO  Created: ~/me/blog/fast/fastZhe.github.io/source/_posts/hexo安装部署教程.md\n#编辑博客\n$ vim ~/me/blog/fast/fastZhe.github.io/source/_posts/hexo安装部署教程.md\n#推送至远程项目目录进行保存分支为hexo（保存项目目录，多机操作）\n$ git add .\n$ git commit -m \"最新博客等。。。\"\n$ git push origin hexo\n#生成博客\n$ hexo g\n#本地预览（在本地验证博客是否有问题）,访问以下地址即可\n$ hexo server\n➜  fastZhe.github.io git:(hexo) ✗ hexo server\nINFO  Start processing\nINFO  Hexo is running at http://localhost:4000/. Press Ctrl+C to stop.\n\n#部署博客至githubpage\nhexo d\n```\n\n### 打开页面 \b你的域名，请尽情欣赏吧！！！\n","tags":["hexo"]},{"title":"Hello World","url":"/2018/01/30/hello-world/","content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n<!--more-->\n\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/deployment.html)\n"}]